{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "# Text classification: sentiment analysis \n",
    "\n",
    "</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "## Popular tasks of text classification\n",
    "\n",
    "</font>\n",
    "\n",
    "- **Spam detection**: Having message decide is is spammy or not \n",
    "- **Topic identification**: Having article choose one of known classes like \"Sport\", \"Technology\", \"Finances\"\n",
    "- **Sentiment analysis**: Is the moview positive or negative \n",
    "- **Spelling correction**: what is more suitable \"weather\" or \"whether\"  \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "## Features from Text\n",
    "\n",
    "</font>\n",
    "\n",
    "1. The most common words\n",
    "2. *Stop* words\n",
    "3. Normalization: lower case / stemming / lemmatizing\n",
    "4. Capitalization as feature \n",
    "5. POS e.g. \"the weather\" vs whether  \n",
    "6. grouping\n",
    "    - buy, purchase\n",
    "    - Mr, Ms, Dr\n",
    "    - Numbers\n",
    "    - Dates\n",
    "7. Bigrams, n-grams e.g. \"White House\"\n",
    "8. Sub-sequences e.g. \"ing\", \"ion\"\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "## Naive Bayes Classifiers\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "### Text classification of search query \n",
    "\n",
    "</font>\n",
    "\n",
    "- **python**  as snake -> Zoology\n",
    "- **python**  as programming language -> Computer Science\n",
    "- **python**  as \"monty python\" -> Entertainment\n",
    "\n",
    "Probabilistic model:\n",
    "\n",
    "#### Bayes Rule\n",
    "\n",
    "\\begin{equation*}\n",
    "P(y|X) = \\frac{P(X| y) \\cdot P(y)}{P(X)} \n",
    "\\quad\\quad\\quad\n",
    "Posterior = \\frac{ Likelihood \\cdot Prior}{Evidence} \n",
    "\\quad\\quad\\quad\n",
    "P(class| python) = \\frac{P(python| class) \\cdot P(class)}{P(python)} \n",
    "\\end{equation*}\n",
    "\n",
    "Considering the $P(python)$ is common for all classes we may compare just nominators: \n",
    "\n",
    "\\begin{equation*}\n",
    "P(python| Zoology) \\cdot P(Zoology) \n",
    "\\quad\\quad\\quad \n",
    "P(python|CS) \\cdot P(CS) \n",
    "\\quad\\quad\\quad\n",
    "P(python|Entertainment) \\cdot P(Entertainment) \n",
    "\\end{equation*}\n",
    "\n",
    "In general: \n",
    "\\begin{equation*}\n",
    "\\hat{y} =  \\underset{y}{argmax} \\quad P(y|X) =  \\underset{argmax}{y} P(X|y) \\cdot P(y)\n",
    "\\end{equation*}\n",
    "\n",
    "Most probably predicted class is <font color = blue>CS</font>\n",
    "\n",
    "#### Naive Bayes Classifiers\n",
    "\\begin{equation*}\n",
    "\\hat{y} =  \\underset{y}{argmax} \\quad P(y) \\prod_{ i=1 }^{ n }{ P(x_{ i }|\\,y) } \n",
    "\\end{equation*}\n",
    "\n",
    "If search query = **\"python snake\"** \n",
    "\\begin{equation*}\n",
    "\\hat{y} =  \\underset{y}{argmax} \\quad\n",
    "P(y)\\cdot P(python|\\,y) \\cdot P(snake|\\,y)\n",
    "\\end{equation*}\n",
    "\n",
    "Now, the most probably predicted class is <font color = blue>Zoology</font> since  $P(snake|\\,CS)$ is far less than $P(snake|\\,Zoology)$\n",
    "\n",
    "Note: if one of word is not presented in text then its statistical propability = 0 and as the result\n",
    "the whole likelihood = 0 regardless of other words. Thus it is worth using laplace smooting  \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Laplace smooting \n",
    " \n",
    "</font>\n",
    "\n",
    "\n",
    "$\n",
    "A : 1 \\quad\n",
    "B : 3\\quad\n",
    "C : 0\\quad\n",
    "D : 6\\quad\n",
    "$\n",
    "\n",
    "$N= 10\\quad K =4$ \n",
    "<br>N - number of samples, K - number of classes\n",
    "\n",
    "\\begin{equation*}\n",
    "P(A) = 0.1\\quad\\quad\\quad\\quad\n",
    "P(B) = 0.3\\quad\\quad\\quad\\quad\n",
    "P(C) = 0.0\\quad\\quad\\quad\\quad\n",
    "P(D) = 0.6\\\\\n",
    "\\end{equation*}\n",
    "\n",
    "<font color = blue >\n",
    "\n",
    "\\begin{equation*}\n",
    "P^{\\,L}(x_{i}) =  \\frac{P(x_{i})+1}{N+K}\n",
    "\\end{equation*}\n",
    "\n",
    "</font>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "P^{\\,L}(A) =  \\frac{1+1}{10+4} = 0.14 \\quad P^{\\,L}(B) =  \\frac{3+1}{10+4} = 0.29\n",
    "\\quad P^{\\,L}(C) =  \\frac{0+1}{10+4} = 0.07 \\quad P^{\\,L}(D) =  \\frac{6+1}{10+4} = 0.5\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "## Sentiment Analysis\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "### Using NLTK\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from nltk.corpus import movie_reviews \r\n",
    "from nltk.corpus import stopwords\r\n",
    "import nltk\r\n",
    "from nltk.tokenize import RegexpTokenizer\r\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "nltk.download('movie_reviews')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\havrylov.mykola\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Load data\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "all_movie_reviews_text= movie_reviews.raw() # it is just all reviews joined into one text e.g. \r\n",
    "# this is the ending of first review: \" the others ( 9/10 ) - stir of echoes ( 8/10 ) \"\r\n",
    "# this is the beginning of second review : \"the happy bastard's quick movie review \"\r\n",
    "print(all_movie_reviews_text[3600:4600])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "way because someone is apparently assuming that the genre is still hot with the kids . \n",
      "it also wrapped production two years ago and has been sitting on the shelves ever since . \n",
      "whatever . . . skip \n",
      "it ! \n",
      "where's joblo coming from ? \n",
      "a nightmare of elm street 3 ( 7/10 ) - blair witch 2 ( 7/10 ) - the crow ( 9/10 ) - the crow : salvation ( 4/10 ) - lost highway ( 10/10 ) - memento ( 10/10 ) - the others ( 9/10 ) - stir of echoes ( 8/10 ) \n",
      "the happy bastard's quick movie review \n",
      "damn that y2k bug . \n",
      "it's got a head start in this movie starring jamie lee curtis and another baldwin brother ( william this time ) in a story regarding a crew of a tugboat that comes across a deserted russian tech ship that has a strangeness to it when they kick the power back on . \n",
      "little do they know the power within . . . \n",
      "going for the gore and bringing on a few action sequences here and there , virus still feels very empty , like a movie going for all flash and no substance . \n",
      "we don't know why the crew w\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Tools to review data \n",
    "\n",
    "</font>\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "cats =  movie_reviews.categories()\r\n",
    "cats"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "cat = cats[0]\r\n",
    "ids= movie_reviews.fileids(cat)\r\n",
    "ids[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['neg/cv000_29416.txt',\n",
       " 'neg/cv001_19502.txt',\n",
       " 'neg/cv002_17424.txt',\n",
       " 'neg/cv003_12683.txt',\n",
       " 'neg/cv004_12641.txt',\n",
       " 'neg/cv005_29357.txt',\n",
       " 'neg/cv006_17022.txt',\n",
       " 'neg/cv007_4992.txt',\n",
       " 'neg/cv008_29326.txt',\n",
       " 'neg/cv009_29417.txt']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "id_review = ids[0]\r\n",
    "print(movie_reviews.raw(id_review))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "plot : two teen couples go to a church party , drink and then drive . \n",
      "they get into an accident . \n",
      "one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \n",
      "what's the deal ? \n",
      "watch the movie and \" sorta \" find out . . . \n",
      "critique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . \n",
      "which is what makes this review an even harder one to write , since i generally applaud films which attempt to break the mold , mess with your head and such ( lost highway & memento ) , but there are good and bad ways of making all types of films , and these folks just didn't snag this one correctly . \n",
      "they seem to have taken this pretty neat concept , but executed it terribly . \n",
      "so what are the problems with the movie ? \n",
      "well , its main problem is that it's simply too jumbled . \n",
      "it starts off \" normal \" but then downshifts into this \" fantasy \" world in which you , as an audience member , have no idea what's going on . \n",
      "there are dreams , there are characters coming back from the dead , there are others who look like the dead , there are strange apparitions , there are disappearances , there are a looooot of chase scenes , there are tons of weird things that happen , and most of it is simply not explained . \n",
      "now i personally don't mind trying to unravel a film every now and then , but when all it does is give me the same clue over and over again , i get kind of fed up after a while , which is this film's biggest problem . \n",
      "it's obviously got this big secret to hide , but it seems to want to hide it completely until its final five minutes . \n",
      "and do they make things entertaining , thrilling or even engaging , in the meantime ? \n",
      "not really . \n",
      "the sad part is that the arrow and i both dig on flicks like this , so we actually figured most of it out by the half-way point , so all of the strangeness after that did start to make a little bit of sense , but it still didn't the make the film all that more entertaining . \n",
      "i guess the bottom line with movies like this is that you should always make sure that the audience is \" into it \" even before they are given the secret password to enter your world of understanding . \n",
      "i mean , showing melissa sagemiller running away from visions for about 20 minutes throughout the movie is just plain lazy ! ! \n",
      "okay , we get it . . . there \n",
      "are people chasing her and we don't know who they are . \n",
      "do we really need to see it over and over again ? \n",
      "how about giving us different scenes offering further insight into all of the strangeness going down in the movie ? \n",
      "apparently , the studio took this film away from its director and chopped it up themselves , and it shows . \n",
      "there might've been a pretty decent teen mind-fuck movie in here somewhere , but i guess \" the suits \" decided that turning it into a music video with little edge , would make more sense . \n",
      "the actors are pretty good for the most part , although wes bentley just seemed to be playing the exact same character that he did in american beauty , only in a new neighborhood . \n",
      "but my biggest kudos go out to sagemiller , who holds her own throughout the entire film , and actually has you feeling her character's unraveling . \n",
      "overall , the film doesn't stick because it doesn't entertain , it's confusing , it rarely excites and it feels pretty redundant for most of its runtime , despite a pretty cool ending and explanation to all of the craziness that came before it . \n",
      "oh , and by the way , this is not a horror or teen slasher flick . . . it's \n",
      "just packaged to look that way because someone is apparently assuming that the genre is still hot with the kids . \n",
      "it also wrapped production two years ago and has been sitting on the shelves ever since . \n",
      "whatever . . . skip \n",
      "it ! \n",
      "where's joblo coming from ? \n",
      "a nightmare of elm street 3 ( 7/10 ) - blair witch 2 ( 7/10 ) - the crow ( 9/10 ) - the crow : salvation ( 4/10 ) - lost highway ( 10/10 ) - memento ( 10/10 ) - the others ( 9/10 ) - stir of echoes ( 8/10 ) \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Tokenize\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def preprocess(text): # removes punctualtion\r\n",
    "    tokenizer = RegexpTokenizer(r'\\w+') # just for demo\r\n",
    "    return tokenizer.tokenize(text.lower())\r\n",
    "\r\n",
    "all_words = preprocess(all_movie_reviews_text)\r\n",
    "print (len(all_words))\r\n",
    "print(all_words[:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1336782\n",
      "['plot', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', 'drink', 'and', 'then', 'drive', 'they', 'get', 'into', 'an', 'accident', 'one', 'of', 'the', 'guys', 'dies', 'but', 'his', 'girlfriend', 'continues', 'to', 'see', 'him', 'in', 'her', 'life', 'and', 'has', 'nightmares', 'what', 's', 'the', 'deal', 'watch', 'the', 'movie', 'and', 'sorta', 'find', 'out', 'critique', 'a', 'mind', 'fuck', 'movie', 'for', 'the', 'teen', 'generation', 'that', 'touches', 'on', 'a', 'very', 'cool', 'idea', 'but', 'presents', 'it', 'in', 'a', 'very', 'bad', 'package', 'which', 'is', 'what', 'makes', 'this', 'review', 'an', 'even', 'harder', 'one', 'to', 'write', 'since', 'i', 'generally', 'applaud', 'films', 'which', 'attempt', 'to', 'break', 'the', 'mold', 'mess', 'with', 'your', 'head', 'and', 'such']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Build vocabulary\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "all_words=nltk.FreqDist(all_words)\r\n",
    "print ('len of vocabulary: {:,}'.format (len(all_words)))\r\n",
    "\r\n",
    "# Use most common words\r\n",
    "most_common_words = list(zip(*all_words.most_common()))[0] # [0] means names whereas [1] are frequencies \r\n",
    "# most_common(5000) - it may retutn limited number but in this sample the features will be filtered later after removing stop words \r\n",
    "print (most_common_words[:10])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len of vocabulary: 39,696\n",
      "('the', 'a', 'and', 'of', 'to', 'is', 'in', 's', 'it', 'that')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Get rid of stop words \n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def remove_stop_words(words):\r\n",
    "    stop_words = set(stopwords.words('english'))  \r\n",
    "    return [w for w in words if w not in stop_words]\r\n",
    "most_common_words_filtered = remove_stop_words(most_common_words)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Select features \n",
    "\n",
    "</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "\r\n",
    "word_features = most_common_words_filtered [:3000]\r\n",
    "print (word_features[:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['film', 'one', 'movie', 'like', 'even', 'good', 'time', 'story', 'would', 'much', 'character', 'also', 'get', 'two', 'well', 'characters', 'first', 'see', 'way', 'make', 'life', 'really', 'films', 'plot', 'little', 'people', 'could', 'scene', 'man', 'bad', 'never', 'best', 'new', 'scenes', 'many', 'director', 'know', 'movies', 'action', 'great', 'another', 'love', 'go', 'made', 'us', 'big', 'end', 'something', 'back', 'still', 'world', 'seems', 'work', 'makes', 'however', 'every', 'though', 'better', 'real', 'audience', 'enough', 'seen', 'take', 'around', 'going', 'year', 'performance', 'role', 'old', 'gets', 'may', 'things', 'think', 'years', 'last', 'comedy', 'funny', 'actually', 'long', 'look', 'almost', 'thing', 'fact', 'nothing', 'say', 'right', 'john', 'although', 'played', 'find', 'script', 'come', 'ever', 'cast', 'since', 'star', 'plays', 'young', 'show', 'comes']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Extract documents and labels\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Note: this does not use tokenizing to documents but words of document retrieved by file_id instead.\r\n",
    "documents = [(list(movie_reviews.words(file_id)), category) # using the words() method of movie_reviews object\r\n",
    "             for category in movie_reviews.categories() # select category - there are two: ['neg', 'pos']\r\n",
    "             for file_id in movie_reviews.fileids(category)]# select all file_ids for specified category\r\n",
    "len (documents)\r\n",
    "# This returns list of tuples (list_of_tokens_of document, label)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print (documents [0]) # (['plot', ':', 'two', 'teen', ... 'echoes', '(', '8', '/', '10', ')'], 'neg')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an', 'accident', '.', 'one', 'of', 'the', 'guys', 'dies', ',', 'but', 'his', 'girlfriend', 'continues', 'to', 'see', 'him', 'in', 'her', 'life', ',', 'and', 'has', 'nightmares', '.', 'what', \"'\", 's', 'the', 'deal', '?', 'watch', 'the', 'movie', 'and', '\"', 'sorta', '\"', 'find', 'out', '.', '.', '.', 'critique', ':', 'a', 'mind', '-', 'fuck', 'movie', 'for', 'the', 'teen', 'generation', 'that', 'touches', 'on', 'a', 'very', 'cool', 'idea', ',', 'but', 'presents', 'it', 'in', 'a', 'very', 'bad', 'package', '.', 'which', 'is', 'what', 'makes', 'this', 'review', 'an', 'even', 'harder', 'one', 'to', 'write', ',', 'since', 'i', 'generally', 'applaud', 'films', 'which', 'attempt', 'to', 'break', 'the', 'mold', ',', 'mess', 'with', 'your', 'head', 'and', 'such', '(', 'lost', 'highway', '&', 'memento', ')', ',', 'but', 'there', 'are', 'good', 'and', 'bad', 'ways', 'of', 'making', 'all', 'types', 'of', 'films', ',', 'and', 'these', 'folks', 'just', 'didn', \"'\", 't', 'snag', 'this', 'one', 'correctly', '.', 'they', 'seem', 'to', 'have', 'taken', 'this', 'pretty', 'neat', 'concept', ',', 'but', 'executed', 'it', 'terribly', '.', 'so', 'what', 'are', 'the', 'problems', 'with', 'the', 'movie', '?', 'well', ',', 'its', 'main', 'problem', 'is', 'that', 'it', \"'\", 's', 'simply', 'too', 'jumbled', '.', 'it', 'starts', 'off', '\"', 'normal', '\"', 'but', 'then', 'downshifts', 'into', 'this', '\"', 'fantasy', '\"', 'world', 'in', 'which', 'you', ',', 'as', 'an', 'audience', 'member', ',', 'have', 'no', 'idea', 'what', \"'\", 's', 'going', 'on', '.', 'there', 'are', 'dreams', ',', 'there', 'are', 'characters', 'coming', 'back', 'from', 'the', 'dead', ',', 'there', 'are', 'others', 'who', 'look', 'like', 'the', 'dead', ',', 'there', 'are', 'strange', 'apparitions', ',', 'there', 'are', 'disappearances', ',', 'there', 'are', 'a', 'looooot', 'of', 'chase', 'scenes', ',', 'there', 'are', 'tons', 'of', 'weird', 'things', 'that', 'happen', ',', 'and', 'most', 'of', 'it', 'is', 'simply', 'not', 'explained', '.', 'now', 'i', 'personally', 'don', \"'\", 't', 'mind', 'trying', 'to', 'unravel', 'a', 'film', 'every', 'now', 'and', 'then', ',', 'but', 'when', 'all', 'it', 'does', 'is', 'give', 'me', 'the', 'same', 'clue', 'over', 'and', 'over', 'again', ',', 'i', 'get', 'kind', 'of', 'fed', 'up', 'after', 'a', 'while', ',', 'which', 'is', 'this', 'film', \"'\", 's', 'biggest', 'problem', '.', 'it', \"'\", 's', 'obviously', 'got', 'this', 'big', 'secret', 'to', 'hide', ',', 'but', 'it', 'seems', 'to', 'want', 'to', 'hide', 'it', 'completely', 'until', 'its', 'final', 'five', 'minutes', '.', 'and', 'do', 'they', 'make', 'things', 'entertaining', ',', 'thrilling', 'or', 'even', 'engaging', ',', 'in', 'the', 'meantime', '?', 'not', 'really', '.', 'the', 'sad', 'part', 'is', 'that', 'the', 'arrow', 'and', 'i', 'both', 'dig', 'on', 'flicks', 'like', 'this', ',', 'so', 'we', 'actually', 'figured', 'most', 'of', 'it', 'out', 'by', 'the', 'half', '-', 'way', 'point', ',', 'so', 'all', 'of', 'the', 'strangeness', 'after', 'that', 'did', 'start', 'to', 'make', 'a', 'little', 'bit', 'of', 'sense', ',', 'but', 'it', 'still', 'didn', \"'\", 't', 'the', 'make', 'the', 'film', 'all', 'that', 'more', 'entertaining', '.', 'i', 'guess', 'the', 'bottom', 'line', 'with', 'movies', 'like', 'this', 'is', 'that', 'you', 'should', 'always', 'make', 'sure', 'that', 'the', 'audience', 'is', '\"', 'into', 'it', '\"', 'even', 'before', 'they', 'are', 'given', 'the', 'secret', 'password', 'to', 'enter', 'your', 'world', 'of', 'understanding', '.', 'i', 'mean', ',', 'showing', 'melissa', 'sagemiller', 'running', 'away', 'from', 'visions', 'for', 'about', '20', 'minutes', 'throughout', 'the', 'movie', 'is', 'just', 'plain', 'lazy', '!', '!', 'okay', ',', 'we', 'get', 'it', '.', '.', '.', 'there', 'are', 'people', 'chasing', 'her', 'and', 'we', 'don', \"'\", 't', 'know', 'who', 'they', 'are', '.', 'do', 'we', 'really', 'need', 'to', 'see', 'it', 'over', 'and', 'over', 'again', '?', 'how', 'about', 'giving', 'us', 'different', 'scenes', 'offering', 'further', 'insight', 'into', 'all', 'of', 'the', 'strangeness', 'going', 'down', 'in', 'the', 'movie', '?', 'apparently', ',', 'the', 'studio', 'took', 'this', 'film', 'away', 'from', 'its', 'director', 'and', 'chopped', 'it', 'up', 'themselves', ',', 'and', 'it', 'shows', '.', 'there', 'might', \"'\", 've', 'been', 'a', 'pretty', 'decent', 'teen', 'mind', '-', 'fuck', 'movie', 'in', 'here', 'somewhere', ',', 'but', 'i', 'guess', '\"', 'the', 'suits', '\"', 'decided', 'that', 'turning', 'it', 'into', 'a', 'music', 'video', 'with', 'little', 'edge', ',', 'would', 'make', 'more', 'sense', '.', 'the', 'actors', 'are', 'pretty', 'good', 'for', 'the', 'most', 'part', ',', 'although', 'wes', 'bentley', 'just', 'seemed', 'to', 'be', 'playing', 'the', 'exact', 'same', 'character', 'that', 'he', 'did', 'in', 'american', 'beauty', ',', 'only', 'in', 'a', 'new', 'neighborhood', '.', 'but', 'my', 'biggest', 'kudos', 'go', 'out', 'to', 'sagemiller', ',', 'who', 'holds', 'her', 'own', 'throughout', 'the', 'entire', 'film', ',', 'and', 'actually', 'has', 'you', 'feeling', 'her', 'character', \"'\", 's', 'unraveling', '.', 'overall', ',', 'the', 'film', 'doesn', \"'\", 't', 'stick', 'because', 'it', 'doesn', \"'\", 't', 'entertain', ',', 'it', \"'\", 's', 'confusing', ',', 'it', 'rarely', 'excites', 'and', 'it', 'feels', 'pretty', 'redundant', 'for', 'most', 'of', 'its', 'runtime', ',', 'despite', 'a', 'pretty', 'cool', 'ending', 'and', 'explanation', 'to', 'all', 'of', 'the', 'craziness', 'that', 'came', 'before', 'it', '.', 'oh', ',', 'and', 'by', 'the', 'way', ',', 'this', 'is', 'not', 'a', 'horror', 'or', 'teen', 'slasher', 'flick', '.', '.', '.', 'it', \"'\", 's', 'just', 'packaged', 'to', 'look', 'that', 'way', 'because', 'someone', 'is', 'apparently', 'assuming', 'that', 'the', 'genre', 'is', 'still', 'hot', 'with', 'the', 'kids', '.', 'it', 'also', 'wrapped', 'production', 'two', 'years', 'ago', 'and', 'has', 'been', 'sitting', 'on', 'the', 'shelves', 'ever', 'since', '.', 'whatever', '.', '.', '.', 'skip', 'it', '!', 'where', \"'\", 's', 'joblo', 'coming', 'from', '?', 'a', 'nightmare', 'of', 'elm', 'street', '3', '(', '7', '/', '10', ')', '-', 'blair', 'witch', '2', '(', '7', '/', '10', ')', '-', 'the', 'crow', '(', '9', '/', '10', ')', '-', 'the', 'crow', ':', 'salvation', '(', '4', '/', '10', ')', '-', 'lost', 'highway', '(', '10', '/', '10', ')', '-', 'memento', '(', '10', '/', '10', ')', '-', 'the', 'others', '(', '9', '/', '10', ')', '-', 'stir', 'of', 'echoes', '(', '8', '/', '10', ')'], 'neg')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Shuffle documents \n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# shuffle first \r\n",
    "random.shuffle(documents) # it is inplace method\r\n",
    "documents= documents[:500] # reduce the data set for speed up the demo \r\n",
    "len (documents)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Vectorize documents \n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def find_features(review_tokens):\r\n",
    "    return {w: w in set(review_tokens) for w in word_features} # feature representation on document\r\n",
    "\r\n",
    "data_set= [(find_features(review_tokens), category) for (review_tokens, category) in documents]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "data_set[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "({'film': True,\n",
       "  'one': False,\n",
       "  'movie': True,\n",
       "  'like': True,\n",
       "  'even': True,\n",
       "  'good': True,\n",
       "  'time': True,\n",
       "  'story': False,\n",
       "  'would': False,\n",
       "  'much': True,\n",
       "  'character': True,\n",
       "  'also': False,\n",
       "  'get': True,\n",
       "  'two': True,\n",
       "  'well': False,\n",
       "  'characters': False,\n",
       "  'first': True,\n",
       "  'see': True,\n",
       "  'way': False,\n",
       "  'make': False,\n",
       "  'life': True,\n",
       "  'really': False,\n",
       "  'films': True,\n",
       "  'plot': False,\n",
       "  'little': True,\n",
       "  'people': True,\n",
       "  'could': True,\n",
       "  'scene': False,\n",
       "  'man': False,\n",
       "  'bad': False,\n",
       "  'never': True,\n",
       "  'best': False,\n",
       "  'new': False,\n",
       "  'scenes': True,\n",
       "  'many': True,\n",
       "  'director': True,\n",
       "  'know': False,\n",
       "  'movies': False,\n",
       "  'action': False,\n",
       "  'great': True,\n",
       "  'another': False,\n",
       "  'love': False,\n",
       "  'go': False,\n",
       "  'made': True,\n",
       "  'us': False,\n",
       "  'big': False,\n",
       "  'end': True,\n",
       "  'something': False,\n",
       "  'back': True,\n",
       "  'still': False,\n",
       "  'world': True,\n",
       "  'seems': False,\n",
       "  'work': True,\n",
       "  'makes': True,\n",
       "  'however': False,\n",
       "  'every': False,\n",
       "  'though': True,\n",
       "  'better': True,\n",
       "  'real': True,\n",
       "  'audience': False,\n",
       "  'enough': True,\n",
       "  'seen': False,\n",
       "  'take': False,\n",
       "  'around': False,\n",
       "  'going': False,\n",
       "  'year': False,\n",
       "  'performance': False,\n",
       "  'role': True,\n",
       "  'old': False,\n",
       "  'gets': False,\n",
       "  'may': True,\n",
       "  'things': True,\n",
       "  'think': False,\n",
       "  'years': True,\n",
       "  'last': False,\n",
       "  'comedy': False,\n",
       "  'funny': False,\n",
       "  'actually': True,\n",
       "  'long': True,\n",
       "  'look': False,\n",
       "  'almost': True,\n",
       "  'thing': False,\n",
       "  'fact': True,\n",
       "  'nothing': False,\n",
       "  'say': False,\n",
       "  'right': True,\n",
       "  'john': False,\n",
       "  'although': False,\n",
       "  'played': False,\n",
       "  'find': False,\n",
       "  'script': False,\n",
       "  'come': False,\n",
       "  'ever': False,\n",
       "  'cast': False,\n",
       "  'since': True,\n",
       "  'star': True,\n",
       "  'plays': False,\n",
       "  'young': False,\n",
       "  'show': False,\n",
       "  'comes': True,\n",
       "  'part': False,\n",
       "  'original': False,\n",
       "  'actors': True,\n",
       "  'screen': False,\n",
       "  'without': False,\n",
       "  'acting': False,\n",
       "  'three': False,\n",
       "  'day': True,\n",
       "  'point': True,\n",
       "  'lot': True,\n",
       "  'least': False,\n",
       "  'takes': True,\n",
       "  'guy': True,\n",
       "  'quite': False,\n",
       "  'away': True,\n",
       "  'family': False,\n",
       "  'effects': False,\n",
       "  'course': False,\n",
       "  'goes': True,\n",
       "  'minutes': False,\n",
       "  'interesting': True,\n",
       "  'might': False,\n",
       "  'far': False,\n",
       "  'high': True,\n",
       "  'rather': False,\n",
       "  'must': True,\n",
       "  'anything': True,\n",
       "  'place': False,\n",
       "  'set': False,\n",
       "  'yet': False,\n",
       "  'watch': False,\n",
       "  'making': False,\n",
       "  'wife': True,\n",
       "  'hard': False,\n",
       "  'always': True,\n",
       "  'fun': False,\n",
       "  'seem': False,\n",
       "  'special': False,\n",
       "  'bit': False,\n",
       "  'times': False,\n",
       "  'trying': False,\n",
       "  'hollywood': False,\n",
       "  'instead': True,\n",
       "  'give': False,\n",
       "  'want': False,\n",
       "  'picture': False,\n",
       "  'kind': False,\n",
       "  'american': False,\n",
       "  'job': True,\n",
       "  'sense': True,\n",
       "  'woman': False,\n",
       "  'home': False,\n",
       "  'series': False,\n",
       "  'actor': False,\n",
       "  'probably': True,\n",
       "  'help': False,\n",
       "  'half': False,\n",
       "  'along': False,\n",
       "  'men': True,\n",
       "  'everything': True,\n",
       "  'pretty': False,\n",
       "  'becomes': False,\n",
       "  'sure': False,\n",
       "  'black': False,\n",
       "  'together': False,\n",
       "  'dialogue': False,\n",
       "  'money': False,\n",
       "  'become': True,\n",
       "  'gives': False,\n",
       "  'given': False,\n",
       "  'looking': False,\n",
       "  'whole': False,\n",
       "  'watching': False,\n",
       "  'father': False,\n",
       "  'feel': False,\n",
       "  'everyone': False,\n",
       "  'music': False,\n",
       "  'wants': False,\n",
       "  'sex': False,\n",
       "  'less': False,\n",
       "  'done': True,\n",
       "  'horror': False,\n",
       "  'got': True,\n",
       "  'death': False,\n",
       "  'perhaps': False,\n",
       "  'city': False,\n",
       "  'next': True,\n",
       "  'especially': False,\n",
       "  'play': False,\n",
       "  'girl': False,\n",
       "  'mind': False,\n",
       "  '10': False,\n",
       "  'moments': False,\n",
       "  'looks': False,\n",
       "  'completely': False,\n",
       "  '2': False,\n",
       "  'reason': False,\n",
       "  'mother': False,\n",
       "  'whose': False,\n",
       "  'line': False,\n",
       "  'night': False,\n",
       "  'human': True,\n",
       "  'rest': False,\n",
       "  'performances': False,\n",
       "  'different': False,\n",
       "  'evil': False,\n",
       "  'small': False,\n",
       "  'james': True,\n",
       "  'simply': False,\n",
       "  'couple': False,\n",
       "  'put': True,\n",
       "  'let': False,\n",
       "  'anyone': False,\n",
       "  'ending': True,\n",
       "  'case': False,\n",
       "  'several': False,\n",
       "  'dead': False,\n",
       "  'michael': True,\n",
       "  'left': True,\n",
       "  'thought': False,\n",
       "  'school': False,\n",
       "  'shows': False,\n",
       "  'humor': False,\n",
       "  'true': False,\n",
       "  'lost': False,\n",
       "  'written': True,\n",
       "  'friend': False,\n",
       "  'entire': False,\n",
       "  'getting': False,\n",
       "  'town': True,\n",
       "  'turns': False,\n",
       "  'soon': False,\n",
       "  'someone': False,\n",
       "  'second': True,\n",
       "  'main': False,\n",
       "  'stars': False,\n",
       "  'found': False,\n",
       "  'use': False,\n",
       "  'problem': True,\n",
       "  'friends': False,\n",
       "  'tv': False,\n",
       "  'top': False,\n",
       "  'name': False,\n",
       "  'begins': False,\n",
       "  'called': False,\n",
       "  'based': False,\n",
       "  'comic': False,\n",
       "  'david': False,\n",
       "  'head': False,\n",
       "  'else': False,\n",
       "  'idea': False,\n",
       "  'either': False,\n",
       "  'wrong': False,\n",
       "  'unfortunately': False,\n",
       "  'later': False,\n",
       "  'final': False,\n",
       "  'hand': False,\n",
       "  'alien': False,\n",
       "  'house': True,\n",
       "  'group': False,\n",
       "  'full': False,\n",
       "  'used': False,\n",
       "  'tries': False,\n",
       "  'often': False,\n",
       "  'war': False,\n",
       "  'sequence': False,\n",
       "  'keep': False,\n",
       "  'turn': False,\n",
       "  'playing': True,\n",
       "  'boy': False,\n",
       "  'behind': False,\n",
       "  'named': False,\n",
       "  'certainly': True,\n",
       "  'live': True,\n",
       "  'believe': False,\n",
       "  'works': True,\n",
       "  'relationship': False,\n",
       "  'face': True,\n",
       "  'hour': False,\n",
       "  'run': False,\n",
       "  'style': False,\n",
       "  'said': False,\n",
       "  'despite': False,\n",
       "  'person': False,\n",
       "  'finally': False,\n",
       "  'shot': False,\n",
       "  'book': True,\n",
       "  'tell': False,\n",
       "  'maybe': False,\n",
       "  'nice': False,\n",
       "  'son': False,\n",
       "  'perfect': False,\n",
       "  'side': False,\n",
       "  'seeing': False,\n",
       "  'able': False,\n",
       "  'finds': False,\n",
       "  'children': False,\n",
       "  'days': False,\n",
       "  'past': True,\n",
       "  'summer': False,\n",
       "  'camera': False,\n",
       "  'including': False,\n",
       "  'mr': False,\n",
       "  'kids': False,\n",
       "  'lives': False,\n",
       "  'directed': False,\n",
       "  'moment': False,\n",
       "  'game': False,\n",
       "  'running': False,\n",
       "  'fight': False,\n",
       "  'supposed': False,\n",
       "  'video': False,\n",
       "  'car': False,\n",
       "  'matter': True,\n",
       "  'kevin': False,\n",
       "  'joe': False,\n",
       "  'lines': False,\n",
       "  'worth': False,\n",
       "  'daughter': False,\n",
       "  'earth': False,\n",
       "  'starts': False,\n",
       "  'need': False,\n",
       "  'entertaining': False,\n",
       "  'white': False,\n",
       "  'start': False,\n",
       "  'writer': True,\n",
       "  'dark': False,\n",
       "  'short': True,\n",
       "  'self': False,\n",
       "  'worst': False,\n",
       "  'nearly': False,\n",
       "  'opening': False,\n",
       "  'try': False,\n",
       "  'upon': False,\n",
       "  'care': False,\n",
       "  'early': True,\n",
       "  'violence': False,\n",
       "  'throughout': False,\n",
       "  'team': False,\n",
       "  'production': False,\n",
       "  'example': False,\n",
       "  'beautiful': False,\n",
       "  'title': False,\n",
       "  'exactly': False,\n",
       "  'jack': False,\n",
       "  'review': False,\n",
       "  'major': True,\n",
       "  'drama': False,\n",
       "  'problems': False,\n",
       "  'sequences': False,\n",
       "  'obvious': False,\n",
       "  'version': False,\n",
       "  'screenplay': False,\n",
       "  'known': False,\n",
       "  'killer': False,\n",
       "  'robert': True,\n",
       "  'disney': False,\n",
       "  'already': False,\n",
       "  'close': False,\n",
       "  'classic': False,\n",
       "  'others': True,\n",
       "  'hit': True,\n",
       "  'kill': False,\n",
       "  'deep': False,\n",
       "  'five': False,\n",
       "  'order': False,\n",
       "  'act': False,\n",
       "  'simple': False,\n",
       "  'fine': False,\n",
       "  'heart': False,\n",
       "  'roles': False,\n",
       "  'jackie': False,\n",
       "  'direction': False,\n",
       "  'eyes': False,\n",
       "  'four': False,\n",
       "  'question': True,\n",
       "  'sort': False,\n",
       "  'sometimes': True,\n",
       "  'knows': True,\n",
       "  'supporting': False,\n",
       "  'coming': False,\n",
       "  'voice': False,\n",
       "  'women': True,\n",
       "  'truly': False,\n",
       "  'save': False,\n",
       "  'jokes': False,\n",
       "  'computer': True,\n",
       "  'child': False,\n",
       "  'boring': False,\n",
       "  'tom': False,\n",
       "  'level': False,\n",
       "  '1': False,\n",
       "  'body': False,\n",
       "  'guys': False,\n",
       "  'genre': False,\n",
       "  'brother': False,\n",
       "  'strong': False,\n",
       "  'stop': False,\n",
       "  'room': True,\n",
       "  'space': False,\n",
       "  'lee': False,\n",
       "  'ends': False,\n",
       "  'beginning': False,\n",
       "  'ship': False,\n",
       "  'york': False,\n",
       "  'attempt': False,\n",
       "  'thriller': False,\n",
       "  'scream': False,\n",
       "  'peter': True,\n",
       "  'husband': False,\n",
       "  'fiction': False,\n",
       "  'happens': False,\n",
       "  'hero': False,\n",
       "  'novel': False,\n",
       "  'note': False,\n",
       "  'hope': False,\n",
       "  'king': False,\n",
       "  'yes': False,\n",
       "  'says': False,\n",
       "  'tells': False,\n",
       "  'quickly': False,\n",
       "  'romantic': False,\n",
       "  'dog': True,\n",
       "  'oscar': False,\n",
       "  'stupid': False,\n",
       "  'possible': False,\n",
       "  'saw': False,\n",
       "  'lead': False,\n",
       "  'career': True,\n",
       "  'murder': False,\n",
       "  'extremely': False,\n",
       "  'manages': False,\n",
       "  'god': False,\n",
       "  'mostly': False,\n",
       "  'wonder': False,\n",
       "  'particularly': True,\n",
       "  'future': False,\n",
       "  'fans': False,\n",
       "  'sound': False,\n",
       "  'worse': False,\n",
       "  'piece': True,\n",
       "  'involving': False,\n",
       "  'de': False,\n",
       "  'appears': False,\n",
       "  'planet': False,\n",
       "  'paul': False,\n",
       "  'involved': False,\n",
       "  'mean': False,\n",
       "  'none': False,\n",
       "  'taking': False,\n",
       "  'hours': False,\n",
       "  'laugh': False,\n",
       "  'police': False,\n",
       "  'sets': False,\n",
       "  'attention': True,\n",
       "  'co': False,\n",
       "  'hell': False,\n",
       "  'eventually': True,\n",
       "  'single': False,\n",
       "  'fall': False,\n",
       "  'falls': False,\n",
       "  'material': False,\n",
       "  'emotional': False,\n",
       "  'power': False,\n",
       "  'late': False,\n",
       "  'lack': False,\n",
       "  'dr': False,\n",
       "  'van': False,\n",
       "  'result': False,\n",
       "  'elements': False,\n",
       "  'meet': False,\n",
       "  'smith': False,\n",
       "  'science': False,\n",
       "  'experience': False,\n",
       "  'bring': True,\n",
       "  'wild': False,\n",
       "  'living': False,\n",
       "  'theater': False,\n",
       "  'interest': False,\n",
       "  'leads': False,\n",
       "  'word': False,\n",
       "  'feature': False,\n",
       "  'battle': False,\n",
       "  'girls': False,\n",
       "  'alone': False,\n",
       "  'obviously': False,\n",
       "  'george': False,\n",
       "  'within': False,\n",
       "  'usually': False,\n",
       "  'enjoy': False,\n",
       "  'guess': False,\n",
       "  'among': False,\n",
       "  'taken': False,\n",
       "  'feeling': False,\n",
       "  'laughs': False,\n",
       "  'aliens': False,\n",
       "  'talk': False,\n",
       "  'chance': False,\n",
       "  'talent': False,\n",
       "  '3': True,\n",
       "  'middle': False,\n",
       "  'number': False,\n",
       "  'easy': False,\n",
       "  'across': False,\n",
       "  'needs': True,\n",
       "  'attempts': False,\n",
       "  'happen': False,\n",
       "  'television': False,\n",
       "  'chris': False,\n",
       "  'deal': False,\n",
       "  'poor': False,\n",
       "  'form': False,\n",
       "  'girlfriend': True,\n",
       "  'viewer': False,\n",
       "  'release': False,\n",
       "  'killed': False,\n",
       "  'forced': True,\n",
       "  'whether': False,\n",
       "  'wonderful': False,\n",
       "  'feels': False,\n",
       "  'oh': False,\n",
       "  'tale': False,\n",
       "  'serious': False,\n",
       "  'expect': True,\n",
       "  'except': False,\n",
       "  'light': False,\n",
       "  'success': False,\n",
       "  'features': False,\n",
       "  'premise': False,\n",
       "  'happy': False,\n",
       "  'words': False,\n",
       "  'leave': False,\n",
       "  'important': False,\n",
       "  'meets': False,\n",
       "  'history': False,\n",
       "  'giving': False,\n",
       "  'crew': False,\n",
       "  'type': True,\n",
       "  'call': False,\n",
       "  'turned': False,\n",
       "  'released': False,\n",
       "  'parents': False,\n",
       "  'art': True,\n",
       "  'impressive': False,\n",
       "  'mission': False,\n",
       "  'working': True,\n",
       "  'seemed': False,\n",
       "  'score': False,\n",
       "  'told': False,\n",
       "  'recent': False,\n",
       "  'robin': False,\n",
       "  'basically': False,\n",
       "  'entertainment': False,\n",
       "  'america': False,\n",
       "  'surprise': False,\n",
       "  'apparently': False,\n",
       "  'easily': False,\n",
       "  'ryan': False,\n",
       "  'cool': False,\n",
       "  'stuff': False,\n",
       "  'cop': False,\n",
       "  'change': False,\n",
       "  'williams': False,\n",
       "  'crime': False,\n",
       "  'office': False,\n",
       "  'parts': False,\n",
       "  'somehow': False,\n",
       "  'sequel': False,\n",
       "  'william': False,\n",
       "  'cut': False,\n",
       "  'die': False,\n",
       "  'jones': False,\n",
       "  'credits': False,\n",
       "  'batman': False,\n",
       "  'suspense': False,\n",
       "  'brings': False,\n",
       "  'events': False,\n",
       "  'reality': False,\n",
       "  'local': False,\n",
       "  'talking': False,\n",
       "  'difficult': True,\n",
       "  'using': False,\n",
       "  'went': False,\n",
       "  'writing': False,\n",
       "  'remember': False,\n",
       "  'near': False,\n",
       "  'straight': False,\n",
       "  'hilarious': False,\n",
       "  'ago': True,\n",
       "  'certain': False,\n",
       "  'ben': False,\n",
       "  'kid': False,\n",
       "  'slow': False,\n",
       "  'blood': False,\n",
       "  'mystery': False,\n",
       "  'complete': False,\n",
       "  'red': False,\n",
       "  'popular': False,\n",
       "  'effective': False,\n",
       "  'fast': False,\n",
       "  'flick': False,\n",
       "  'due': False,\n",
       "  'runs': False,\n",
       "  'gone': False,\n",
       "  'return': False,\n",
       "  'presence': False,\n",
       "  'quality': False,\n",
       "  'dramatic': False,\n",
       "  'filmmakers': False,\n",
       "  'age': True,\n",
       "  'brothers': False,\n",
       "  'business': False,\n",
       "  'general': False,\n",
       "  'rock': False,\n",
       "  'sexual': False,\n",
       "  'present': False,\n",
       "  'surprisingly': False,\n",
       "  'anyway': False,\n",
       "  'uses': False,\n",
       "  '4': False,\n",
       "  'personal': False,\n",
       "  'figure': False,\n",
       "  'smart': False,\n",
       "  'ways': False,\n",
       "  'decides': False,\n",
       "  'annoying': False,\n",
       "  'begin': False,\n",
       "  'somewhat': False,\n",
       "  'shots': False,\n",
       "  'rich': False,\n",
       "  'minute': False,\n",
       "  'law': False,\n",
       "  'previous': False,\n",
       "  'jim': False,\n",
       "  'successful': False,\n",
       "  'harry': False,\n",
       "  'water': False,\n",
       "  'similar': False,\n",
       "  'absolutely': False,\n",
       "  'motion': False,\n",
       "  'former': False,\n",
       "  'strange': False,\n",
       "  'came': False,\n",
       "  'follow': False,\n",
       "  'read': False,\n",
       "  'project': False,\n",
       "  'million': False,\n",
       "  'secret': False,\n",
       "  'starring': False,\n",
       "  'clear': False,\n",
       "  'familiar': False,\n",
       "  'romance': False,\n",
       "  'intelligent': False,\n",
       "  'third': False,\n",
       "  'excellent': False,\n",
       "  'amazing': False,\n",
       "  'party': False,\n",
       "  'budget': False,\n",
       "  'eye': False,\n",
       "  'actress': False,\n",
       "  'prison': False,\n",
       "  'latest': False,\n",
       "  'means': False,\n",
       "  'company': False,\n",
       "  'towards': False,\n",
       "  'predictable': False,\n",
       "  'powerful': False,\n",
       "  'bob': False,\n",
       "  'beyond': False,\n",
       "  'visual': False,\n",
       "  'leaves': False,\n",
       "  'r': False,\n",
       "  'nature': False,\n",
       "  'following': False,\n",
       "  'villain': False,\n",
       "  'leaving': False,\n",
       "  'animated': False,\n",
       "  'low': False,\n",
       "  'b': False,\n",
       "  'bill': False,\n",
       "  'sam': False,\n",
       "  'filled': False,\n",
       "  'wars': False,\n",
       "  'questions': False,\n",
       "  'cinema': False,\n",
       "  'message': False,\n",
       "  'box': False,\n",
       "  'moving': False,\n",
       "  'country': False,\n",
       "  'usual': False,\n",
       "  'martin': False,\n",
       "  'definitely': False,\n",
       "  'add': False,\n",
       "  'large': False,\n",
       "  'clever': False,\n",
       "  'create': False,\n",
       "  'felt': False,\n",
       "  'stories': False,\n",
       "  'brilliant': False,\n",
       "  'ones': False,\n",
       "  'giant': False,\n",
       "  'situation': False,\n",
       "  'murphy': False,\n",
       "  'break': False,\n",
       "  'opens': False,\n",
       "  'scary': False,\n",
       "  'doubt': False,\n",
       "  'drug': False,\n",
       "  'bunch': False,\n",
       "  'thinking': False,\n",
       "  'solid': False,\n",
       "  'effect': False,\n",
       "  'learn': False,\n",
       "  'move': False,\n",
       "  'force': False,\n",
       "  'potential': False,\n",
       "  'seriously': False,\n",
       "  'follows': False,\n",
       "  'saying': False,\n",
       "  'huge': True,\n",
       "  'class': False,\n",
       "  'plan': False,\n",
       "  'agent': True,\n",
       "  'created': False,\n",
       "  'unlike': False,\n",
       "  'pay': False,\n",
       "  'non': True,\n",
       "  'married': True,\n",
       "  'mark': False,\n",
       "  'sweet': False,\n",
       "  'perfectly': True,\n",
       "  'ex': False,\n",
       "  'realize': False,\n",
       "  'audiences': False,\n",
       "  'took': False,\n",
       "  'decent': False,\n",
       "  'likely': False,\n",
       "  'dream': False,\n",
       "  'view': False,\n",
       "  'scott': False,\n",
       "  'subject': False,\n",
       "  'understand': True,\n",
       "  'happened': False,\n",
       "  'enjoyable': False,\n",
       "  'studio': False,\n",
       "  'immediately': False,\n",
       "  'open': False,\n",
       "  'e': False,\n",
       "  'points': False,\n",
       "  'heard': False,\n",
       "  'viewers': False,\n",
       "  'cameron': False,\n",
       "  'truman': False,\n",
       "  'bruce': False,\n",
       "  'frank': False,\n",
       "  'private': False,\n",
       "  'stay': False,\n",
       "  'fails': False,\n",
       "  'impossible': False,\n",
       "  'cold': False,\n",
       "  'richard': False,\n",
       "  'overall': False,\n",
       "  'merely': True,\n",
       "  'exciting': False,\n",
       "  'mess': False,\n",
       "  'chase': False,\n",
       "  'free': False,\n",
       "  'ten': False,\n",
       "  'neither': True,\n",
       "  'wanted': False,\n",
       "  'gun': False,\n",
       "  'appear': False,\n",
       "  'carter': False,\n",
       "  'escape': False,\n",
       "  'ultimately': False,\n",
       "  'fan': False,\n",
       "  'inside': False,\n",
       "  'favorite': False,\n",
       "  'modern': False,\n",
       "  'l': True,\n",
       "  'wedding': True,\n",
       "  'stone': False,\n",
       "  'trek': False,\n",
       "  'brought': False,\n",
       "  'trouble': False,\n",
       "  'otherwise': False,\n",
       "  'tim': False,\n",
       "  '5': False,\n",
       "  'allen': False,\n",
       "  'bond': False,\n",
       "  'society': False,\n",
       "  'liked': False,\n",
       "  'dumb': False,\n",
       "  'musical': False,\n",
       "  'stand': False,\n",
       "  'political': False,\n",
       "  'various': False,\n",
       "  'talented': False,\n",
       "  'particular': False,\n",
       "  'west': False,\n",
       "  'state': False,\n",
       "  'keeps': False,\n",
       "  'english': True,\n",
       "  'silly': False,\n",
       "  'u': False,\n",
       "  'situations': False,\n",
       "  'park': False,\n",
       "  'teen': False,\n",
       "  'rating': False,\n",
       "  'slightly': False,\n",
       "  'steve': False,\n",
       "  'truth': True,\n",
       "  'air': False,\n",
       "  'element': False,\n",
       "  'joke': False,\n",
       "  'spend': False,\n",
       "  'key': False,\n",
       "  'biggest': False,\n",
       "  'members': False,\n",
       "  'effort': False,\n",
       "  'government': False,\n",
       "  'focus': False,\n",
       "  'eddie': False,\n",
       "  'soundtrack': False,\n",
       "  'hands': False,\n",
       "  'earlier': False,\n",
       "  'chan': False,\n",
       "  'purpose': False,\n",
       "  'today': False,\n",
       "  'showing': False,\n",
       "  'memorable': False,\n",
       "  'six': True,\n",
       "  'cannot': False,\n",
       "  'max': False,\n",
       "  'offers': False,\n",
       "  'rated': False,\n",
       "  'mars': False,\n",
       "  'heavy': False,\n",
       "  'totally': False,\n",
       "  'control': False,\n",
       "  'credit': False,\n",
       "  'fi': False,\n",
       "  'woody': False,\n",
       "  'ideas': False,\n",
       "  'sci': False,\n",
       "  'wait': False,\n",
       "  'sit': False,\n",
       "  'female': False,\n",
       "  'ask': False,\n",
       "  'waste': False,\n",
       "  'terrible': False,\n",
       "  'depth': False,\n",
       "  'simon': False,\n",
       "  'aspect': False,\n",
       "  'list': False,\n",
       "  'mary': False,\n",
       "  'sister': False,\n",
       "  'animation': False,\n",
       "  'entirely': False,\n",
       "  'fear': False,\n",
       "  'steven': False,\n",
       "  'moves': False,\n",
       "  'actual': False,\n",
       "  'army': False,\n",
       "  'british': False,\n",
       "  'constantly': False,\n",
       "  'fire': False,\n",
       "  'convincing': True,\n",
       "  'setting': False,\n",
       "  'gave': False,\n",
       "  'tension': False,\n",
       "  'street': False,\n",
       "  '8': False,\n",
       "  'brief': False,\n",
       "  'ridiculous': False,\n",
       "  'cinematography': False,\n",
       "  'typical': False,\n",
       "  'nick': False,\n",
       "  'screenwriter': False,\n",
       "  'ability': False,\n",
       "  'spent': False,\n",
       "  'quick': False,\n",
       "  'violent': False,\n",
       "  'atmosphere': False,\n",
       "  'subtle': False,\n",
       "  'expected': False,\n",
       "  'fairly': False,\n",
       "  'seven': True,\n",
       "  'killing': False,\n",
       "  'tone': False,\n",
       "  'master': True,\n",
       "  'disaster': False,\n",
       "  'lots': False,\n",
       "  'thinks': False,\n",
       "  'song': False,\n",
       "  'cheap': False,\n",
       "  'suddenly': False,\n",
       "  'background': False,\n",
       "  'club': False,\n",
       "  'willis': False,\n",
       "  'whatever': False,\n",
       "  'highly': False,\n",
       "  'sees': False,\n",
       "  'complex': False,\n",
       "  'greatest': False,\n",
       "  'impact': False,\n",
       "  'beauty': False,\n",
       "  'front': False,\n",
       "  'humans': False,\n",
       "  'indeed': False,\n",
       "  'flat': False,\n",
       "  'grace': False,\n",
       "  'wrote': False,\n",
       "  'amusing': False,\n",
       "  'ii': False,\n",
       "  'mike': False,\n",
       "  'cute': False,\n",
       "  'dull': False,\n",
       "  'minor': False,\n",
       "  'recently': False,\n",
       "  'hate': False,\n",
       "  'outside': False,\n",
       "  'plenty': False,\n",
       "  'wish': False,\n",
       "  'godzilla': False,\n",
       "  'college': True,\n",
       "  'titanic': False,\n",
       "  'sounds': False,\n",
       "  'telling': False,\n",
       "  'sight': True,\n",
       "  'double': False,\n",
       "  'cinematic': False,\n",
       "  'queen': False,\n",
       "  'hold': False,\n",
       "  'meanwhile': False,\n",
       "  'awful': False,\n",
       "  'clearly': False,\n",
       "  'theme': False,\n",
       "  'hear': False,\n",
       "  'x': False,\n",
       "  'amount': False,\n",
       "  'baby': False,\n",
       "  'approach': False,\n",
       "  'dreams': False,\n",
       "  'shown': False,\n",
       "  'island': False,\n",
       "  'reasons': False,\n",
       "  'charm': False,\n",
       "  'miss': False,\n",
       "  'longer': False,\n",
       "  'common': False,\n",
       "  'sean': False,\n",
       "  'carry': False,\n",
       "  'believable': False,\n",
       "  'realistic': False,\n",
       "  'chemistry': True,\n",
       "  'possibly': False,\n",
       "  'casting': False,\n",
       "  'carrey': False,\n",
       "  'french': False,\n",
       "  'trailer': False,\n",
       "  'tough': False,\n",
       "  'produced': False,\n",
       "  'imagine': False,\n",
       "  'choice': True,\n",
       "  'ride': False,\n",
       "  'somewhere': False,\n",
       "  'hot': False,\n",
       "  'race': False,\n",
       "  'road': False,\n",
       "  'leader': False,\n",
       "  'thin': False,\n",
       "  'jerry': False,\n",
       "  'slowly': False,\n",
       "  'delivers': False,\n",
       "  'detective': False,\n",
       "  'brown': False,\n",
       "  'jackson': False,\n",
       "  'member': False,\n",
       "  'provide': False,\n",
       "  'president': False,\n",
       "  'puts': False,\n",
       "  'asks': False,\n",
       "  'critics': False,\n",
       "  'appearance': False,\n",
       "  'famous': False,\n",
       "  'okay': False,\n",
       "  'intelligence': False,\n",
       "  'energy': False,\n",
       "  'sent': False,\n",
       "  'spielberg': False,\n",
       "  'development': False,\n",
       "  'etc': False,\n",
       "  'language': False,\n",
       "  'blue': False,\n",
       "  'proves': False,\n",
       "  'vampire': False,\n",
       "  'seemingly': False,\n",
       "  'basic': False,\n",
       "  'caught': True,\n",
       "  ...},\n",
       " 'pos')"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Split to training and test set\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "split_on = int(len(data_set)*.8)\r\n",
    "X_y_train= data_set[:split_on]\r\n",
    "X_y_test = data_set[split_on:]\r\n",
    "print (len(X_y_train))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "400\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Train model\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "clf= nltk.NaiveBayesClassifier.train(X_y_train) # Note: the difference grammar comparing with sklearn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Evaluate model\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "nltk.classify.accuracy(clf, X_y_test)*100"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "72.0"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Review most informative features\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "clf.show_most_informative_features(15)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most Informative Features\n",
      "               pointless = True              neg : pos    =     11.6 : 1.0\n",
      "                 unfunny = True              neg : pos    =      9.7 : 1.0\n",
      "             outstanding = True              pos : neg    =      9.6 : 1.0\n",
      "                   bland = True              neg : pos    =      8.5 : 1.0\n",
      "                    crap = True              neg : pos    =      8.5 : 1.0\n",
      "                  direct = True              neg : pos    =      8.5 : 1.0\n",
      "               promising = True              neg : pos    =      8.5 : 1.0\n",
      "                  finest = True              pos : neg    =      8.1 : 1.0\n",
      "                  superb = True              pos : neg    =      7.9 : 1.0\n",
      "                   badly = True              neg : pos    =      7.9 : 1.0\n",
      "                   drunk = True              neg : pos    =      7.9 : 1.0\n",
      "                 choices = True              pos : neg    =      7.4 : 1.0\n",
      "                   clich = True              neg : pos    =      7.2 : 1.0\n",
      "               community = True              pos : neg    =      6.7 : 1.0\n",
      "                    bore = True              neg : pos    =      6.6 : 1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "### Incorporate with sklearn\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier # this is wrapper to incorporate with sklearn using nltk style.\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "\r\n",
    "# Convert to nltk classifiers \r\n",
    "MNNB_classifier= SklearnClassifier(MultinomialNB()) # Note : use ()\r\n",
    "\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "lr_classifier = SklearnClassifier(LogisticRegression()) \r\n",
    "\r\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC # NuSVC - Similar to SVC but uses a parameter to control the number of support vectors.\r\n",
    "svc_clf = SklearnClassifier(SVC())  \r\n",
    "lin_svc_clf= SklearnClassifier(LinearSVC())  \r\n",
    "nu_svc_clf = SklearnClassifier(NuSVC())  \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# native nltk classifier\r\n",
    "clf= nltk.NaiveBayesClassifier.train(X_y_train) \r\n",
    "\r\n",
    "print('Accuracy nltk.NaiveBayesClassifier={}%'.format(nltk.classify.accuracy(clf,X_y_test) * 100))\r\n",
    "# clf.show_most_informative_features(15)\r\n",
    "\r\n",
    "MNNB_classifier.train(X_y_train)\r\n",
    "print('Accuracy MNNB_classifier ={}%'.format(nltk.classify.accuracy(MNNB_classifier, X_y_test) * 100)) # 79.0%\r\n",
    "\r\n",
    "lr_classifier.train(X_y_train)\r\n",
    "print('Accuracy lr_classifier ={}%'.format(nltk.classify.accuracy(lr_classifier, X_y_test) * 100)) # 82.0%\r\n",
    "\r\n",
    "svc_clf.train(X_y_train)\r\n",
    "print('Accuracy svc_clf={}%'.format(nltk.classify.accuracy(svc_clf, X_y_test) * 100)) # 52.0% - default is rbf kernel\r\n",
    "\r\n",
    "lin_svc_clf.train(X_y_train)\r\n",
    "print('Accuracy lin_svc_clf={}%'.format(nltk.classify.accuracy(lin_svc_clf, X_y_test) * 100)) # 82.0%\r\n",
    "\r\n",
    "nu_svc_clf.train(X_y_train)\r\n",
    "print('Accuracy nu_svc_clf={}%'.format(nltk.classify.accuracy(nu_svc_clf, X_y_test) * 100)) #\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy nltk.NaiveBayesClassifier=72.0%\n",
      "Accuracy MNNB_classifier =76.0%\n",
      "Accuracy lr_classifier =77.0%\n",
      "Accuracy svc_clf=76.0%\n",
      "Accuracy lin_svc_clf=78.0%\n",
      "Accuracy nu_svc_clf=78.0%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "### Combining algos with a vote\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "from nltk.classify import ClassifierI\r\n",
    "class Vote_Classifier(ClassifierI): # inherit\r\n",
    "    def __init__(self, *classifiers): # expecting list of classifiers\r\n",
    "        self.classifiers = classifiers\r\n",
    "\r\n",
    "    def classify(self, sample): \r\n",
    "        return mode([clf.classify(sample) for clf in self.classifiers]) \r\n",
    "\r\n",
    "    def calc_confidence(self, sample):\r\n",
    "        votes= [clf.classify(sample) for clf in self.classifiers] #\r\n",
    "        return votes.count(mode(votes))/len(votes) # fraction of how many votes match to mode to total votes number\r\n",
    "\r\n",
    "def mode(array): # returns first mode in case of multi modes\r\n",
    "    return max(set(array), key=array.count)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Explanation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "a= [3,3,1,2,2]\r\n",
    "mode(a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "a.count (mode(a))/len(a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "vote_clf= Vote_Classifier(clf, lr_classifier, svc_clf, lin_svc_clf, nu_svc_clf)\r\n",
    "print('Accuracy vote_clf={:.2%}'.format(nltk.classify.accuracy(vote_clf, X_y_test)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy vote_clf=78.00%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Classify new sample\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# https://timesofindia.indiatimes.com/entertainment/english/movie-reviews/cold-pursuit/movie-review/67892834.cms\r\n",
    "new_review = '''This unusual satire on gangsters and revenge stories, starts off with a quote from Oscar Wilde and some delightful background music that sets the tone for rest of the film. The first few minutes play out like a predictable thriller, featuring a wronged father and his pursuit for vigilante justice. But, what follows is a series of stylised killing sequences, that almost seem like parodies of action set pieces that youve seen Liam Neeson pulling off with deadpan ease in the past. Yet, director Hans Petter Noland, who also made the Norwegian film In Order Of Disappearance that inspired Cold Pursuit, and writer Frank Baldwin create a refreshing narrative full of memorable moments. The movie seems bizarrely funny and the snow-heavy setting creates the right atmosphere for the dry and cold-cut humour.\r\n",
    "The story begins with tragedy and the first few minutes seem dead serious, right up to the point where Coxman confronts his first victim, the gangster named Speedo. But, as the revenge-seeking father moves up the ranks of the mafia chain, the characters become quirky and the situations get thoroughly entertaining. The introduction of characters like Viking (Tom Bateman), the main antagonist and his team of crazy henchmen like Mustang, Dexter and more, alleviates the narrative. Theres also a track of warring mafia gangs as Viking wages a war against the native Indians led by White Bull (Tom Jackson). Cold Pursuit may not be too creative with the kill sequences, but it does get interesting with the wry sense of humour.\r\n",
    "Neeson does what he does best. He keeps a straight face and plays the game of intimidation with ease. Hes just a regular guy whos way out of his league, killing gangsters. But, his outrageous mission is what makes the story interesting. Watch out for a superb cameo by William Forsythe, too, who plays a brief but key role in Coxmans revenge saga.\r\n",
    "The way Cold Pursuit manages to blend sardonic humour with cold-blooded killings makes it reminiscent of movies like The Coen Brothers Fargo and Guy Ritchies Snatch. This ones a refreshingly cool black-comedy that does wonders for the genre.\r\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "x_new  = find_features(preprocess(new_review))\r\n",
    "x_new"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'film': True,\n",
       " 'one': True,\n",
       " 'movie': True,\n",
       " 'like': True,\n",
       " 'even': False,\n",
       " 'good': False,\n",
       " 'time': False,\n",
       " 'story': True,\n",
       " 'would': False,\n",
       " 'much': False,\n",
       " 'character': False,\n",
       " 'also': True,\n",
       " 'get': True,\n",
       " 'two': False,\n",
       " 'well': False,\n",
       " 'characters': True,\n",
       " 'first': True,\n",
       " 'see': False,\n",
       " 'way': True,\n",
       " 'make': False,\n",
       " 'life': False,\n",
       " 'really': False,\n",
       " 'films': False,\n",
       " 'plot': False,\n",
       " 'little': False,\n",
       " 'people': False,\n",
       " 'could': False,\n",
       " 'scene': False,\n",
       " 'man': False,\n",
       " 'bad': False,\n",
       " 'never': False,\n",
       " 'best': True,\n",
       " 'new': False,\n",
       " 'scenes': False,\n",
       " 'many': False,\n",
       " 'director': True,\n",
       " 'know': False,\n",
       " 'movies': True,\n",
       " 'action': True,\n",
       " 'great': False,\n",
       " 'another': False,\n",
       " 'love': False,\n",
       " 'go': False,\n",
       " 'made': True,\n",
       " 'us': False,\n",
       " 'big': False,\n",
       " 'end': False,\n",
       " 'something': False,\n",
       " 'back': False,\n",
       " 'still': False,\n",
       " 'world': False,\n",
       " 'seems': True,\n",
       " 'work': False,\n",
       " 'makes': True,\n",
       " 'however': False,\n",
       " 'every': False,\n",
       " 'though': False,\n",
       " 'better': False,\n",
       " 'real': False,\n",
       " 'audience': False,\n",
       " 'enough': False,\n",
       " 'seen': True,\n",
       " 'take': False,\n",
       " 'around': False,\n",
       " 'going': False,\n",
       " 'year': False,\n",
       " 'performance': False,\n",
       " 'role': True,\n",
       " 'old': False,\n",
       " 'gets': False,\n",
       " 'may': True,\n",
       " 'things': False,\n",
       " 'think': False,\n",
       " 'years': False,\n",
       " 'last': False,\n",
       " 'comedy': True,\n",
       " 'funny': True,\n",
       " 'actually': False,\n",
       " 'long': False,\n",
       " 'look': False,\n",
       " 'almost': True,\n",
       " 'thing': False,\n",
       " 'fact': False,\n",
       " 'nothing': False,\n",
       " 'say': False,\n",
       " 'right': True,\n",
       " 'john': False,\n",
       " 'although': False,\n",
       " 'played': False,\n",
       " 'find': False,\n",
       " 'script': False,\n",
       " 'come': False,\n",
       " 'ever': False,\n",
       " 'cast': False,\n",
       " 'since': False,\n",
       " 'star': False,\n",
       " 'plays': True,\n",
       " 'young': False,\n",
       " 'show': False,\n",
       " 'comes': False,\n",
       " 'part': False,\n",
       " 'original': False,\n",
       " 'actors': False,\n",
       " 'screen': False,\n",
       " 'without': False,\n",
       " 'acting': False,\n",
       " 'three': False,\n",
       " 'day': False,\n",
       " 'point': True,\n",
       " 'lot': False,\n",
       " 'least': False,\n",
       " 'takes': False,\n",
       " 'guy': True,\n",
       " 'quite': False,\n",
       " 'away': False,\n",
       " 'family': False,\n",
       " 'effects': False,\n",
       " 'course': False,\n",
       " 'goes': False,\n",
       " 'minutes': True,\n",
       " 'interesting': True,\n",
       " 'might': False,\n",
       " 'far': False,\n",
       " 'high': False,\n",
       " 'rather': False,\n",
       " 'must': False,\n",
       " 'anything': False,\n",
       " 'place': False,\n",
       " 'set': True,\n",
       " 'yet': True,\n",
       " 'watch': True,\n",
       " 'making': False,\n",
       " 'wife': False,\n",
       " 'hard': False,\n",
       " 'always': False,\n",
       " 'fun': False,\n",
       " 'seem': True,\n",
       " 'special': False,\n",
       " 'bit': False,\n",
       " 'times': False,\n",
       " 'trying': False,\n",
       " 'hollywood': False,\n",
       " 'instead': False,\n",
       " 'give': False,\n",
       " 'want': False,\n",
       " 'picture': False,\n",
       " 'kind': False,\n",
       " 'american': False,\n",
       " 'job': False,\n",
       " 'sense': True,\n",
       " 'woman': False,\n",
       " 'home': False,\n",
       " 'series': True,\n",
       " 'actor': False,\n",
       " 'probably': False,\n",
       " 'help': False,\n",
       " 'half': False,\n",
       " 'along': False,\n",
       " 'men': False,\n",
       " 'everything': False,\n",
       " 'pretty': False,\n",
       " 'becomes': False,\n",
       " 'sure': False,\n",
       " 'black': True,\n",
       " 'together': False,\n",
       " 'dialogue': False,\n",
       " 'money': False,\n",
       " 'become': True,\n",
       " 'gives': False,\n",
       " 'given': False,\n",
       " 'looking': False,\n",
       " 'whole': False,\n",
       " 'watching': False,\n",
       " 'father': True,\n",
       " 'feel': False,\n",
       " 'everyone': False,\n",
       " 'music': True,\n",
       " 'wants': False,\n",
       " 'sex': False,\n",
       " 'less': False,\n",
       " 'done': False,\n",
       " 'horror': False,\n",
       " 'got': False,\n",
       " 'death': False,\n",
       " 'perhaps': False,\n",
       " 'city': False,\n",
       " 'next': False,\n",
       " 'especially': False,\n",
       " 'play': True,\n",
       " 'girl': False,\n",
       " 'mind': False,\n",
       " '10': False,\n",
       " 'moments': True,\n",
       " 'looks': False,\n",
       " 'completely': False,\n",
       " '2': False,\n",
       " 'reason': False,\n",
       " 'mother': False,\n",
       " 'whose': False,\n",
       " 'line': False,\n",
       " 'night': False,\n",
       " 'human': False,\n",
       " 'rest': True,\n",
       " 'performances': False,\n",
       " 'different': False,\n",
       " 'evil': False,\n",
       " 'small': False,\n",
       " 'james': False,\n",
       " 'simply': False,\n",
       " 'couple': False,\n",
       " 'put': False,\n",
       " 'let': False,\n",
       " 'anyone': False,\n",
       " 'ending': False,\n",
       " 'case': False,\n",
       " 'several': False,\n",
       " 'dead': True,\n",
       " 'michael': False,\n",
       " 'left': False,\n",
       " 'thought': False,\n",
       " 'school': False,\n",
       " 'shows': False,\n",
       " 'humor': False,\n",
       " 'true': False,\n",
       " 'lost': False,\n",
       " 'written': False,\n",
       " 'friend': False,\n",
       " 'entire': False,\n",
       " 'getting': False,\n",
       " 'town': False,\n",
       " 'turns': False,\n",
       " 'soon': False,\n",
       " 'someone': False,\n",
       " 'second': False,\n",
       " 'main': True,\n",
       " 'stars': False,\n",
       " 'found': False,\n",
       " 'use': False,\n",
       " 'problem': False,\n",
       " 'friends': False,\n",
       " 'tv': False,\n",
       " 'top': False,\n",
       " 'name': False,\n",
       " 'begins': True,\n",
       " 'called': False,\n",
       " 'based': False,\n",
       " 'comic': False,\n",
       " 'david': False,\n",
       " 'head': False,\n",
       " 'else': False,\n",
       " 'idea': False,\n",
       " 'either': False,\n",
       " 'wrong': False,\n",
       " 'unfortunately': False,\n",
       " 'later': False,\n",
       " 'final': False,\n",
       " 'hand': False,\n",
       " 'alien': False,\n",
       " 'house': False,\n",
       " 'group': False,\n",
       " 'full': True,\n",
       " 'used': False,\n",
       " 'tries': False,\n",
       " 'often': False,\n",
       " 'war': True,\n",
       " 'sequence': False,\n",
       " 'keep': False,\n",
       " 'turn': False,\n",
       " 'playing': False,\n",
       " 'boy': False,\n",
       " 'behind': False,\n",
       " 'named': True,\n",
       " 'certainly': False,\n",
       " 'live': False,\n",
       " 'believe': False,\n",
       " 'works': False,\n",
       " 'relationship': False,\n",
       " 'face': True,\n",
       " 'hour': False,\n",
       " 'run': False,\n",
       " 'style': False,\n",
       " 'said': False,\n",
       " 'despite': False,\n",
       " 'person': False,\n",
       " 'finally': False,\n",
       " 'shot': False,\n",
       " 'book': False,\n",
       " 'tell': False,\n",
       " 'maybe': False,\n",
       " 'nice': False,\n",
       " 'son': False,\n",
       " 'perfect': False,\n",
       " 'side': False,\n",
       " 'seeing': False,\n",
       " 'able': False,\n",
       " 'finds': False,\n",
       " 'children': False,\n",
       " 'days': False,\n",
       " 'past': True,\n",
       " 'summer': False,\n",
       " 'camera': False,\n",
       " 'including': False,\n",
       " 'mr': False,\n",
       " 'kids': False,\n",
       " 'lives': False,\n",
       " 'directed': False,\n",
       " 'moment': False,\n",
       " 'game': True,\n",
       " 'running': False,\n",
       " 'fight': False,\n",
       " 'supposed': False,\n",
       " 'video': False,\n",
       " 'car': False,\n",
       " 'matter': False,\n",
       " 'kevin': False,\n",
       " 'joe': False,\n",
       " 'lines': False,\n",
       " 'worth': False,\n",
       " 'daughter': False,\n",
       " 'earth': False,\n",
       " 'starts': True,\n",
       " 'need': False,\n",
       " 'entertaining': True,\n",
       " 'white': True,\n",
       " 'start': False,\n",
       " 'writer': True,\n",
       " 'dark': False,\n",
       " 'short': False,\n",
       " 'self': False,\n",
       " 'worst': False,\n",
       " 'nearly': False,\n",
       " 'opening': False,\n",
       " 'try': False,\n",
       " 'upon': False,\n",
       " 'care': False,\n",
       " 'early': False,\n",
       " 'violence': False,\n",
       " 'throughout': False,\n",
       " 'team': True,\n",
       " 'production': False,\n",
       " 'example': False,\n",
       " 'beautiful': False,\n",
       " 'title': False,\n",
       " 'exactly': False,\n",
       " 'jack': False,\n",
       " 'review': False,\n",
       " 'major': False,\n",
       " 'drama': False,\n",
       " 'problems': False,\n",
       " 'sequences': True,\n",
       " 'obvious': False,\n",
       " 'version': False,\n",
       " 'screenplay': False,\n",
       " 'known': False,\n",
       " 'killer': False,\n",
       " 'robert': False,\n",
       " 'disney': False,\n",
       " 'already': False,\n",
       " 'close': False,\n",
       " 'classic': False,\n",
       " 'others': False,\n",
       " 'hit': False,\n",
       " 'kill': True,\n",
       " 'deep': False,\n",
       " 'five': False,\n",
       " 'order': True,\n",
       " 'act': False,\n",
       " 'simple': False,\n",
       " 'fine': False,\n",
       " 'heart': False,\n",
       " 'roles': False,\n",
       " 'jackie': False,\n",
       " 'direction': False,\n",
       " 'eyes': False,\n",
       " 'four': False,\n",
       " 'question': False,\n",
       " 'sort': False,\n",
       " 'sometimes': False,\n",
       " 'knows': False,\n",
       " 'supporting': False,\n",
       " 'coming': False,\n",
       " 'voice': False,\n",
       " 'women': False,\n",
       " 'truly': False,\n",
       " 'save': False,\n",
       " 'jokes': False,\n",
       " 'computer': False,\n",
       " 'child': False,\n",
       " 'boring': False,\n",
       " 'tom': True,\n",
       " 'level': False,\n",
       " '1': False,\n",
       " 'body': False,\n",
       " 'guys': False,\n",
       " 'genre': True,\n",
       " 'brother': False,\n",
       " 'strong': False,\n",
       " 'stop': False,\n",
       " 'room': False,\n",
       " 'space': False,\n",
       " 'lee': False,\n",
       " 'ends': False,\n",
       " 'beginning': False,\n",
       " 'ship': False,\n",
       " 'york': False,\n",
       " 'attempt': False,\n",
       " 'thriller': True,\n",
       " 'scream': False,\n",
       " 'peter': False,\n",
       " 'husband': False,\n",
       " 'fiction': False,\n",
       " 'happens': False,\n",
       " 'hero': False,\n",
       " 'novel': False,\n",
       " 'note': False,\n",
       " 'hope': False,\n",
       " 'king': False,\n",
       " 'yes': False,\n",
       " 'says': False,\n",
       " 'tells': False,\n",
       " 'quickly': False,\n",
       " 'romantic': False,\n",
       " 'dog': False,\n",
       " 'oscar': True,\n",
       " 'stupid': False,\n",
       " 'possible': False,\n",
       " 'saw': False,\n",
       " 'lead': False,\n",
       " 'career': False,\n",
       " 'murder': False,\n",
       " 'extremely': False,\n",
       " 'manages': True,\n",
       " 'god': False,\n",
       " 'mostly': False,\n",
       " 'wonder': False,\n",
       " 'particularly': False,\n",
       " 'future': False,\n",
       " 'fans': False,\n",
       " 'sound': False,\n",
       " 'worse': False,\n",
       " 'piece': False,\n",
       " 'involving': False,\n",
       " 'de': False,\n",
       " 'appears': False,\n",
       " 'planet': False,\n",
       " 'paul': False,\n",
       " 'involved': False,\n",
       " 'mean': False,\n",
       " 'none': False,\n",
       " 'taking': False,\n",
       " 'hours': False,\n",
       " 'laugh': False,\n",
       " 'police': False,\n",
       " 'sets': True,\n",
       " 'attention': False,\n",
       " 'co': False,\n",
       " 'hell': False,\n",
       " 'eventually': False,\n",
       " 'single': False,\n",
       " 'fall': False,\n",
       " 'falls': False,\n",
       " 'material': False,\n",
       " 'emotional': False,\n",
       " 'power': False,\n",
       " 'late': False,\n",
       " 'lack': False,\n",
       " 'dr': False,\n",
       " 'van': False,\n",
       " 'result': False,\n",
       " 'elements': False,\n",
       " 'meet': False,\n",
       " 'smith': False,\n",
       " 'science': False,\n",
       " 'experience': False,\n",
       " 'bring': False,\n",
       " 'wild': False,\n",
       " 'living': False,\n",
       " 'theater': False,\n",
       " 'interest': False,\n",
       " 'leads': False,\n",
       " 'word': False,\n",
       " 'feature': False,\n",
       " 'battle': False,\n",
       " 'girls': False,\n",
       " 'alone': False,\n",
       " 'obviously': False,\n",
       " 'george': False,\n",
       " 'within': False,\n",
       " 'usually': False,\n",
       " 'enjoy': False,\n",
       " 'guess': False,\n",
       " 'among': False,\n",
       " 'taken': False,\n",
       " 'feeling': False,\n",
       " 'laughs': False,\n",
       " 'aliens': False,\n",
       " 'talk': False,\n",
       " 'chance': False,\n",
       " 'talent': False,\n",
       " '3': False,\n",
       " 'middle': False,\n",
       " 'number': False,\n",
       " 'easy': False,\n",
       " 'across': False,\n",
       " 'needs': False,\n",
       " 'attempts': False,\n",
       " 'happen': False,\n",
       " 'television': False,\n",
       " 'chris': False,\n",
       " 'deal': False,\n",
       " 'poor': False,\n",
       " 'form': False,\n",
       " 'girlfriend': False,\n",
       " 'viewer': False,\n",
       " 'release': False,\n",
       " 'killed': False,\n",
       " 'forced': False,\n",
       " 'whether': False,\n",
       " 'wonderful': False,\n",
       " 'feels': False,\n",
       " 'oh': False,\n",
       " 'tale': False,\n",
       " 'serious': True,\n",
       " 'expect': False,\n",
       " 'except': False,\n",
       " 'light': False,\n",
       " 'success': False,\n",
       " 'features': False,\n",
       " 'premise': False,\n",
       " 'happy': False,\n",
       " 'words': False,\n",
       " 'leave': False,\n",
       " 'important': False,\n",
       " 'meets': False,\n",
       " 'history': False,\n",
       " 'giving': False,\n",
       " 'crew': False,\n",
       " 'type': False,\n",
       " 'call': False,\n",
       " 'turned': False,\n",
       " 'released': False,\n",
       " 'parents': False,\n",
       " 'art': False,\n",
       " 'impressive': False,\n",
       " 'mission': True,\n",
       " 'working': False,\n",
       " 'seemed': False,\n",
       " 'score': False,\n",
       " 'told': False,\n",
       " 'recent': False,\n",
       " 'robin': False,\n",
       " 'basically': False,\n",
       " 'entertainment': False,\n",
       " 'america': False,\n",
       " 'surprise': False,\n",
       " 'apparently': False,\n",
       " 'easily': False,\n",
       " 'ryan': False,\n",
       " 'cool': True,\n",
       " 'stuff': False,\n",
       " 'cop': False,\n",
       " 'change': False,\n",
       " 'williams': False,\n",
       " 'crime': False,\n",
       " 'office': False,\n",
       " 'parts': False,\n",
       " 'somehow': False,\n",
       " 'sequel': False,\n",
       " 'william': True,\n",
       " 'cut': True,\n",
       " 'die': False,\n",
       " 'jones': False,\n",
       " 'credits': False,\n",
       " 'batman': False,\n",
       " 'suspense': False,\n",
       " 'brings': False,\n",
       " 'events': False,\n",
       " 'reality': False,\n",
       " 'local': False,\n",
       " 'talking': False,\n",
       " 'difficult': False,\n",
       " 'using': False,\n",
       " 'went': False,\n",
       " 'writing': False,\n",
       " 'remember': False,\n",
       " 'near': False,\n",
       " 'straight': True,\n",
       " 'hilarious': False,\n",
       " 'ago': False,\n",
       " 'certain': False,\n",
       " 'ben': False,\n",
       " 'kid': False,\n",
       " 'slow': False,\n",
       " 'blood': False,\n",
       " 'mystery': False,\n",
       " 'complete': False,\n",
       " 'red': False,\n",
       " 'popular': False,\n",
       " 'effective': False,\n",
       " 'fast': False,\n",
       " 'flick': False,\n",
       " 'due': False,\n",
       " 'runs': False,\n",
       " 'gone': False,\n",
       " 'return': False,\n",
       " 'presence': False,\n",
       " 'quality': False,\n",
       " 'dramatic': False,\n",
       " 'filmmakers': False,\n",
       " 'age': False,\n",
       " 'brothers': True,\n",
       " 'business': False,\n",
       " 'general': False,\n",
       " 'rock': False,\n",
       " 'sexual': False,\n",
       " 'present': False,\n",
       " 'surprisingly': False,\n",
       " 'anyway': False,\n",
       " 'uses': False,\n",
       " '4': False,\n",
       " 'personal': False,\n",
       " 'figure': False,\n",
       " 'smart': False,\n",
       " 'ways': False,\n",
       " 'decides': False,\n",
       " 'annoying': False,\n",
       " 'begin': False,\n",
       " 'somewhat': False,\n",
       " 'shots': False,\n",
       " 'rich': False,\n",
       " 'minute': False,\n",
       " 'law': False,\n",
       " 'previous': False,\n",
       " 'jim': False,\n",
       " 'successful': False,\n",
       " 'harry': False,\n",
       " 'water': False,\n",
       " 'similar': False,\n",
       " 'absolutely': False,\n",
       " 'motion': False,\n",
       " 'former': False,\n",
       " 'strange': False,\n",
       " 'came': False,\n",
       " 'follow': False,\n",
       " 'read': False,\n",
       " 'project': False,\n",
       " 'million': False,\n",
       " 'secret': False,\n",
       " 'starring': False,\n",
       " 'clear': False,\n",
       " 'familiar': False,\n",
       " 'romance': False,\n",
       " 'intelligent': False,\n",
       " 'third': False,\n",
       " 'excellent': False,\n",
       " 'amazing': False,\n",
       " 'party': False,\n",
       " 'budget': False,\n",
       " 'eye': False,\n",
       " 'actress': False,\n",
       " 'prison': False,\n",
       " 'latest': False,\n",
       " 'means': False,\n",
       " 'company': False,\n",
       " 'towards': False,\n",
       " 'predictable': True,\n",
       " 'powerful': False,\n",
       " 'bob': False,\n",
       " 'beyond': False,\n",
       " 'visual': False,\n",
       " 'leaves': False,\n",
       " 'r': False,\n",
       " 'nature': False,\n",
       " 'following': False,\n",
       " 'villain': False,\n",
       " 'leaving': False,\n",
       " 'animated': False,\n",
       " 'low': False,\n",
       " 'b': False,\n",
       " 'bill': False,\n",
       " 'sam': False,\n",
       " 'filled': False,\n",
       " 'wars': False,\n",
       " 'questions': False,\n",
       " 'cinema': False,\n",
       " 'message': False,\n",
       " 'box': False,\n",
       " 'moving': False,\n",
       " 'country': False,\n",
       " 'usual': False,\n",
       " 'martin': False,\n",
       " 'definitely': False,\n",
       " 'add': False,\n",
       " 'large': False,\n",
       " 'clever': False,\n",
       " 'create': True,\n",
       " 'felt': False,\n",
       " 'stories': True,\n",
       " 'brilliant': False,\n",
       " 'ones': False,\n",
       " 'giant': False,\n",
       " 'situation': False,\n",
       " 'murphy': False,\n",
       " 'break': False,\n",
       " 'opens': False,\n",
       " 'scary': False,\n",
       " 'doubt': False,\n",
       " 'drug': False,\n",
       " 'bunch': False,\n",
       " 'thinking': False,\n",
       " 'solid': False,\n",
       " 'effect': False,\n",
       " 'learn': False,\n",
       " 'move': False,\n",
       " 'force': False,\n",
       " 'potential': False,\n",
       " 'seriously': False,\n",
       " 'follows': True,\n",
       " 'saying': False,\n",
       " 'huge': False,\n",
       " 'class': False,\n",
       " 'plan': False,\n",
       " 'agent': False,\n",
       " 'created': False,\n",
       " 'unlike': False,\n",
       " 'pay': False,\n",
       " 'non': False,\n",
       " 'married': False,\n",
       " 'mark': False,\n",
       " 'sweet': False,\n",
       " 'perfectly': False,\n",
       " 'ex': False,\n",
       " 'realize': False,\n",
       " 'audiences': False,\n",
       " 'took': False,\n",
       " 'decent': False,\n",
       " 'likely': False,\n",
       " 'dream': False,\n",
       " 'view': False,\n",
       " 'scott': False,\n",
       " 'subject': False,\n",
       " 'understand': False,\n",
       " 'happened': False,\n",
       " 'enjoyable': False,\n",
       " 'studio': False,\n",
       " 'immediately': False,\n",
       " 'open': False,\n",
       " 'e': False,\n",
       " 'points': False,\n",
       " 'heard': False,\n",
       " 'viewers': False,\n",
       " 'cameron': False,\n",
       " 'truman': False,\n",
       " 'bruce': False,\n",
       " 'frank': True,\n",
       " 'private': False,\n",
       " 'stay': False,\n",
       " 'fails': False,\n",
       " 'impossible': False,\n",
       " 'cold': True,\n",
       " 'richard': False,\n",
       " 'overall': False,\n",
       " 'merely': False,\n",
       " 'exciting': False,\n",
       " 'mess': False,\n",
       " 'chase': False,\n",
       " 'free': False,\n",
       " 'ten': False,\n",
       " 'neither': False,\n",
       " 'wanted': False,\n",
       " 'gun': False,\n",
       " 'appear': False,\n",
       " 'carter': False,\n",
       " 'escape': False,\n",
       " 'ultimately': False,\n",
       " 'fan': False,\n",
       " 'inside': False,\n",
       " 'favorite': False,\n",
       " 'modern': False,\n",
       " 'l': False,\n",
       " 'wedding': False,\n",
       " 'stone': False,\n",
       " 'trek': False,\n",
       " 'brought': False,\n",
       " 'trouble': False,\n",
       " 'otherwise': False,\n",
       " 'tim': False,\n",
       " '5': False,\n",
       " 'allen': False,\n",
       " 'bond': False,\n",
       " 'society': False,\n",
       " 'liked': False,\n",
       " 'dumb': False,\n",
       " 'musical': False,\n",
       " 'stand': False,\n",
       " 'political': False,\n",
       " 'various': False,\n",
       " 'talented': False,\n",
       " 'particular': False,\n",
       " 'west': False,\n",
       " 'state': False,\n",
       " 'keeps': True,\n",
       " 'english': False,\n",
       " 'silly': False,\n",
       " 'u': False,\n",
       " 'situations': True,\n",
       " 'park': False,\n",
       " 'teen': False,\n",
       " 'rating': False,\n",
       " 'slightly': False,\n",
       " 'steve': False,\n",
       " 'truth': False,\n",
       " 'air': False,\n",
       " 'element': False,\n",
       " 'joke': False,\n",
       " 'spend': False,\n",
       " 'key': True,\n",
       " 'biggest': False,\n",
       " 'members': False,\n",
       " 'effort': False,\n",
       " 'government': False,\n",
       " 'focus': False,\n",
       " 'eddie': False,\n",
       " 'soundtrack': False,\n",
       " 'hands': False,\n",
       " 'earlier': False,\n",
       " 'chan': False,\n",
       " 'purpose': False,\n",
       " 'today': False,\n",
       " 'showing': False,\n",
       " 'memorable': True,\n",
       " 'six': False,\n",
       " 'cannot': False,\n",
       " 'max': False,\n",
       " 'offers': False,\n",
       " 'rated': False,\n",
       " 'mars': False,\n",
       " 'heavy': True,\n",
       " 'totally': False,\n",
       " 'control': False,\n",
       " 'credit': False,\n",
       " 'fi': False,\n",
       " 'woody': False,\n",
       " 'ideas': False,\n",
       " 'sci': False,\n",
       " 'wait': False,\n",
       " 'sit': False,\n",
       " 'female': False,\n",
       " 'ask': False,\n",
       " 'waste': False,\n",
       " 'terrible': False,\n",
       " 'depth': False,\n",
       " 'simon': False,\n",
       " 'aspect': False,\n",
       " 'list': False,\n",
       " 'mary': False,\n",
       " 'sister': False,\n",
       " 'animation': False,\n",
       " 'entirely': False,\n",
       " 'fear': False,\n",
       " 'steven': False,\n",
       " 'moves': True,\n",
       " 'actual': False,\n",
       " 'army': False,\n",
       " 'british': False,\n",
       " 'constantly': False,\n",
       " 'fire': False,\n",
       " 'convincing': False,\n",
       " 'setting': True,\n",
       " 'gave': False,\n",
       " 'tension': False,\n",
       " 'street': False,\n",
       " '8': False,\n",
       " 'brief': True,\n",
       " 'ridiculous': False,\n",
       " 'cinematography': False,\n",
       " 'typical': False,\n",
       " 'nick': False,\n",
       " 'screenwriter': False,\n",
       " 'ability': False,\n",
       " 'spent': False,\n",
       " 'quick': False,\n",
       " 'violent': False,\n",
       " 'atmosphere': True,\n",
       " 'subtle': False,\n",
       " 'expected': False,\n",
       " 'fairly': False,\n",
       " 'seven': False,\n",
       " 'killing': True,\n",
       " 'tone': True,\n",
       " 'master': False,\n",
       " 'disaster': False,\n",
       " 'lots': False,\n",
       " 'thinks': False,\n",
       " 'song': False,\n",
       " 'cheap': False,\n",
       " 'suddenly': False,\n",
       " 'background': True,\n",
       " 'club': False,\n",
       " 'willis': False,\n",
       " 'whatever': False,\n",
       " 'highly': False,\n",
       " 'sees': False,\n",
       " 'complex': False,\n",
       " 'greatest': False,\n",
       " 'impact': False,\n",
       " 'beauty': False,\n",
       " 'front': False,\n",
       " 'humans': False,\n",
       " 'indeed': False,\n",
       " 'flat': False,\n",
       " 'grace': False,\n",
       " 'wrote': False,\n",
       " 'amusing': False,\n",
       " 'ii': False,\n",
       " 'mike': False,\n",
       " 'cute': False,\n",
       " 'dull': False,\n",
       " 'minor': False,\n",
       " 'recently': False,\n",
       " 'hate': False,\n",
       " 'outside': False,\n",
       " 'plenty': False,\n",
       " 'wish': False,\n",
       " 'godzilla': False,\n",
       " 'college': False,\n",
       " 'titanic': False,\n",
       " 'sounds': False,\n",
       " 'telling': False,\n",
       " 'sight': False,\n",
       " 'double': False,\n",
       " 'cinematic': False,\n",
       " 'queen': False,\n",
       " 'hold': False,\n",
       " 'meanwhile': False,\n",
       " 'awful': False,\n",
       " 'clearly': False,\n",
       " 'theme': False,\n",
       " 'hear': False,\n",
       " 'x': False,\n",
       " 'amount': False,\n",
       " 'baby': False,\n",
       " 'approach': False,\n",
       " 'dreams': False,\n",
       " 'shown': False,\n",
       " 'island': False,\n",
       " 'reasons': False,\n",
       " 'charm': False,\n",
       " 'miss': False,\n",
       " 'longer': False,\n",
       " 'common': False,\n",
       " 'sean': False,\n",
       " 'carry': False,\n",
       " 'believable': False,\n",
       " 'realistic': False,\n",
       " 'chemistry': False,\n",
       " 'possibly': False,\n",
       " 'casting': False,\n",
       " 'carrey': False,\n",
       " 'french': False,\n",
       " 'trailer': False,\n",
       " 'tough': False,\n",
       " 'produced': False,\n",
       " 'imagine': False,\n",
       " 'choice': False,\n",
       " 'ride': False,\n",
       " 'somewhere': False,\n",
       " 'hot': False,\n",
       " 'race': False,\n",
       " 'road': False,\n",
       " 'leader': False,\n",
       " 'thin': False,\n",
       " 'jerry': False,\n",
       " 'slowly': False,\n",
       " 'delivers': False,\n",
       " 'detective': False,\n",
       " 'brown': False,\n",
       " 'jackson': True,\n",
       " 'member': False,\n",
       " 'provide': False,\n",
       " 'president': False,\n",
       " 'puts': False,\n",
       " 'asks': False,\n",
       " 'critics': False,\n",
       " 'appearance': False,\n",
       " 'famous': False,\n",
       " 'okay': False,\n",
       " 'intelligence': False,\n",
       " 'energy': False,\n",
       " 'sent': False,\n",
       " 'spielberg': False,\n",
       " 'development': False,\n",
       " 'etc': False,\n",
       " 'language': False,\n",
       " 'blue': False,\n",
       " 'proves': False,\n",
       " 'vampire': False,\n",
       " 'seemingly': False,\n",
       " 'basic': False,\n",
       " 'caught': False,\n",
       " ...}"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "print('\\nClassification: {}\\nConfidence: {:.2%}'.format(\r\n",
    "    vote_clf.classify(x_new),vote_clf.calc_confidence(x_new)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Classification: pos\n",
      "Confidence: 100.00%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "### Using sklearn\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Load data \n",
    "\n",
    "data set ['amazon-reviews-unlocked-mobile-phones'](https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones)\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "import os\r\n",
    "cwd = os.getcwd() # current working directory\r\n",
    "path = os.path.join(cwd,'data\\\\Amazon_Unlocked_Mobile.csv\\\\')\r\n",
    "fn = path + 'Amazon_Unlocked_Mobile.csv' # https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\r\n",
    "df = pd.read_csv(fn) # \r\n",
    "print('len=  {:,}\\ncolumns= {}'.format(len(df), list(df)))\r\n",
    "\r\n",
    "# df = df.sample(frac=0.1, random_state=10) # reduce the amount of reviews due to speedup the training considering this is demo\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len=  413,840\n",
      "columns= ['Product Name', 'Brand Name', 'Price', 'Rating', 'Reviews', 'Review Votes']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \n",
       "0       5  I feel so LUCKY to have found this used (phone...           1.0  \n",
       "1       4  nice phone, nice up grade from my pantach revu...           0.0  \n",
       "2       5                                       Very pleased           0.0  \n",
       "3       4  It works good but it goes slow sometimes but i...           0.0  \n",
       "4       4  Great phone to replace my lost phone. The only...           0.0  "
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Get rid of records with missed data \n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "df.dropna(inplace=True) \r\n",
    "print('len=  {:,}'.format(len(df)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len=  334,335\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Label positive and negative \n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "df = df[df['Rating'] != 3] # Remove any 'neutral' ratings equal to 3  as uninformative\r\n",
    "df['Rating_binary'] = np.where(df['Rating'] > 3, 1, 0) # returns 1 for 4,5 and 0 for 1,2\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "      <th>Rating_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \\\n",
       "0       5  I feel so LUCKY to have found this used (phone...           1.0   \n",
       "1       4  nice phone, nice up grade from my pantach revu...           0.0   \n",
       "2       5                                       Very pleased           0.0   \n",
       "3       4  It works good but it goes slow sometimes but i...           0.0   \n",
       "4       4  Great phone to replace my lost phone. The only...           0.0   \n",
       "\n",
       "   Rating_binary  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "df['Rating_binary'].mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7482686025879323"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Split to train and test sets\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Reviews'],df['Rating_binary'],random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Review training sample\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "X_train.iloc[0], y_train.iloc[0] # Be careful with quering like X_train[0] because it casts to X_train.loc[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('I bought a BB Black and was deliveried a White BB.Really is not a serious provider...Next time is better to cancel the order.',\n",
       " 0)"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Extract Features \n",
    "\n",
    "</font>\n",
    "The bag-of-words approach is simple way to represent text for use in machine learning, which ignores structure and only counts how often each word occurs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Count vectorizer\n",
    "\n",
    "</font>\n",
    "By default, selects tokens of 2 or more alphanumeric characters (punctuation is completely ignored and always treated as a token separator)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \r\n",
    "\r\n",
    "vect = CountVectorizer().fit(X_train) # Fit the CountVectorizer to the training data\r\n",
    "print('features samples:\\n{}'.format(vect.get_feature_names()[::2000])) # display each 2000-th feature \r\n",
    "print ('\\nlen of features {:,}'.format(len(vect.get_feature_names()))) \r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "features samples:\n",
      "['00', '4less', 'adr6275', 'assignment', 'blazingly', 'cassettes', 'condishion', 'debi', 'dollarsshipping', 'esteem', 'flashy', 'gorila', 'human', 'irullu', 'like', 'microsaudered', 'nightmarish', 'p770', 'poori', 'quirky', 'responseive', 'send', 'sos', 'synch', 'trace', 'utiles', 'withstanding']\n",
      "\n",
      "len of features 53,216\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Transfrom the X_train to feature representation\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "X_train_vectorized = vect.transform(X_train) # indeces of existing words from vocabulary and their count in current text\r\n",
    "X_train_vectorized"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<231207x53216 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6117776 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "print (X_train_vectorized[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (0, 4986)\t1\n",
      "  (0, 7259)\t2\n",
      "  (0, 7676)\t1\n",
      "  (0, 7878)\t1\n",
      "  (0, 8476)\t1\n",
      "  (0, 9637)\t1\n",
      "  (0, 14420)\t1\n",
      "  (0, 26003)\t2\n",
      "  (0, 31892)\t1\n",
      "  (0, 32284)\t1\n",
      "  (0, 33437)\t1\n",
      "  (0, 37356)\t1\n",
      "  (0, 38473)\t1\n",
      "  (0, 42146)\t1\n",
      "  (0, 46946)\t1\n",
      "  (0, 47462)\t1\n",
      "  (0, 47639)\t1\n",
      "  (0, 51169)\t1\n",
      "  (0, 51673)\t1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Review vectorized training sample\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "# review first sample\r\n",
    "df = pd.DataFrame(X_train_vectorized[0].toarray(), index=[\"value\"]).T\r\n",
    "df[df[\"value\"] > 0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7259</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7676</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7878</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9637</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14420</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26003</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31892</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32284</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33437</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37356</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38473</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42146</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46946</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47462</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47639</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51169</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51673</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       value\n",
       "4986       1\n",
       "7259       2\n",
       "7676       1\n",
       "7878       1\n",
       "8476       1\n",
       "9637       1\n",
       "14420      1\n",
       "26003      2\n",
       "31892      1\n",
       "32284      1\n",
       "33437      1\n",
       "37356      1\n",
       "38473      1\n",
       "42146      1\n",
       "46946      1\n",
       "47462      1\n",
       "47639      1\n",
       "51169      1\n",
       "51673      1"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "print(list(df[df[\"value\"] > 0].index))\r\n",
    "[vect.get_feature_names()[index] for index in df[df[\"value\"] > 0].index.values]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[4986, 7259, 7676, 7878, 8476, 9637, 14420, 26003, 31892, 32284, 33437, 37356, 38473, 42146, 46946, 47462, 47639, 51169, 51673]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['and',\n",
       " 'bb',\n",
       " 'better',\n",
       " 'black',\n",
       " 'bought',\n",
       " 'cancel',\n",
       " 'deliveried',\n",
       " 'is',\n",
       " 'next',\n",
       " 'not',\n",
       " 'order',\n",
       " 'provider',\n",
       " 'really',\n",
       " 'serious',\n",
       " 'the',\n",
       " 'time',\n",
       " 'to',\n",
       " 'was',\n",
       " 'white']"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Train model\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "from sklearn.metrics import f1_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "clf = LogisticRegression(max_iter=2000).fit(X_train_vectorized, y_train) # Train the model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Evaluate model\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "predictions = clf.predict(vect.transform(X_test)) # Predict the transformed test documents\r\n",
    "print('f1: ', f1_score(y_test, predictions)) \r\n",
    "scores = clf.decision_function(vect.transform(X_test)) \r\n",
    "print('AUC: ', roc_auc_score(y_test, scores)) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f1:  0.9691796161664887\n",
      "AUC:  0.9795203337742681\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Review relevant features \n",
    "    \n",
    "</font>\n",
    "\n",
    "The smallest coefs corresponds to `Neg` impact, and largest coefs represent `Pos` impact"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "feature_names = np.array(vect.get_feature_names())\r\n",
    "sorted_coef_index = clf.coef_[0].argsort() # ascending  [0] is just squeeze from shape (1,n)\r\n",
    "clf.coef_.shape, clf.coef_[0].shape, sorted(clf.coef_[0])[:10], sorted(clf.coef_[0])[-11:-1], "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1, 53216),\n",
       " (53216,),\n",
       " [-4.66996028024669,\n",
       "  -3.640686532455537,\n",
       "  -3.621230402982406,\n",
       "  -3.5243529949992762,\n",
       "  -3.359035727903423,\n",
       "  -3.2310767905639044,\n",
       "  -3.1391235992080944,\n",
       "  -3.1320734199960913,\n",
       "  -3.131109796055131,\n",
       "  -3.1165376558770204],\n",
       " [3.285948197536963,\n",
       "  3.296745762045075,\n",
       "  3.299978703079375,\n",
       "  3.3582195153383285,\n",
       "  3.5177823563853994,\n",
       "  3.6040204266342624,\n",
       "  3.6199845581877512,\n",
       "  3.6548974979659623,\n",
       "  4.409282357861199,\n",
       "  4.71741931752714])"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "print('Smallest coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\r\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))\r\n",
    "# model.coef_[0][sorted_coef_index[0]] the smallest "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Smallest coefs:\n",
      "['mony' 'worst' 'false' 'worthless' 'horribly' 'messing' 'unsatisfied'\n",
      " 'blacklist' 'junk' 'garbage']\n",
      "\n",
      "Largest Coefs: \n",
      "['excelent' 'excelente' '4eeeks' 'exelente' 'efficient' 'excellent'\n",
      " 'loving' 'pleasantly' 'loves' 'mn8k2ll']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\r\n",
    "\r\n",
    "## Term frequencyinverse document frequency (TFIDF)\r\n",
    "\r\n",
    "\r\n",
    "</font>\r\n",
    "\r\n",
    "TFIDF is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. Its value increases proportionally to the number of times a word appears in the document and decreases by the number of documents in the corpus that contain the word\r\n",
    "<div style=\"float:left;\">\r\n",
    "<br>\r\n",
    "    \r\n",
    "**Term frequency** $(tf(t,d))$ is measure of how frequent term t is in document d \r\n",
    "$$ tf(t,d) = \\frac{k}{n},$$ <br>$d$ - document,  $k$ - number of times word occurs in document $d$, $n$ - total number of words in document $d$.\r\n",
    "<br>\r\n",
    "Note: Various approaches can be used for term frequency e.g. *augmented frequency*, to prevent a bias towards longer documents (raw frequency divided by the raw frequency of the most occurring term in the document):\r\n",
    "\r\n",
    "$$ tf^{\\,A}(t,d) = 0.5+ 0.5\\cdot \\frac{tf(t,d)}{\\underset{t' \\in d}{max}(tf(t',d))} $$\r\n",
    "\r\n",
    "**Inverse document frequency** $(idf(t,D))$ is a measure of how much information the word provides.\r\n",
    "$$ idf(t,D) = log \\frac{N}{K},$$ <br>$D$ - all documents, $K$ - number of documents in $D$ that contain the word , $N$ - total number of documents in $D$. <br>\r\n",
    "</div>\r\n",
    "\r\n",
    "Note: Various approaches can be used for inverse document frequency \r\n",
    "\r\n",
    "<div style=\"float:left;\">\r\n",
    "<table width=\"500\">\r\n",
    "    <tr>\r\n",
    "        <th style=\"text-align:center\" bgcolor= white>Document1</th>\r\n",
    "        <th style=\"text-align:center\"  bgcolor= white >Document2</th></tr>\r\n",
    "    <tr>\r\n",
    "        <td>\r\n",
    "            <table>\r\n",
    "                <tr>\r\n",
    "                    <th  bgcolor=gainsboro>Term</th>\r\n",
    "                    <th  bgcolor=gainsboro>Term Count</th></tr>\r\n",
    "                <tr><td>this</td><td>1</td></tr>\r\n",
    "                <tr><td>is</td><td>1</td></tr>\r\n",
    "                <tr><td>a</td><td>2</td></tr>\r\n",
    "                <tr><td>sample</td><td>1</td></tr>\r\n",
    "            </table>\r\n",
    "        </td>\r\n",
    "        <td>\r\n",
    "            <table>\r\n",
    "                <tr>\r\n",
    "                    <th bgcolor=gainsboro>Term</th>\r\n",
    "                    <th  bgcolor=gainsboro>Term Count</th></tr>\r\n",
    "                <tr><td>this</td><td>1</td></tr>\r\n",
    "                <tr><td>is</td><td>1</td></tr>\r\n",
    "                <tr><td>another</td><td>2</td></tr>\r\n",
    "                <tr><td>example</td><td>3</td></tr>\r\n",
    "            </table>\r\n",
    "        </td>\r\n",
    "    </tr>\r\n",
    "</table>\r\n",
    "<div/>\r\n",
    "\r\n",
    "<div style=\"float:left;\">\r\n",
    "<br>\r\n",
    "\r\n",
    "For <strong>\"this\"</strong>:\r\n",
    "$$ tf (\"this\", d_{1}) =  \\frac{1}{5} = 0.2, \\quad  tf (\"this\", d_{2}) =  \\frac{1}{7} \\approx 0.14, \\quad idf (\"this\", D) =  log \\frac{2}{2} =0; $$\r\n",
    "\r\n",
    "$$ tfidf(\"this\", d_{1}, D)  = 0.2 \\cdot 0 = 0, \\quad    tfidf(\"this\", d_{2}, D)  = 0.14 \\cdot 0 = 0 $$\r\n",
    "\r\n",
    "For <strong>\"example\"</strong>:\r\n",
    "$$ tf (\"example\", d_{1}) =  \\frac{0}{5} = 0 , \\quad  tf (\"example\", d_{2}) =  \\frac{3}{7} \\approx 0.43 , \\quad idf (\"example\", D) =  log \\frac{2}{1} \\approx 0.3; $$\r\n",
    "\r\n",
    "$$ tfidf(\"example\", d_{1}, D)  = 0 \\cdot 0.3 = 0, \\quad    tfidf(\"example\", d_{2}, D)  = 0.43 \\cdot 0.3 = 0.129 $$\r\n",
    "\r\n",
    "</div>\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "### Sklearn tfidf\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Compute sklearn tfidf for sample with 2 documents \n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "X = np.array(['this is a sample a', 'this is another example another example example'])\r\n",
    "tfidf_vectorizer= TfidfVectorizer().fit(X)\r\n",
    "X_vectorized= tfidf_vectorizer.transform(X)\r\n",
    "print (tfidf_vectorizer.vocabulary_)\r\n",
    "X_vectorized.toarray()\r\n",
    "# conclusion: sklearn uses different variant of computation tfidf"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'this': 4, 'is': 2, 'sample': 3, 'another': 0, 'example': 1}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.50154891, 0.70490949, 0.50154891],\n",
       "       [0.53428425, 0.80142637, 0.19007382, 0.        , 0.19007382]])"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Use sklearn tfidf for Amazon_Unlocked_Mobile documents \n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "tfidf_vectorizer= TfidfVectorizer(min_df=5)#.fit(X_train) \r\n",
    "    # min_df - minimum document count to include the term, default is 1 \r\n",
    "    # you may also set max_features (Int or None) to return just limited number of top tfidf features \r\n",
    "X_train_vectorized = tfidf_vectorizer.fit_transform(X_train)\r\n",
    "print ('len of features= {:,}'.format(len(tfidf_vectorizer.get_feature_names()))) \r\n",
    "    # Note: min_df=5 caused 17,951  comparing to 53,216 acquired by count vectorizer\r\n",
    "    # Note: min_df=5 is also available in count vectorizer\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len of features= 17,951\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "# X_train_vectorized.shape # (231207, 17951) = (n_documents, n_features)\r\n",
    "sorted_tfidf_index = X_train_vectorized.max(axis=0).toarray()[0].argsort() \r\n",
    "    # max(axis=0) means max through all docs - will get the max of each word within all docs\r\n",
    "    # [0] - just squeezing     \r\n",
    "print (np.sort(X_train_vectorized.max(axis=0).toarray()[0]))\r\n",
    "sorted_tfidf_index # indices of the most tfidf terms \r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.01989111 0.01989111 0.01989111 ... 1.         1.         1.        ]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 3624, 12532, 17320, ...,  7414,  2184,  4635], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "feature_names = np.array(tfidf_vectorizer.get_feature_names())\r\n",
    "print ('feature_names ',feature_names)\r\n",
    "print('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\r\n",
    "print('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-11:-1]]))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "feature_names  ['00' '000' '0000' ... '' 't' '']\n",
      "Smallest tfidf:\n",
      "['commenter' 'pthalo' 'warmness' 'storageso' 'aggregration' '1300'\n",
      " '625nits' 'a10' 'submarket' 'brawns']\n",
      "\n",
      "Largest tfidf: \n",
      "['defective' 'batteries' 'gooood' 'epic' 'luis' 'goood' 'basico'\n",
      " 'aceptable' 'problems' 'excellant']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Train model on features  extracted by tfidf vectorizer\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "clf = LogisticRegression(max_iter=1000).fit(X_train_vectorized, y_train) # Train the model\r\n",
    "predictions = clf.predict(tfidf_vectorizer.transform(X_test)) \r\n",
    "print('f1: ', f1_score(y_test, predictions)) \r\n",
    "scores = clf.decision_function(tfidf_vectorizer.transform(X_test)) \r\n",
    "print('AUC: ', roc_auc_score(y_test, scores)) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f1:  0.9658793557580206\n",
      "AUC:  0.9821688869291787\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Conclusion: Perfromance is not worse but there are 3 times less amount of features used"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "sorted_coef_index = clf.coef_[0].argsort()\r\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\r\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Smallest Coefs:\n",
      "['not' 'worst' 'useless' 'disappointed' 'terrible' 'return' 'waste' 'poor'\n",
      " 'horrible' 'doesn']\n",
      "\n",
      "Largest Coefs: \n",
      "['love' 'great' 'excellent' 'perfect' 'amazing' 'awesome' 'perfectly'\n",
      " 'easy' 'best' 'loves']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "### n-grams\n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "# the problem is the following reviews are treated the same by current model\r\n",
    "targets= [\r\n",
    "    \"not an issue, phone is working\", \r\n",
    "    \"an issue, phone is not working\"\r\n",
    "]\r\n",
    "print(clf.predict(tfidf_vectorizer.transform(targets)))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "count_vectorizer = CountVectorizer(min_df=5, max_features=50000, ngram_range=(1,2)).fit(X_train) # Note: both limits are included\r\n",
    "X_train_vectorized = count_vectorizer.transform(X_train)\r\n",
    "print('len of features using n-grams vectorizer={:,}'.format(len(count_vectorizer.get_feature_names()))) \r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len of features using n-grams vectorizer=50,000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "clf= LogisticRegression(max_iter= 2000).fit(X_train_vectorized, y_train)\r\n",
    "predictions = clf.predict(count_vectorizer.transform(X_test)) \r\n",
    "print('f1: ', f1_score(y_test, predictions)) \r\n",
    "scores = clf.decision_function(count_vectorizer.transform(X_test)) \r\n",
    "print('AUC: ', roc_auc_score(y_test, scores))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f1:  0.9828362603484706\n",
      "AUC:  0.9889421498020248\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "feature_names = np.array(count_vectorizer.get_feature_names())\r\n",
    "sorted_coef_index = clf.coef_[0].argsort()\r\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\r\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Smallest Coefs:\n",
      "['no good' 'worst' 'junk' 'not happy' 'not good' 'garbage' 'horrible'\n",
      " 'nit' 'great support' 'looks ok']\n",
      "\n",
      "Largest Coefs: \n",
      "['not bad' 'excelent' 'excelente' 'excellent' 'perfect' 'no problems'\n",
      " 'exelente' 'awesome' 'no issues' 'amazing']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "print (targets)\r\n",
    "print(clf.predict(count_vectorizer.transform(targets)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['not an issue, phone is working', 'an issue, phone is not working']\n",
      "[1 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "## Home Task \n",
    "\n",
    "</font>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\n",
    "\n",
    "### Load data \n",
    "\n",
    "</font>\n",
    "\n",
    "[Sentiment Analysis Dataset](https://www.kaggle.com/sonaam1234/sentimentdata)\n",
    "\n",
    "alternative source: \n",
    "<br>\n",
    "[rt-polaritydata](https://github.com/dennybritz/cnn-text-classification-tf/tree/master/data/rt-polaritydata)\n",
    "\n",
    "alternative source: \n",
    "<br>\n",
    "[Movie Review Data](http://www.cs.cornell.edu/people/pabo/movie-review-data)\n",
    "\n",
    "Each line in these two files corresponds to a single snippet (usually containing roughly one single sentence); all snippets are down-cased.  \n",
    "[More info about dataset](https://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.README.1.0.txt)\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### First method"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "source": [
    "import re\r\n",
    "import nltk\r\n",
    "import random\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\r\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "source": [
    "def get_texts(filename: str) -> str:\r\n",
    "    \"\"\"Get raw text from files\r\n",
    "\r\n",
    "    Args:\r\n",
    "        filename (str): File name\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        str: raw full text\r\n",
    "    \"\"\"\r\n",
    "    with open(filename, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:  # some invalid symbols encountered\r\n",
    "        content = f.read()\r\n",
    "    return content"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "source": [
    "# get negative and positive texts\r\n",
    "full_neg, full_pos = get_texts(\"rt-polarity.neg\"), get_texts(\"rt-polarity.pos\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "source": [
    "def preprocess(text: str) -> list:\r\n",
    "    \"\"\"Get words from text\r\n",
    "\r\n",
    "    Args:\r\n",
    "        text (str): raw text from files\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        list: all words\r\n",
    "    \"\"\"\r\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\r\n",
    "    return tokenizer.tokenize(text.lower())\r\n",
    "\r\n",
    "neg_text = preprocess(full_neg)\r\n",
    "pos_text = preprocess(full_pos)\r\n",
    "\r\n",
    "print(f\"Negative words list len - {len(neg_text)}\\nFirst ten elements - {neg_text[:10]}\")\r\n",
    "print(f\"Positive words list len - {len(pos_text)}\\nFirst ten elements - {(pos_text[:10])}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Negative words list len - 103030\n",
      "First ten elements - ['simplistic', 'silly', 'and', 'tedious', 'it', 's', 'so', 'laddish', 'and', 'juvenile']\n",
      "Positive words list len - 103204\n",
      "First ten elements - ['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'century', 's']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "source": [
    "# concatenate of two lists\r\n",
    "all_words = neg_text + pos_text\r\n",
    "print(f\"All words list len - {len(all_words)}\\nFirst ten elements - {all_words[:10]}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All words list len - 206234\n",
      "First ten elements - ['simplistic', 'silly', 'and', 'tedious', 'it', 's', 'so', 'laddish', 'and', 'juvenile']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "source": [
    "# calculate frequency for each word\r\n",
    "all_words = nltk.FreqDist(all_words)\r\n",
    "print(f\"Vocab len: {len(all_words)}\")\r\n",
    "\r\n",
    "# take most common words\r\n",
    "most_common_words = list(zip(*all_words.most_common()))[0]\r\n",
    "print(f\"Ten the most common words - {most_common_words[:10]}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vocab len: 18359\n",
      "Ten the most common words - ('the', 'a', 'and', 'of', 'to', 's', 'it', 'is', 'in', 'that')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "source": [
    "def remove_stopwords(words:list) -> list:\r\n",
    "    \"\"\"Remove stop words from the list of common words\r\n",
    "\r\n",
    "    Args:\r\n",
    "        words (list): the most common words\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        list: not stop words\r\n",
    "    \"\"\"\r\n",
    "    stop_words = set(stopwords.words('english'))  \r\n",
    "    return [w for w in words if w not in stop_words]\r\n",
    "\r\n",
    "most_common_words_filtered = remove_stopwords(most_common_words)\r\n",
    "print(f\"Most common words filtered list len - {len(most_common_words_filtered)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most common words filtered list len - 18211\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "source": [
    "word_features = most_common_words_filtered [:5000]\r\n",
    "print(f\"Top 50 word features - {word_features[:50]}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 50 word features - ['film', 'movie', 'one', 'like', 'story', 'good', 'much', 'even', 'comedy', 'time', 'characters', 'well', 'director', 'little', 'way', 'funny', 'make', 'enough', 'never', 'life', 'makes', 'bad', 'may', 'best', 'us', 'work', 'love', 'would', 'made', 'new', 'movies', 'something', 'could', 'action', 'drama', 'really', 'two', 'plot', 'see', 'performances', 'long', 'many', 'still', 'films', 'look', 'old', 'every', 'people', 'big', 'first']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "source": [
    "neg_texts_with_cat = [(word_tokenize(sentence), \"neg\") for sentence in full_neg.splitlines()]\r\n",
    "print(neg_texts_with_cat[1])\r\n",
    "\r\n",
    "pos_text_with_cat = [(word_tokenize(sentence), \"pos\") for sentence in full_pos.splitlines()]\r\n",
    "print(pos_text_with_cat[0])\r\n",
    "\r\n",
    "documents = neg_texts_with_cat + pos_text_with_cat\r\n",
    "print(documents[:5])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(['it', \"'s\", 'so', 'laddish', 'and', 'juvenile', ',', 'only', 'teenage', 'boys', 'could', 'possibly', 'find', 'it', 'funny', '.'], 'neg')\n",
      "(['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'century', \"'s\", 'new', '``', 'conan', '``', 'and', 'that', 'he', \"'s\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', ',', 'jean-claud', 'van', 'damme', 'or', 'steven', 'segal', '.'], 'pos')\n",
      "[(['simplistic', ',', 'silly', 'and', 'tedious', '.'], 'neg'), (['it', \"'s\", 'so', 'laddish', 'and', 'juvenile', ',', 'only', 'teenage', 'boys', 'could', 'possibly', 'find', 'it', 'funny', '.'], 'neg'), (['exploitative', 'and', 'largely', 'devoid', 'of', 'the', 'depth', 'or', 'sophistication', 'that', 'would', 'make', 'watching', 'such', 'a', 'graphic', 'treatment', 'of', 'the', 'crimes', 'bearable', '.'], 'neg'), (['[', 'garbus', ']', 'discards', 'the', 'potential', 'for', 'pathological', 'study', ',', 'exhuming', 'instead', ',', 'the', 'skewed', 'melodrama', 'of', 'the', 'circumstantial', 'situation', '.'], 'neg'), (['a', 'visually', 'flashy', 'but', 'narratively', 'opaque', 'and', 'emotionally', 'vapid', 'exercise', 'in', 'style', 'and', 'mystification', '.'], 'neg')]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "source": [
    "# we need to shuffle docs in order to take pos and neg texts\r\n",
    "random.shuffle(documents)\r\n",
    "documents = documents[:5000] # take less data to speed up trainings\r\n",
    "print(documents[:5])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(['as', 'happily', 'glib', 'and', 'vicious', 'as', 'its', 'characters', '.'], 'neg'), (['as', 'gory', 'as', 'the', 'scenes', 'of', 'torture', 'and', 'self-mutilation', 'may', 'be', ',', 'they', 'are', 'pitted', 'against', 'shimmering', 'cinematography', 'that', 'lends', 'the', 'setting', 'the', 'ethereal', 'beauty', 'of', 'an', 'asian', 'landscape', 'painting', '.'], 'pos'), (['bittersweet', 'comedy/drama', 'full', 'of', 'life', ',', 'hand', 'gestures', ',', 'and', 'some', 'really', 'adorable', 'italian', 'guys', '.'], 'pos'), (['sorvino', 'is', 'delightful', 'in', 'the', 'central', 'role', '.', 'she', 'nearly', 'glows', 'with', 'enthusiasm', ',', 'sensuality', 'and', 'a', 'conniving', 'wit', '.'], 'pos'), (['a', 'thinly', 'veiled', 'excuse', 'for', 'wilson', 'to', 'play', 'his', 'self-deprecating', 'act', 'against', 'murphy', \"'s\", 'well-honed', 'prima', 'donna', 'shtick', '.'], 'neg')]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "source": [
    "def find_features(review_tokens:list, word_features: list = word_features) -> dict:\r\n",
    "    \"\"\"Take words from word_features and check if it exists in given words_list\r\n",
    "\r\n",
    "    Args:\r\n",
    "        review_tokens (list): words in sentence\r\n",
    "        word_features (list, optional): [description]. the most common words\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        dict: words that exist or not in given words list\r\n",
    "    \"\"\"\r\n",
    "    return {w: w in set(review_tokens) for w in word_features}\r\n",
    "\r\n",
    "\r\n",
    "data_set = [(find_features(review_tokens), category) for (review_tokens, category) in documents]\r\n",
    "data_set[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "({'film': False,\n",
       "  'movie': False,\n",
       "  'one': False,\n",
       "  'like': False,\n",
       "  'story': False,\n",
       "  'good': False,\n",
       "  'much': False,\n",
       "  'even': False,\n",
       "  'comedy': False,\n",
       "  'time': False,\n",
       "  'characters': False,\n",
       "  'well': False,\n",
       "  'director': False,\n",
       "  'little': False,\n",
       "  'way': False,\n",
       "  'funny': False,\n",
       "  'make': False,\n",
       "  'enough': False,\n",
       "  'never': False,\n",
       "  'life': False,\n",
       "  'makes': False,\n",
       "  'bad': False,\n",
       "  'may': True,\n",
       "  'best': False,\n",
       "  'us': False,\n",
       "  'work': False,\n",
       "  'love': False,\n",
       "  'would': False,\n",
       "  'made': False,\n",
       "  'new': False,\n",
       "  'movies': False,\n",
       "  'something': False,\n",
       "  'could': False,\n",
       "  'action': False,\n",
       "  'drama': False,\n",
       "  'really': False,\n",
       "  'two': False,\n",
       "  'plot': False,\n",
       "  'see': False,\n",
       "  'performances': False,\n",
       "  'long': False,\n",
       "  'many': False,\n",
       "  'still': False,\n",
       "  'films': False,\n",
       "  'look': False,\n",
       "  'old': False,\n",
       "  'every': False,\n",
       "  'people': False,\n",
       "  'big': False,\n",
       "  'first': False,\n",
       "  'nothing': False,\n",
       "  'better': False,\n",
       "  'get': False,\n",
       "  'fun': False,\n",
       "  'without': False,\n",
       "  'great': False,\n",
       "  'character': False,\n",
       "  'though': False,\n",
       "  'might': False,\n",
       "  'audience': False,\n",
       "  'also': False,\n",
       "  'world': False,\n",
       "  'another': False,\n",
       "  'cast': False,\n",
       "  'real': False,\n",
       "  'kind': False,\n",
       "  'ever': False,\n",
       "  'self': False,\n",
       "  'humor': False,\n",
       "  'script': False,\n",
       "  'year': False,\n",
       "  'sense': False,\n",
       "  'feel': False,\n",
       "  'less': False,\n",
       "  'often': False,\n",
       "  'performance': False,\n",
       "  'far': False,\n",
       "  'thing': False,\n",
       "  'feels': False,\n",
       "  'hard': False,\n",
       "  'thriller': False,\n",
       "  'man': False,\n",
       "  'screen': False,\n",
       "  'seems': False,\n",
       "  'picture': False,\n",
       "  'minutes': False,\n",
       "  'tale': False,\n",
       "  'heart': False,\n",
       "  'full': False,\n",
       "  'quite': False,\n",
       "  'documentary': False,\n",
       "  'hollywood': False,\n",
       "  'almost': False,\n",
       "  'end': False,\n",
       "  'yet': False,\n",
       "  'interesting': False,\n",
       "  'go': False,\n",
       "  'american': False,\n",
       "  'entertaining': False,\n",
       "  'rather': False,\n",
       "  'de': False,\n",
       "  'take': False,\n",
       "  'family': False,\n",
       "  'watching': False,\n",
       "  'seen': False,\n",
       "  'romantic': False,\n",
       "  'ultimately': False,\n",
       "  'comes': False,\n",
       "  'moments': False,\n",
       "  'right': False,\n",
       "  'despite': False,\n",
       "  'lot': False,\n",
       "  'original': False,\n",
       "  'acting': False,\n",
       "  'human': False,\n",
       "  'find': False,\n",
       "  'worth': False,\n",
       "  'gets': False,\n",
       "  'back': False,\n",
       "  'times': False,\n",
       "  'actors': False,\n",
       "  'takes': False,\n",
       "  'come': False,\n",
       "  'things': False,\n",
       "  'dialogue': False,\n",
       "  'scenes': True,\n",
       "  'watch': False,\n",
       "  'high': False,\n",
       "  'compelling': False,\n",
       "  'material': False,\n",
       "  'young': False,\n",
       "  'years': False,\n",
       "  'music': False,\n",
       "  'kids': False,\n",
       "  'style': False,\n",
       "  'going': False,\n",
       "  'half': False,\n",
       "  'cinema': False,\n",
       "  'anyone': False,\n",
       "  'works': False,\n",
       "  'think': False,\n",
       "  'star': False,\n",
       "  'writer': False,\n",
       "  'seem': False,\n",
       "  'know': False,\n",
       "  'want': False,\n",
       "  'emotional': False,\n",
       "  'least': False,\n",
       "  'last': False,\n",
       "  'special': False,\n",
       "  'point': False,\n",
       "  'gives': False,\n",
       "  'piece': False,\n",
       "  'part': False,\n",
       "  'give': False,\n",
       "  'making': False,\n",
       "  'say': False,\n",
       "  'show': False,\n",
       "  'sometimes': False,\n",
       "  'subject': False,\n",
       "  'pretty': False,\n",
       "  'cinematic': False,\n",
       "  'entertainment': False,\n",
       "  'together': False,\n",
       "  'video': False,\n",
       "  'moving': False,\n",
       "  'bit': False,\n",
       "  'keep': False,\n",
       "  'true': False,\n",
       "  'fans': False,\n",
       "  'dull': False,\n",
       "  'whole': False,\n",
       "  'sweet': False,\n",
       "  'away': False,\n",
       "  'war': False,\n",
       "  'fascinating': False,\n",
       "  'anything': False,\n",
       "  'art': False,\n",
       "  'age': False,\n",
       "  'since': False,\n",
       "  'three': False,\n",
       "  'need': False,\n",
       "  'manages': False,\n",
       "  'laughs': False,\n",
       "  'women': False,\n",
       "  'flick': False,\n",
       "  'offers': False,\n",
       "  'history': False,\n",
       "  'dark': False,\n",
       "  'experience': False,\n",
       "  'clever': False,\n",
       "  'always': False,\n",
       "  'silly': False,\n",
       "  'predictable': False,\n",
       "  'direction': False,\n",
       "  'simply': False,\n",
       "  'low': False,\n",
       "  'mr': False,\n",
       "  'instead': False,\n",
       "  'everything': False,\n",
       "  'title': False,\n",
       "  'day': False,\n",
       "  'feature': False,\n",
       "  'comic': False,\n",
       "  'care': False,\n",
       "  'actually': False,\n",
       "  'around': False,\n",
       "  'nearly': False,\n",
       "  'coming': False,\n",
       "  'series': False,\n",
       "  'charm': False,\n",
       "  'whose': False,\n",
       "  'done': False,\n",
       "  'visual': False,\n",
       "  'horror': False,\n",
       "  'matter': False,\n",
       "  'place': False,\n",
       "  'filmmakers': False,\n",
       "  'narrative': False,\n",
       "  'looking': False,\n",
       "  'familiar': False,\n",
       "  'genre': False,\n",
       "  'effects': False,\n",
       "  'screenplay': False,\n",
       "  'set': False,\n",
       "  'idea': False,\n",
       "  'short': False,\n",
       "  'mind': False,\n",
       "  'goes': False,\n",
       "  'trying': False,\n",
       "  'children': False,\n",
       "  'probably': False,\n",
       "  'hour': False,\n",
       "  'plays': False,\n",
       "  'smart': False,\n",
       "  'home': False,\n",
       "  'premise': False,\n",
       "  'power': False,\n",
       "  'turns': False,\n",
       "  'thought': False,\n",
       "  'enjoyable': False,\n",
       "  'engaging': False,\n",
       "  'becomes': False,\n",
       "  'although': False,\n",
       "  'feeling': False,\n",
       "  'lacks': False,\n",
       "  'study': False,\n",
       "  'tv': False,\n",
       "  'especially': False,\n",
       "  'worst': False,\n",
       "  'amusing': False,\n",
       "  'ending': False,\n",
       "  'enjoy': False,\n",
       "  'strong': False,\n",
       "  'minute': False,\n",
       "  'girl': False,\n",
       "  'men': False,\n",
       "  'effort': False,\n",
       "  'lack': False,\n",
       "  'romance': False,\n",
       "  'intelligent': False,\n",
       "  'charming': False,\n",
       "  'modern': False,\n",
       "  'likely': False,\n",
       "  'solid': False,\n",
       "  'face': False,\n",
       "  'john': False,\n",
       "  'theater': False,\n",
       "  'acted': False,\n",
       "  'put': False,\n",
       "  'boring': False,\n",
       "  'debut': False,\n",
       "  'directed': False,\n",
       "  'mostly': False,\n",
       "  'version': False,\n",
       "  'message': False,\n",
       "  'portrait': False,\n",
       "  'fresh': False,\n",
       "  'else': False,\n",
       "  'wit': False,\n",
       "  'actor': False,\n",
       "  'easy': False,\n",
       "  'sort': False,\n",
       "  'certainly': False,\n",
       "  'black': False,\n",
       "  'hours': False,\n",
       "  'shot': False,\n",
       "  'filmmaker': False,\n",
       "  'beautiful': False,\n",
       "  'become': False,\n",
       "  'serious': False,\n",
       "  'heavy': False,\n",
       "  'next': False,\n",
       "  'beautifully': False,\n",
       "  'rare': False,\n",
       "  'play': False,\n",
       "  'fine': False,\n",
       "  'level': False,\n",
       "  'small': False,\n",
       "  'surprisingly': False,\n",
       "  'everyone': False,\n",
       "  'exercise': False,\n",
       "  'along': False,\n",
       "  'culture': False,\n",
       "  'opera': False,\n",
       "  'problem': False,\n",
       "  'slow': False,\n",
       "  'interest': False,\n",
       "  'quirky': False,\n",
       "  'light': False,\n",
       "  'energy': False,\n",
       "  'sure': False,\n",
       "  'french': False,\n",
       "  'lives': False,\n",
       "  'mess': False,\n",
       "  'book': False,\n",
       "  'viewers': False,\n",
       "  'leave': False,\n",
       "  'looks': False,\n",
       "  'classic': False,\n",
       "  'beyond': False,\n",
       "  'ideas': False,\n",
       "  'whether': False,\n",
       "  'powerful': False,\n",
       "  'obvious': False,\n",
       "  'melodrama': False,\n",
       "  'fact': False,\n",
       "  'either': False,\n",
       "  'dramatic': False,\n",
       "  'completely': False,\n",
       "  'past': False,\n",
       "  'must': False,\n",
       "  'believe': False,\n",
       "  'reason': False,\n",
       "  'neither': False,\n",
       "  'adventure': False,\n",
       "  'tone': False,\n",
       "  'live': False,\n",
       "  'filmmaking': False,\n",
       "  'shows': False,\n",
       "  'school': False,\n",
       "  'sex': False,\n",
       "  'production': False,\n",
       "  'recent': False,\n",
       "  'death': False,\n",
       "  'fails': False,\n",
       "  'suspense': False,\n",
       "  'stuff': False,\n",
       "  'delivers': False,\n",
       "  'jokes': False,\n",
       "  'written': False,\n",
       "  'tries': False,\n",
       "  'laugh': False,\n",
       "  'perfect': False,\n",
       "  'left': False,\n",
       "  'intriguing': False,\n",
       "  'truly': False,\n",
       "  'camera': False,\n",
       "  'deeply': False,\n",
       "  'scene': False,\n",
       "  'summer': False,\n",
       "  'reality': False,\n",
       "  'middle': False,\n",
       "  'woman': False,\n",
       "  'ride': False,\n",
       "  'ends': False,\n",
       "  'dumb': False,\n",
       "  'spirit': False,\n",
       "  'head': False,\n",
       "  'close': False,\n",
       "  'simple': False,\n",
       "  'sad': False,\n",
       "  'impossible': False,\n",
       "  'line': False,\n",
       "  'project': False,\n",
       "  'spy': False,\n",
       "  'occasionally': False,\n",
       "  'exactly': False,\n",
       "  'hilarious': False,\n",
       "  'touching': False,\n",
       "  'audiences': False,\n",
       "  'already': False,\n",
       "  'remains': False,\n",
       "  'terrific': False,\n",
       "  'boy': False,\n",
       "  'disney': False,\n",
       "  'formula': False,\n",
       "  'b': False,\n",
       "  'storytelling': False,\n",
       "  'satisfying': False,\n",
       "  'role': False,\n",
       "  'passion': False,\n",
       "  'proves': False,\n",
       "  'seeing': False,\n",
       "  'different': False,\n",
       "  'dead': False,\n",
       "  'easily': False,\n",
       "  'teen': False,\n",
       "  'talent': False,\n",
       "  'got': False,\n",
       "  'pleasure': False,\n",
       "  'crime': False,\n",
       "  'images': False,\n",
       "  'stories': False,\n",
       "  'political': False,\n",
       "  'flat': False,\n",
       "  'attempt': False,\n",
       "  'turn': False,\n",
       "  'gags': False,\n",
       "  'personal': False,\n",
       "  'sequel': False,\n",
       "  'run': False,\n",
       "  'side': False,\n",
       "  'difficult': False,\n",
       "  'particularly': False,\n",
       "  'journey': False,\n",
       "  'honest': False,\n",
       "  'pretentious': False,\n",
       "  'complex': False,\n",
       "  'animation': False,\n",
       "  'mystery': False,\n",
       "  'given': False,\n",
       "  'psychological': False,\n",
       "  'cool': False,\n",
       "  'visually': False,\n",
       "  'falls': False,\n",
       "  'none': False,\n",
       "  'stand': False,\n",
       "  'earnest': False,\n",
       "  'cold': False,\n",
       "  'class': False,\n",
       "  'found': False,\n",
       "  'thin': False,\n",
       "  'intelligence': False,\n",
       "  'social': False,\n",
       "  'case': False,\n",
       "  'second': False,\n",
       "  'ways': False,\n",
       "  'eye': False,\n",
       "  'michael': False,\n",
       "  'top': False,\n",
       "  'hit': False,\n",
       "  'getting': False,\n",
       "  'novel': False,\n",
       "  'leaves': False,\n",
       "  'gone': False,\n",
       "  '2': False,\n",
       "  'game': False,\n",
       "  'told': False,\n",
       "  'tell': False,\n",
       "  'straight': False,\n",
       "  'rock': False,\n",
       "  'cliches': False,\n",
       "  'truth': False,\n",
       "  'budget': False,\n",
       "  'que': False,\n",
       "  'memorable': False,\n",
       "  'violence': False,\n",
       "  'writing': False,\n",
       "  'brilliant': False,\n",
       "  'uses': False,\n",
       "  'help': False,\n",
       "  'concept': False,\n",
       "  'satire': False,\n",
       "  'four': False,\n",
       "  'guys': False,\n",
       "  'rich': False,\n",
       "  'job': False,\n",
       "  'finally': False,\n",
       "  'act': False,\n",
       "  'overall': False,\n",
       "  'soap': False,\n",
       "  'wrong': False,\n",
       "  'nature': False,\n",
       "  'warm': False,\n",
       "  'keeps': False,\n",
       "  'lost': False,\n",
       "  'viewer': False,\n",
       "  'barely': False,\n",
       "  'needs': False,\n",
       "  'rarely': False,\n",
       "  'hero': False,\n",
       "  'creepy': False,\n",
       "  'wild': False,\n",
       "  'otherwise': False,\n",
       "  'elements': False,\n",
       "  'days': False,\n",
       "  'contrived': False,\n",
       "  'deep': False,\n",
       "  'form': False,\n",
       "  'entirely': False,\n",
       "  'mood': False,\n",
       "  'lead': False,\n",
       "  'imagine': False,\n",
       "  'final': False,\n",
       "  'taste': False,\n",
       "  'clear': False,\n",
       "  'running': False,\n",
       "  'moral': False,\n",
       "  'appeal': False,\n",
       "  'approach': False,\n",
       "  'starts': False,\n",
       "  'several': False,\n",
       "  'city': False,\n",
       "  'fi': False,\n",
       "  'white': False,\n",
       "  'possible': False,\n",
       "  'fire': False,\n",
       "  'important': False,\n",
       "  'worthy': False,\n",
       "  'epic': False,\n",
       "  'thoughtful': False,\n",
       "  'moment': False,\n",
       "  'others': False,\n",
       "  'surprising': False,\n",
       "  'insight': False,\n",
       "  'behind': False,\n",
       "  'fairly': False,\n",
       "  'loud': False,\n",
       "  'oscar': False,\n",
       "  'animated': False,\n",
       "  'based': False,\n",
       "  'tragedy': False,\n",
       "  'excellent': False,\n",
       "  'perhaps': False,\n",
       "  'david': False,\n",
       "  'adults': False,\n",
       "  'sci': False,\n",
       "  'call': False,\n",
       "  'eyes': False,\n",
       "  'attention': False,\n",
       "  'period': False,\n",
       "  'wonderful': False,\n",
       "  'future': False,\n",
       "  'tedious': False,\n",
       "  'depth': False,\n",
       "  'result': False,\n",
       "  'start': False,\n",
       "  'expect': False,\n",
       "  'bland': False,\n",
       "  'thoroughly': False,\n",
       "  'among': False,\n",
       "  'entire': False,\n",
       "  'remarkable': False,\n",
       "  'fantasy': False,\n",
       "  'comedies': False,\n",
       "  'imagination': False,\n",
       "  'quality': False,\n",
       "  'parents': False,\n",
       "  'adaptation': False,\n",
       "  'bring': False,\n",
       "  'change': False,\n",
       "  'cute': False,\n",
       "  'witty': False,\n",
       "  'co': False,\n",
       "  'engrossing': False,\n",
       "  'emotionally': False,\n",
       "  'cultural': False,\n",
       "  'guy': False,\n",
       "  'hand': False,\n",
       "  'remake': False,\n",
       "  'sharp': False,\n",
       "  'ii': False,\n",
       "  'cut': False,\n",
       "  'maybe': False,\n",
       "  'worse': False,\n",
       "  'house': False,\n",
       "  'perfectly': False,\n",
       "  'working': False,\n",
       "  'gentle': False,\n",
       "  'tired': False,\n",
       "  'road': False,\n",
       "  'usual': False,\n",
       "  'taking': False,\n",
       "  'add': False,\n",
       "  'gorgeous': False,\n",
       "  'career': False,\n",
       "  'pop': False,\n",
       "  'air': False,\n",
       "  'hope': False,\n",
       "  'genuine': False,\n",
       "  'latest': False,\n",
       "  'single': False,\n",
       "  'la': False,\n",
       "  'nice': False,\n",
       "  'wonder': False,\n",
       "  'fast': False,\n",
       "  'knows': False,\n",
       "  'quiet': False,\n",
       "  'filled': False,\n",
       "  'merely': False,\n",
       "  'strange': False,\n",
       "  'vision': False,\n",
       "  'points': False,\n",
       "  'stupid': False,\n",
       "  'decent': False,\n",
       "  'surprise': False,\n",
       "  'someone': False,\n",
       "  'offer': False,\n",
       "  'joke': False,\n",
       "  'view': False,\n",
       "  'plenty': False,\n",
       "  'inside': False,\n",
       "  'scary': False,\n",
       "  'somewhat': False,\n",
       "  'cheap': False,\n",
       "  'ugly': False,\n",
       "  'water': False,\n",
       "  'appealing': False,\n",
       "  'begins': False,\n",
       "  'winning': False,\n",
       "  'events': False,\n",
       "  'effective': False,\n",
       "  'thanks': False,\n",
       "  'impressive': False,\n",
       "  'beauty': True,\n",
       "  'unfortunately': False,\n",
       "  'pictures': False,\n",
       "  'provides': False,\n",
       "  'however': False,\n",
       "  'playing': False,\n",
       "  'sit': False,\n",
       "  'try': False,\n",
       "  'awful': False,\n",
       "  'able': False,\n",
       "  'highly': False,\n",
       "  'ambitious': False,\n",
       "  'definitely': False,\n",
       "  'emotions': False,\n",
       "  'miss': False,\n",
       "  'lots': False,\n",
       "  'mean': False,\n",
       "  'pure': False,\n",
       "  'hip': False,\n",
       "  'lovely': False,\n",
       "  'america': False,\n",
       "  'magic': False,\n",
       "  'captures': False,\n",
       "  'free': False,\n",
       "  'numbers': False,\n",
       "  'execution': False,\n",
       "  'exciting': False,\n",
       "  'sound': False,\n",
       "  'night': False,\n",
       "  'subtle': False,\n",
       "  'robert': False,\n",
       "  'suffers': False,\n",
       "  'examination': False,\n",
       "  'throughout': False,\n",
       "  'force': False,\n",
       "  'crafted': False,\n",
       "  'sequences': False,\n",
       "  'utterly': False,\n",
       "  'major': False,\n",
       "  'historical': False,\n",
       "  'pace': False,\n",
       "  'memory': False,\n",
       "  'let': False,\n",
       "  'welcome': False,\n",
       "  'grant': False,\n",
       "  'artist': False,\n",
       "  'stars': False,\n",
       "  'female': False,\n",
       "  'open': False,\n",
       "  'soul': False,\n",
       "  'brings': False,\n",
       "  'boys': False,\n",
       "  'ensemble': False,\n",
       "  'issues': False,\n",
       "  'process': False,\n",
       "  'e': False,\n",
       "  '90': False,\n",
       "  'dog': False,\n",
       "  'alone': False,\n",
       "  'certain': False,\n",
       "  'deserves': False,\n",
       "  'read': False,\n",
       "  'ya': False,\n",
       "  'hell': False,\n",
       "  'cartoon': False,\n",
       "  'provocative': False,\n",
       "  'era': False,\n",
       "  'allen': False,\n",
       "  'sustain': False,\n",
       "  'bond': False,\n",
       "  'murder': False,\n",
       "  'sexual': False,\n",
       "  'williams': False,\n",
       "  'felt': False,\n",
       "  'creative': False,\n",
       "  'meaning': False,\n",
       "  'fashioned': False,\n",
       "  'college': False,\n",
       "  'relationship': False,\n",
       "  'potential': False,\n",
       "  'master': False,\n",
       "  'except': False,\n",
       "  'odd': False,\n",
       "  'chemistry': False,\n",
       "  'country': False,\n",
       "  'date': False,\n",
       "  'touch': False,\n",
       "  'length': False,\n",
       "  'quickly': False,\n",
       "  'impact': False,\n",
       "  'words': False,\n",
       "  'spielberg': False,\n",
       "  'across': False,\n",
       "  'wants': False,\n",
       "  'average': False,\n",
       "  'yes': False,\n",
       "  'used': False,\n",
       "  'ago': False,\n",
       "  'actress': False,\n",
       "  'paced': False,\n",
       "  'kid': False,\n",
       "  'deal': False,\n",
       "  'surprises': False,\n",
       "  'question': False,\n",
       "  'urban': False,\n",
       "  'tension': False,\n",
       "  'use': False,\n",
       "  'masterpiece': False,\n",
       "  'delightful': False,\n",
       "  'poignant': False,\n",
       "  'upon': False,\n",
       "  'creates': False,\n",
       "  'flaws': False,\n",
       "  'situation': False,\n",
       "  'sentimental': False,\n",
       "  'rest': False,\n",
       "  'mediocre': False,\n",
       "  'handed': False,\n",
       "  'five': False,\n",
       "  'puts': False,\n",
       "  'trip': False,\n",
       "  'contemporary': False,\n",
       "  'thinking': False,\n",
       "  'unfunny': False,\n",
       "  'money': False,\n",
       "  'fully': False,\n",
       "  'waste': False,\n",
       "  'casting': False,\n",
       "  'girls': False,\n",
       "  'taken': False,\n",
       "  'monster': False,\n",
       "  'formulaic': False,\n",
       "  'generic': False,\n",
       "  'couple': False,\n",
       "  'called': False,\n",
       "  'sensitive': False,\n",
       "  'lacking': False,\n",
       "  'success': False,\n",
       "  'unsettling': False,\n",
       "  'extreme': False,\n",
       "  'unexpected': False,\n",
       "  'talented': False,\n",
       "  'create': False,\n",
       "  'happy': False,\n",
       "  'flawed': False,\n",
       "  'niro': False,\n",
       "  'convincing': False,\n",
       "  'ability': False,\n",
       "  'involved': False,\n",
       "  'sincere': False,\n",
       "  'hardly': False,\n",
       "  'watchable': False,\n",
       "  'previous': False,\n",
       "  'weird': False,\n",
       "  'badly': False,\n",
       "  'crowd': False,\n",
       "  'ultimate': False,\n",
       "  'large': False,\n",
       "  'trouble': False,\n",
       "  'course': False,\n",
       "  'inspired': False,\n",
       "  'giving': False,\n",
       "  'george': False,\n",
       "  'century': False,\n",
       "  'leads': False,\n",
       "  'plain': False,\n",
       "  'slight': False,\n",
       "  'hold': False,\n",
       "  'focus': False,\n",
       "  'living': False,\n",
       "  'remember': False,\n",
       "  'mildly': False,\n",
       "  'forgettable': False,\n",
       "  'extremely': False,\n",
       "  'saw': False,\n",
       "  'apart': False,\n",
       "  'em': False,\n",
       "  'grace': False,\n",
       "  'supposed': False,\n",
       "  'routine': False,\n",
       "  'crush': False,\n",
       "  'cannot': False,\n",
       "  'seriously': False,\n",
       "  'episode': False,\n",
       "  'reveals': False,\n",
       "  'mix': False,\n",
       "  'mark': False,\n",
       "  'slightly': False,\n",
       "  'jackson': False,\n",
       "  'melodramatic': False,\n",
       "  'key': False,\n",
       "  'relationships': False,\n",
       "  'largely': False,\n",
       "  'attempts': False,\n",
       "  'room': False,\n",
       "  'name': False,\n",
       "  'problems': False,\n",
       "  '2002': False,\n",
       "  'substance': False,\n",
       "  'ill': False,\n",
       "  'es': False,\n",
       "  'dry': False,\n",
       "  'york': False,\n",
       "  'amount': False,\n",
       "  'finds': False,\n",
       "  'uneven': False,\n",
       "  'terms': False,\n",
       "  'indeed': False,\n",
       "  'crazy': False,\n",
       "  'company': False,\n",
       "  'steven': False,\n",
       "  'thrills': False,\n",
       "  'sets': False,\n",
       "  'twists': False,\n",
       "  'flicks': False,\n",
       "  'blue': False,\n",
       "  'pleasant': False,\n",
       "  'gross': False,\n",
       "  'ones': False,\n",
       "  'ms': False,\n",
       "  'tragic': False,\n",
       "  'pacing': False,\n",
       "  'provoking': False,\n",
       "  'stylish': False,\n",
       "  'fiction': False,\n",
       "  'treat': False,\n",
       "  'succeeds': False,\n",
       "  'gripping': False,\n",
       "  'inventive': False,\n",
       "  'intimate': False,\n",
       "  'sports': False,\n",
       "  'unique': False,\n",
       "  'themes': False,\n",
       "  'effect': False,\n",
       "  'meditation': False,\n",
       "  'complete': False,\n",
       "  'lame': False,\n",
       "  'soundtrack': False,\n",
       "  'goofy': False,\n",
       "  'interested': False,\n",
       "  'drag': False,\n",
       "  'red': False,\n",
       "  'promise': False,\n",
       "  'terrible': False,\n",
       "  'viewing': False,\n",
       "  'poetry': False,\n",
       "  'green': False,\n",
       "  'twist': False,\n",
       "  'standard': False,\n",
       "  'involving': False,\n",
       "  'television': False,\n",
       "  'word': False,\n",
       "  'sophisticated': False,\n",
       "  'runs': False,\n",
       "  'gay': False,\n",
       "  'indulgent': False,\n",
       "  'happens': False,\n",
       "  'business': False,\n",
       "  'heaven': False,\n",
       "  'painful': False,\n",
       "  'blood': False,\n",
       "  'successful': False,\n",
       "  'cross': False,\n",
       "  'recommend': False,\n",
       "  'person': False,\n",
       "  'near': False,\n",
       "  'considerable': False,\n",
       "  'edge': False,\n",
       "  'presents': False,\n",
       "  '10': False,\n",
       "  'bright': False,\n",
       "  'absolutely': False,\n",
       "  'x': False,\n",
       "  'appears': False,\n",
       "  'friendship': False,\n",
       "  'hits': False,\n",
       "  'colorful': False,\n",
       "  'missing': False,\n",
       "  'played': False,\n",
       "  'triumph': False,\n",
       "  'disturbing': False,\n",
       "  'skin': False,\n",
       "  'refreshing': False,\n",
       "  'typical': False,\n",
       "  'clichs': False,\n",
       "  'forced': False,\n",
       "  'wanted': False,\n",
       "  'forget': False,\n",
       "  'evil': False,\n",
       "  'brain': False,\n",
       "  'sandler': False,\n",
       "  'ice': False,\n",
       "  'target': False,\n",
       "  'share': False,\n",
       "  'franchise': False,\n",
       "  'talk': False,\n",
       "  'murphy': False,\n",
       "  'strangely': False,\n",
       "  'core': False,\n",
       "  'wise': False,\n",
       "  'wife': False,\n",
       "  'situations': False,\n",
       "  'equally': False,\n",
       "  'conflict': False,\n",
       "  'general': False,\n",
       "  'parts': False,\n",
       "  'loses': False,\n",
       "  'british': False,\n",
       "  'poor': False,\n",
       "  'tom': False,\n",
       "  'hot': False,\n",
       "  'frame': False,\n",
       "  'bizarre': False,\n",
       "  'pieces': False,\n",
       "  'hate': False,\n",
       "  'non': False,\n",
       "  'blend': False,\n",
       "  'break': False,\n",
       "  'stunning': False,\n",
       "  'politics': False,\n",
       "  'somehow': False,\n",
       "  'manner': False,\n",
       "  'fan': False,\n",
       "  'constructed': False,\n",
       "  'dream': False,\n",
       "  'absorbing': False,\n",
       "  'sentimentality': False,\n",
       "  'originality': False,\n",
       "  'imax': False,\n",
       "  'somewhere': False,\n",
       "  'said': False,\n",
       "  'please': False,\n",
       "  'report': False,\n",
       "  'match': False,\n",
       "  'questions': False,\n",
       "  'punch': False,\n",
       "  'battle': False,\n",
       "  'huge': False,\n",
       "  'space': False,\n",
       "  'el': False,\n",
       "  'derivative': False,\n",
       "  'fat': False,\n",
       "  'wedding': False,\n",
       "  'doubt': False,\n",
       "  'holds': False,\n",
       "  'beat': False,\n",
       "  'eventually': False,\n",
       "  'understand': False,\n",
       "  'follow': False,\n",
       "  'peter': False,\n",
       "  'cliche': False,\n",
       "  'tells': False,\n",
       "  'setting': True,\n",
       "  'today': False,\n",
       "  'depressing': False,\n",
       "  'moore': False,\n",
       "  'guilty': False,\n",
       "  'whatever': False,\n",
       "  'sexy': False,\n",
       "  'soderbergh': False,\n",
       "  'virtually': False,\n",
       "  'car': False,\n",
       "  'liked': False,\n",
       "  'means': False,\n",
       "  'central': False,\n",
       "  'child': False,\n",
       "  'god': False,\n",
       "  'painfully': False,\n",
       "  'post': False,\n",
       "  'lines': False,\n",
       "  'created': False,\n",
       "  'energetic': False,\n",
       "  'alive': False,\n",
       "  'obviously': False,\n",
       "  'popcorn': False,\n",
       "  'loss': False,\n",
       "  'tough': False,\n",
       "  'fare': False,\n",
       "  'haunting': False,\n",
       "  'grief': False,\n",
       "  'affecting': False,\n",
       "  'possibly': False,\n",
       "  'footage': False,\n",
       "  'party': False,\n",
       "  'deliver': False,\n",
       "  ...},\n",
       " 'pos')"
      ]
     },
     "metadata": {},
     "execution_count": 248
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "source": [
    "split_on = int(len(data_set)*.8)\r\n",
    "X_y_train = data_set[:split_on]\r\n",
    "X_y_test = data_set[split_on:]\r\n",
    "print(len(X_y_train))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "source": [
    "clf = nltk.NaiveBayesClassifier.train(X_y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "source": [
    "clf.show_most_informative_features(15)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most Informative Features\n",
      "                    warm = True              pos : neg    =     12.6 : 1.0\n",
      "                  boring = True              neg : pos    =     12.1 : 1.0\n",
      "                    flat = True              neg : pos    =     12.1 : 1.0\n",
      "                touching = True              pos : neg    =     11.9 : 1.0\n",
      "                    dull = True              neg : pos    =     10.4 : 1.0\n",
      "                   falls = True              neg : pos    =     10.1 : 1.0\n",
      "                  reason = True              neg : pos    =     10.1 : 1.0\n",
      "                 perfect = True              pos : neg    =      9.2 : 1.0\n",
      "                   sharp = True              pos : neg    =      9.2 : 1.0\n",
      "                   title = True              neg : pos    =      8.5 : 1.0\n",
      "                captures = True              pos : neg    =      8.5 : 1.0\n",
      "               brilliant = True              pos : neg    =      7.8 : 1.0\n",
      "             examination = True              pos : neg    =      7.8 : 1.0\n",
      "                 tedious = True              neg : pos    =      7.6 : 1.0\n",
      "                   fails = True              neg : pos    =      7.2 : 1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "source": [
    "# Convert to nltk classifiers \r\n",
    "MNNB_classifier= SklearnClassifier(MultinomialNB())\r\n",
    "\r\n",
    "lr_classifier = SklearnClassifier(LogisticRegression())\r\n",
    "\r\n",
    "svc_clf = SklearnClassifier(SVC())\r\n",
    "\r\n",
    "lin_svc_clf= SklearnClassifier(LinearSVC())\r\n",
    "\r\n",
    "nu_svc_clf = SklearnClassifier(NuSVC())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "source": [
    "# native nltk classifier\r\n",
    "clf= nltk.NaiveBayesClassifier.train(X_y_train) \r\n",
    "\r\n",
    "print('Accuracy nltk.NaiveBayesClassifier={}%'.format(nltk.classify.accuracy(clf,X_y_test) * 100))\r\n",
    "# clf.show_most_informative_features(15)\r\n",
    "\r\n",
    "MNNB_classifier.train(X_y_train)\r\n",
    "print('Accuracy MNNB_classifier ={}%'.format(nltk.classify.accuracy(MNNB_classifier, X_y_test) * 100))\r\n",
    "\r\n",
    "lr_classifier.train(X_y_train)\r\n",
    "print('Accuracy lr_classifier ={}%'.format(nltk.classify.accuracy(lr_classifier, X_y_test) * 100))\r\n",
    "\r\n",
    "svc_clf.train(X_y_train)\r\n",
    "print('Accuracy svc_clf={}%'.format(nltk.classify.accuracy(svc_clf, X_y_test) * 100))\r\n",
    "\r\n",
    "lin_svc_clf.train(X_y_train)\r\n",
    "print('Accuracy lin_svc_clf={}%'.format(nltk.classify.accuracy(lin_svc_clf, X_y_test) * 100))\r\n",
    "\r\n",
    "nu_svc_clf.train(X_y_train)\r\n",
    "print('Accuracy nu_svc_clf={}%'.format(nltk.classify.accuracy(nu_svc_clf, X_y_test) * 100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy nltk.NaiveBayesClassifier=75.7%\n",
      "Accuracy MNNB_classifier =76.7%\n",
      "Accuracy lr_classifier =73.6%\n",
      "Accuracy svc_clf=72.8%\n",
      "Accuracy lin_svc_clf=70.0%\n",
      "Accuracy nu_svc_clf=73.4%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Second method. Using Sklearn"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "source": [
    "import pandas as pd\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import roc_auc_score, f1_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "source": [
    "pos_texts_with_cat = [[sentence, 1] for sentence in full_pos.splitlines()]\r\n",
    "neg_texts_with_cat = [[sentence, 0] for sentence in full_neg.splitlines()]\r\n",
    "\r\n",
    "all_texts = pos_texts_with_cat + neg_texts_with_cat\r\n",
    "\r\n",
    "df = pd.DataFrame(all_texts, columns=[\"text\", \"binary_attitude\"])\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>binary_attitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  binary_attitude\n",
       "0  the rock is destined to be the 21st century's ...                1\n",
       "1  the gorgeously elaborate continuation of \" the...                1\n",
       "2                     effective but too-tepid biopic                1\n",
       "3  if you sometimes like to go to the movies to h...                1\n",
       "4  emerges as something rare , an issue movie tha...                1"
      ]
     },
     "metadata": {},
     "execution_count": 275
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['binary_attitude'], random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "source": [
    "vect = CountVectorizer().fit(X_train)\r\n",
    "print('features samples:\\n{}'.format(vect.get_feature_names()[::2000]))\r\n",
    "print ('\\nlen of features {:,}'.format(len(vect.get_feature_names())))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "features samples:\n",
      "['00', 'bv', 'discordant', 'genres', 'labour', 'overstylized', 'rotting', 'tackles', 'zest']\n",
      "\n",
      "len of features 16,021\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "source": [
    "X_train_vectorized = vect.transform(X_train)\r\n",
    "print(X_train_vectorized[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (0, 178)\t1\n",
      "  (0, 930)\t2\n",
      "  (0, 1331)\t1\n",
      "  (0, 3396)\t1\n",
      "  (0, 5770)\t1\n",
      "  (0, 6529)\t1\n",
      "  (0, 6767)\t1\n",
      "  (0, 7407)\t1\n",
      "  (0, 7610)\t1\n",
      "  (0, 7622)\t1\n",
      "  (0, 8075)\t1\n",
      "  (0, 9738)\t1\n",
      "  (0, 12177)\t1\n",
      "  (0, 12681)\t1\n",
      "  (0, 15243)\t1\n",
      "  (0, 15595)\t1\n",
      "  (0, 15652)\t1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "source": [
    "df = pd.DataFrame(X_train_vectorized[0].toarray(), index=[\"value\"]).T\r\n",
    "df[df[\"value\"] > 0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5770</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6529</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6767</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7407</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7622</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8075</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9738</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12177</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12681</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15243</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15595</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15652</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       value\n",
       "178        1\n",
       "930        2\n",
       "1331       1\n",
       "3396       1\n",
       "5770       1\n",
       "6529       1\n",
       "6767       1\n",
       "7407       1\n",
       "7610       1\n",
       "7622       1\n",
       "8075       1\n",
       "9738       1\n",
       "12177      1\n",
       "12681      1\n",
       "15243      1\n",
       "15595      1\n",
       "15652      1"
      ]
     },
     "metadata": {},
     "execution_count": 279
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "source": [
    "print(list(df[df[\"value\"] > 0].index))\r\n",
    "[vect.get_feature_names()[index] for index in df[df[\"value\"] > 0].index.values]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[178, 930, 1331, 3396, 5770, 6529, 6767, 7407, 7610, 7622, 8075, 9738, 12177, 12681, 15243, 15595, 15652]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['about',\n",
       " 'as',\n",
       " 'been',\n",
       " 'cutting',\n",
       " 'fresh',\n",
       " 'have',\n",
       " 'hollywood',\n",
       " 'instead',\n",
       " 'is',\n",
       " 'issue',\n",
       " 'last',\n",
       " 'of',\n",
       " 'satire',\n",
       " 'should',\n",
       " 'variety',\n",
       " 'week',\n",
       " 'what']"
      ]
     },
     "metadata": {},
     "execution_count": 280
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "source": [
    "clf = LogisticRegression(max_iter=2000, C=2, solver=\"saga\").fit(X_train_vectorized, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "source": [
    "predictions = clf.predict(vect.transform(X_test))\r\n",
    "print(f\"f1: {f1_score(y_test, predictions)}\")\r\n",
    "scores = clf.decision_function(vect.transform(X_test))\r\n",
    "print(f\"AUC: {roc_auc_score(y_test, scores)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f1: 0.7700374531835205\n",
      "AUC: 0.8437597304938264\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "source": [
    "feature_names = np.array(vect.get_feature_names())\r\n",
    "sorted_coef_index = clf.coef_[0].argsort()\r\n",
    "print(f\"Smallest coefs:\\n{feature_names[sorted_coef_index[:10]]}\\n\")\r\n",
    "print(f\"Largest Coefs: \\n{feature_names[sorted_coef_index[:-11:-1]]}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Smallest coefs:\n",
      "['dull' 'waste' 'boring' 'bore' 'neither' 'problem' 'worst'\n",
      " 'disappointment' 'suffers' 'supposed']\n",
      "\n",
      "Largest Coefs: \n",
      "['masterpiece' 'thanks' 'liberating' 'unflinching' 'enjoyable'\n",
      " 'entertaining' 'remarkable' 'glorious' 'engrossing' 'solid']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = green >\r\n",
    "\r\n",
    "## Learn more\r\n",
    "</font>\r\n",
    "\r\n",
    "sklearn.feature_extraction.text.CountVectorizer\r\n",
    "<br>\r\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\r\n",
    "\r\n",
    "Bag-of-words model\r\n",
    "<br>\r\n",
    "https://en.wikipedia.org/wiki/Bag-of-words_model\r\n",
    "\r\n",
    "tfidf\r\n",
    "<br>\r\n",
    "https://en.wikipedia.org/wiki/Tf%E2%80%93idf\r\n",
    "\r\n",
    "sklearn.feature_extraction.text.TfidfVectorizer\r\n",
    "<br>\r\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\r\n",
    "\r\n",
    "Applied Text Mining in Python\r\n",
    "<br>\r\n",
    "https://www.coursera.org/learn/python-text-mining/home/welcome\r\n",
    "\r\n",
    "Natural Language Processing tutorial\r\n",
    "<br>\r\n",
    "https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "<font color = green >\n",
    "\n",
    "## Next lesson: topic modeling \n",
    "</font>\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "interpreter": {
   "hash": "472c026ac2569fdbd4a7bd0058fc52d81c15d27b6366e23ecde7104f403cf5a1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}