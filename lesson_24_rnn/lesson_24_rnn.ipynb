{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"lesson_24_rnn.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"nPujIuUGptPO"},"source":["<font color = green >\n","\n","# Recurrent neural networks \n","\n","</font>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6LYAkqpRptPm"},"source":["\n","\n","<font color = green >\n","\n","## Samples or sequences to sequence problems\n","\n","</font>\n","\n","\n","\n","<table align=\"left\">\n","<tr>\n","    <td>Speech recogniiton</td>\n","    <td><img src = \"images/lesson_21_waves.jpg\" align = 'left' width = 100, heaight = 100> </td>\n","    <td>Machine learning provides computer systems the ability <br> \n","         to learn without being explicitly programmed\n","    </td>\n","</tr>\n","<tr>\n","    <td>Machine translation</td>\n","    <td> 機器學習為計算機系統提供了能力\n","          在沒有明確編程的情況下學習\n","    </td>\n","    <td>Machine learning provides computer systems the ability <br> \n","         to learn without being explicitly programmed\n","    </td>\n","</tr>\n","<tr>\n","    <td>Video activity recognition</td>\n","    <td><img src = \"images/lesson_21_var.png\" align = 'left' width = 100, heaight = 100> \n","    </td>\n","    <td>Start running\n","    </td>\n","</tr>\n","<tr>\n","    <td>Named entity recognition</td>\n","    <td>Michael arrived to New York from Boston  in 21 Sep 1978 \n","    </td>\n","    <td>Person: Michael<br>Location: New York, Boston<br> date: 1978/09/21 \n","    </td>\n","</tr>\n","\n","<tr>\n","    <td>Sentiment analysis</td>\n","    <td> It was not as terrifying enough for thriller as expected\n","    </td>\n","    <td><img src = \"images/lesson_21_stars.jpg\" align = 'left' width = 100, heaight = 100>\n","    </td>\n","</tr>\n","\n","</table>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mBLV5b_YptPq"},"source":["<font color = green >\n","\n","## Notation\n","\n","</font>\n","\n","For example `named entity recognition`.\n","\n","Some sample $(x,y) = (X^{(i)},Y^{(i)})$\n","\n","<img src = \"images/lesson_21_notation2.png\" align = 'left' width = 600, heaight = 600> \n","\n","<div style=\"clear:left;\"></div>\n","Len of input $T_{x}=11; \\quad$ Len of output $T_{y}=11$ \n","\n","Note: $T_{x}$ and $T_{y}$ may differ\n","\n","Each $x^{<t>}$ is represented as one-hot vector built being based on some vocabulary (e.g. 10,000 most frequent words + `\"UNK\"` + `\"EOS\"`). \n","<br> Shape of every sample $x = (vocab\\_size, T_{x}) $\n","\n","Each $y^{<t>}$ is represented as one-hot vector built being based on number of entities types \n","<br> Shape of  of every sample $y= (entity\\_num, T_{y}) $\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UQyerHRvptPt"},"source":["<font color = green >\n","\n","## RNN structure\n","\n","\n","</font>\n","\n","Every cell contains the same parameters \n","\n","<img src = \"images/lesson_21_rnn_simple1.png\" align = 'left' width = 800, heaight = 800> \n","\n","<div style=\"clear:left;\"></div>\n","$$A^{<0>}=0$$<br>\n","$$A^{<t>}= g_{a}(W_{aa}@ A^{<t-1>} + W_{ax}@ x^{<t>}+ b_{a}), \\quad (g_{a} \\text{is usually RELU/tanh)}$$ <br>\n","$$y^{<t>}= g_{y}(W_{ay}@ A^{<t>} + b_{y}), \\quad (g_{y} \\text{ is usually sigmoid/softmax)}$$\n","\n","<br>\n"]},{"cell_type":"markdown","metadata":{"id":"UEgyP5U8ptPw"},"source":["<font color = green >\n","\n","## RNN cell\n","\n","</font>\n","\n","<img src = \"images/lesson_21_rnn_cell2.png\" align = 'left' width = 500, heaight = 500> \n","\n"]},{"cell_type":"markdown","metadata":{"id":"c-dYZfMBptPy"},"source":["<font color = green >\n","\n","## RNN types samples\n","\n","</font>\n","\n","<img src = \"images/lesson_21_oto.png\" align = 'left' width = 100, heaight = 100> \n","<img src = \"images/lesson_21_mto.png\" align = 'left' width = 400, heaight = 400> \n","<img src = \"images/lesson_21_otm.png\" align = 'left' width = 400, heaight = 400> \n","<div style=\"clear:left;\"></div>\n","<img src = \"images/lesson_21_mtm.png\" align = 'left'  width = 400, heaight = 400> \n","<img src = \"images/lesson_21_mtm1.png\" align = 'left'  width = 400, heaight = 400> \n","\n","\n","<img src = \"images/lesson_21_ed.png\" align = 'left'  width = 400, heaight = 400> \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Pz-9CslyptP0"},"source":["<font color = green >\n","\n","## Language model\n","\n","</font>\n","\n","Language model is a probability distribution over sequences of words.\n","<br>It provides ability to estimate the relative likelihood of similar words and phrases e.g.<br>\n","$\\quad P(\\text{\"recognize speech\"}) \\quad \\text{and} \\quad P(\\text{\"wreck a nice beach\"}) $\n","\n","Usually the task is to compare probability of different words following by some context of $n$ previous words ($n$-gram)  e.g. $\\quad P(\\text{\"beings\"} | \\text{\"we are human\"}) \\quad \\text{and} \\quad P(\\text{\"beans\"} | \\text{\"we are human\"}) $\n","\n","RNN is one of implementations of Language model.\n","\n","<font color = green >\n","\n","### Implementation steps\n","\n","</font>\n","\n","1. Get corpus (large text)\n","2. Tokenize and build vocabulary of tokens (make sure to have + `\"UNK\"` for words out of vocabulary  and `\"EOS\"` to denote end of sentence)\n","3. Prepare training set by tokenizing to sentence. \n","If the sentence is `Pluto is the largest dwarf planet in the Solar System`, then \n","\n","<img src = \"images/lesson_21_lm1.png\" align = 'left' width = 800, heaight = 800> \n","<div style=\"clear:left;\"></div>\n","4. Compute cost \n","$\\mathcal {L} = \\sum \\limits_{i=1}^{m} \\sum \\limits_{t=1}^{T_{X_{i}}} y_{i}^{<t>} log \\,\\hat y_{i}^{<t>} $\n","<br>Note: if the task is to predict the only following word after $n$-gram context then cost msy include the only last output $\\mathcal {L} = \\sum \\limits_{i=1}^{m}  y_{i}^{<T_{y_{i}}>} log \\,\\hat y_{i}^{<T_{y_{i}}>} $\n","<br>5. Run optimization. <br>\n","6. Having trained model, all $\\hat y^{<1>}, \\hat y^{<2>},... \\hat y^{<T_{y}>}$ are probabilty distributions over vocabulary tokens (outputs of corresponding softmax layer) \n","<br>So you may compute $P$(\"Pluto\") from $\\hat y^{<1>}$, $P$(\"is\"|\"Pluto\") from $\\hat y^{<2>}$ and so get the probability of phrase to compare with another phrase.\n"]},{"cell_type":"markdown","metadata":{"id":"tpWMj3T3ptP2"},"source":["\n","<font color = green >\n","\n","### Sampling\n","\n","</font>\n","\n","Sampling is performed being based on probability distribution (outputs of corresponding softmax layer).\n","<br>You may configure how much strictly to sample the word - from selecting the most probable word to consider all words with the same probability and as the result pick random word from all vocabulary.\n","<img src = \"images/lesson_21_sampling.png\" align = 'left' width = 800, heaight = 800> \n","\n","<div style=\"clear:left;\"></div>\n","Note: \n","\n","- You need to resample in case of \"UNK\" is generated.\n","- You may stop sampling by setting the limit in case of \"EOS\" is not generated for long.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-dkUacALptP3"},"source":["\n","<font color = green >\n","\n","## Sample 1: Language model using numpy  \n","\n","</font>\n","\n","Character level language model is implemented as RNN for dinosaurus names\n"]},{"cell_type":"code","metadata":{"id":"TovkrKIdptP6"},"source":["# import os\n","# cwd= os.getcwd()\n","# path = os.path.join(cwd,'data')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CCqqq_1Lrt4j","executionInfo":{"status":"ok","timestamp":1634482404006,"user_tz":-180,"elapsed":307,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"5d4b2f4e-2b2e-4825-e038-b9e167b3e1b7"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"BHKIpkyQptP-","executionInfo":{"status":"ok","timestamp":1634482557741,"user_tz":-180,"elapsed":147849,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"951493be-281d-4782-946f-d63f30013606"},"source":["import numpy as np\n","import random\n","\n","\n","def softmax(x):\n","    e_x = np.exp(x - np.max(x))\n","    return e_x / e_x.sum(axis=0)\n","\n","\n","def print_sample(sample_ix, ix_to_char):\n","    txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n","    txt = txt[0].upper() + txt[1:]  # capitalize first character\n","    print('%s' % (txt,), end='')\n","\n","\n","def initialize_parameters(n_a, n_x, n_y):\n","    \"\"\"\n","    Initialize parameters with small random values\n","\n","    Returns:\n","    parameters -- python dictionary containing:\n","                        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)\n","                        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)\n","                        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n","                        b --  Bias, numpy array of shape (n_a, 1)\n","                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n","    \"\"\"\n","    np.random.seed(1)\n","    Wax = np.random.randn(n_a, n_x) * 0.01  \n","    Waa = np.random.randn(n_a, n_a) * 0.01  \n","    Wya = np.random.randn(n_y, n_a) * 0.01  \n","    b = np.zeros((n_a, 1))  \n","    by = np.zeros((n_y, 1))  \n","\n","    parameters = {\"Wax\": Wax, \"Waa\": Waa, \"Wya\": Wya, \"b\": b, \"by\": by}\n","\n","    return parameters\n","\n","\n","def rnn_step_forward(parameters, a_prev, x):\n","    Waa, Wax, Wya, by, b = parameters['Waa'], parameters['Wax'], parameters['Wya'], parameters['by'], parameters['b']\n","    a_next = np.tanh(np.dot(Wax, x) + np.dot(Waa, a_prev) + b)  # hidden state\n","    p_t = softmax(\n","        np.dot(Wya, a_next) + by)  # unnormalized log probabilities for next chars # probabilities for next chars\n","\n","    return a_next, p_t\n","\n","\n","def rnn_step_backward(dy, gradients, parameters, x, a, a_prev):\n","    gradients['dWya'] += np.dot(dy, a.T)\n","    gradients['dby'] += dy\n","    da = np.dot(parameters['Wya'].T, dy) + gradients['da_next']  # backprop into h\n","    daraw = (1 - a * a) * da  # backprop through tanh nonlinearity\n","    gradients['db'] += daraw\n","    gradients['dWax'] += np.dot(daraw, x.T)\n","    gradients['dWaa'] += np.dot(daraw, a_prev.T)\n","    gradients['da_next'] = np.dot(parameters['Waa'].T, daraw)\n","    return gradients\n","\n","\n","def update_parameters(parameters, gradients, lr):\n","    parameters['Wax'] += -lr * gradients['dWax']\n","    parameters['Waa'] += -lr * gradients['dWaa']\n","    parameters['Wya'] += -lr * gradients['dWya']\n","    parameters['b'] += -lr * gradients['db']\n","    parameters['by'] += -lr * gradients['dby']\n","    return parameters\n","\n","\n","def rnn_forward(X, Y, a0, parameters, vocab_size=27):\n","    # Initialize x, a and y_hat as empty dictionaries\n","    x, a, y_hat = {}, {}, {}\n","\n","    a[-1] = np.copy(a0)\n","\n","    # initialize your loss to 0\n","    loss = 0\n","\n","    for t in range(len(X)):\n","        # Set x[t] to be the one-hot vector representation of the t'th character in X.        \n","        x[t] = np.zeros((vocab_size, 1))\n","        if (X[t] != None):\n","            x[t][X[t]] = 1\n","\n","        # Run one step forward of the RNN\n","        a[t], y_hat[t] = rnn_step_forward(parameters, a[t - 1], x[t])\n","\n","        # Update the loss by substracting the cross-entropy term of this time-step from it.\n","        loss -= np.log(y_hat[t][Y[t], 0])\n","\n","    cache = (y_hat, a, x)\n","\n","    return loss, cache\n","\n","\n","def rnn_backward(X, Y, parameters, cache):\n","    # Initialize gradients as an empty dictionary\n","    gradients = {}\n","\n","    # Retrieve from cache and parameters\n","    (y_hat, a, x) = cache\n","    Waa, Wax, Wya, by, b = parameters['Waa'], parameters['Wax'], parameters['Wya'], parameters['by'], parameters['b']\n","\n","    # each one should be initialized to zeros of the same dimension as its corresponding parameter\n","    gradients['dWax'], gradients['dWaa'], gradients['dWya'] = np.zeros_like(Wax), np.zeros_like(Waa), np.zeros_like(Wya)\n","    gradients['db'], gradients['dby'] = np.zeros_like(b), np.zeros_like(by)\n","    gradients['da_next'] = np.zeros_like(a[0])\n","\n","\n","    # Backpropagate\n","    for t in reversed(range(len(X))):\n","        dy = np.copy(y_hat[t])\n","        dy[Y[t]] -= 1\n","        gradients = rnn_step_backward(dy, gradients, parameters, x[t], a[t], a[t - 1])\n","\n","\n","    return gradients, a\n","\n","\n","def clip(gradients, maxValue):\n","    '''\n","    Clips the gradients' values between minimum and maximum.\n","\n","    Arguments:\n","    gradients - a dictionary containing the gradients \"dWaa\", \"dWax\", \"dWya\", \"db\", \"dby\"\n","    maxValue - everything above this number is set to this number, and everything less than -maxValue is set to -maxValue\n","\n","    Returns:\n","    gradients - a dictionary with the clipped gradients.\n","    '''\n","\n","    dWaa, dWax, dWya, db, dby = gradients['dWaa'], gradients['dWax'], gradients['dWya'], gradients['db'], gradients[\n","        'dby']\n","    # clip to mitigate exploding gradients\n","    for gradient in [dWax, dWaa, dWya, db, dby]:\n","        np.clip(gradient, -maxValue, maxValue, out=gradient)\n","\n","    gradients = {\"dWaa\": dWaa, \"dWax\": dWax, \"dWya\": dWya, \"db\": db, \"dby\": dby}\n","\n","    return gradients\n","\n","\n","def sample(parameters, char_to_ix, seed):\n","    \"\"\"\n","    Sample a sequence of characters according to a sequence of probability distributions output of the RNN\n","\n","    Arguments:\n","    parameters -- python dictionary containing the parameters Waa, Wax, Wya, by, and b.\n","    char_to_ix -- python dictionary mapping each character to an index.\n","    seed -- used for grading purposes. Do not worry about it.\n","\n","    Returns:\n","    indices -- a list of length n containing the indices of the sampled characters.\n","    \"\"\"\n","\n","    # Retrieve parameters and relevant shapes from \"parameters\" dictionary\n","    Waa, Wax, Wya, by, b = parameters['Waa'], parameters['Wax'], parameters['Wya'], parameters['by'], parameters['b']\n","    vocab_size = by.shape[0]\n","    n_a = Waa.shape[1]\n","\n","    # Create the vector x for the first character (initializing the sequence generation)\n","    x = np.zeros((vocab_size, 1)) \n","    # Initialize a_prev as zeros\n","    a_prev = np.zeros(shape=(n_a, 1))\n","    # Create an empty list of indices, this is the list which will contain the list of indices of the characters to generate\n","    indices = []\n","\n","    # Idx is a flag to detect a newline character, we initialize it to -1\n","    idx = -1  # this is just to pass the first while condition\n","\n","    # Loop over time-steps t. At each time-step, sample a character from a probability distribution and append\n","    # its index to \"indices\". We'll stop if we reach 50 characters \n","    counter = 0\n","    newline_character = char_to_ix['\\n']\n","\n","    while (idx != newline_character and counter != 50):\n","        # Forward propagate \n","        a = np.tanh(Wax @ x + Waa @ a_prev + b)\n","        z = Wya @ a + by\n","        y = softmax(z)\n","\n","        np.random.seed(counter + seed)\n","\n","        # Sample the index of a character within the vocabulary from the probability distribution y\n","        idx = np.random.choice(vocab_size, p=y.ravel())\n","\n","        # Append the index to \"indices\"\n","        indices.append(idx)\n","\n","        # Overwrite the input character as the one corresponding to the sampled index.\n","        x = np.zeros(shape=(vocab_size, 1))\n","        x[idx] = 1\n","        # Update \"a_prev\" to be \"a\"\n","        a_prev = a\n","\n","        # for grading purposes\n","        seed += 1\n","        counter += 1\n","\n","    if (counter == 50):\n","        indices.append(char_to_ix['\\n'])\n","\n","    return indices\n","\n","\n","def optimize(X, Y, a_prev, parameters, learning_rate=0.01):\n","    \"\"\"\n","    Execute one step of the optimization to train the model.\n","\n","    Arguments:\n","    X -- list of integers, where each integer is a number that maps to a character in the vocabulary.\n","    Y -- list of integers, exactly the same as X but shifted one index to the left.\n","    a_prev -- previous hidden state.\n","    parameters -- python dictionary containing:\n","                        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)\n","                        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)\n","                        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n","                        b --  Bias, numpy array of shape (n_a, 1)\n","                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n","    learning_rate -- learning rate for the model.\n","\n","    Returns:\n","    loss -- value of the loss function (cross-entropy)\n","    gradients -- python dictionary containing:\n","                        dWax -- Gradients of input-to-hidden weights, of shape (n_a, n_x)\n","                        dWaa -- Gradients of hidden-to-hidden weights, of shape (n_a, n_a)\n","                        dWya -- Gradients of hidden-to-output weights, of shape (n_y, n_a)\n","                        db -- Gradients of bias vector, of shape (n_a, 1)\n","                        dby -- Gradients of output bias vector, of shape (n_y, 1)\n","    a[len(X)-1] -- the last hidden state, of shape (n_a, 1)\n","    \"\"\"\n","\n","    # Forward propagate through time\n","    loss, cache = rnn_forward(X, Y, a_prev, parameters)\n","\n","    # Backpropagate through time \n","    gradients, a = rnn_backward(X, Y, parameters, cache)\n","\n","    # Clip your gradients between -5 (min) and 5 (max) \n","    gradients = clip(gradients, 5)\n","\n","    # Update parameters (≈1 line)\n","    parameters = update_parameters(parameters, gradients, learning_rate)\n","\n","    return loss, gradients, a[len(X) - 1]\n","\n","\n","def model(data, ix_to_char, char_to_ix, num_iterations=100000, n_a=50, dino_names=7, vocab_size=27):\n","    \"\"\"\n","    Trains the model and generates dinosaur names.\n","\n","    Arguments:\n","    data -- text corpus\n","    ix_to_char -- dictionary that maps the index to a character\n","    char_to_ix -- dictionary that maps a character to an index\n","    num_iterations -- number of iterations to train the model for\n","    n_a -- number of units of the RNN cell\n","    dino_names -- number of dinosaur names you want to sample at each iteration.\n","    vocab_size -- number of unique characters found in the text, size of the vocabulary\n","\n","    Returns:\n","    parameters -- learned parameters\n","    \"\"\"\n","\n","    # Retrieve n_x and n_y from vocab_size\n","    n_x, n_y = vocab_size, vocab_size\n","\n","    # Initialize parameters\n","    parameters = initialize_parameters(n_a, n_x, n_y)\n","\n","    # Build list of all dinosaur names (training examples).\n","    with open(fn) as f:\n","        examples = f.readlines()\n","    examples = [x.lower().strip() for x in examples]\n","    print ('Training set samples number = {:,}'.format (len(examples)))\n","\n","    # Shuffle list of all dinosaur names\n","    np.random.seed(0)\n","    np.random.shuffle(examples)\n","\n","    # Initialize the hidden state of your LSTM\n","    a_prev = np.zeros((n_a, 1))\n","\n","    # Optimization loop\n","    for j in range(num_iterations):\n","        # Use the hint above to define one training example (X,Y) (≈ 2 lines)\n","        index = j % len(examples)\n","        X = [None] + [char_to_ix[ch] for ch in examples[index]]\n","        Y = X[1:] + [char_to_ix[\"\\n\"]]\n","        \n","        # Perform one optimization step: Forward-prop -> Backward-prop -> Clip -> Update parameters        \n","        loss, gradients, a_prev = optimize(X, Y, a_prev, parameters, learning_rate=0.01)\n","\n","        # Every 2000 Iteration, generate \"n\" characters thanks to sample() to check if the model is learning properly\n","        if j % 4000 == 0:\n","            print('Iteration: %d, Loss: %f' % (j, loss) + '\\n')\n","\n","            seed = 0\n","            for name in range(dino_names):\n","                # Sample indices and print them\n","                sampled_indices = sample(parameters, char_to_ix, seed)\n","                print_sample(sampled_indices, ix_to_char)\n","\n","                seed += 1  \n","\n","            print('\\n')\n","\n","    return parameters\n","\n","# execution ===\n","\n","fn = '/content/drive/MyDrive/ds_camp/lesson_24_rnn/dinos.txt'\n","\n","data = open(fn, 'r').read()\n","data= data.lower()\n","chars = list(set(data))\n","data_size, vocab_size = len(data), len(chars)\n","print('Total characters number = {:,} \\n Unique characters numver = {}.'.format (data_size, vocab_size))\n","\n","char_to_ix = { ch:i for i,ch in enumerate(sorted(chars)) }\n","ix_to_char = { i:ch for i,ch in enumerate(sorted(chars)) }\n","print(ix_to_char)\n","print(char_to_ix )\n","\n","# Training the model¶\n","parameters = model(data, ix_to_char, char_to_ix)\n"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Total characters number = 19,909 \n"," Unique characters numver = 27.\n","{0: '\\n', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n","{'\\n': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n","Training set samples number = 1,536\n","Iteration: 0, Loss: 39.548882\n","\n","Nkzxwtdmfqoeyhsqwasjkjvu\n","Kneb\n","Kzxwtdmfqoeyhsqwasjkjvu\n","Neb\n","Zxwtdmfqoeyhsqwasjkjvu\n","Eb\n","Xwtdmfqoeyhsqwasjkjvu\n","\n","\n","Iteration: 4000, Loss: 9.605753\n","\n","Mivrosaurus\n","Inee\n","Ivtroplisaurus\n","Mbaaisaurus\n","Wusichisaurus\n","Cabaselachus\n","Toraperlethosdarenitochusthiamamumamaon\n","\n","\n","Iteration: 8000, Loss: 22.380867\n","\n","Onxusichepriuon\n","Kilabersaurus\n","Lutrodon\n","Omaaerosaurus\n","Xutrcheps\n","Edaksoje\n","Trodiktonus\n","\n","\n","Iteration: 12000, Loss: 20.168279\n","\n","Onyxosaurus\n","Kica\n","Lustrepiosaurus\n","Olaagrraiansaurus\n","Yuspangosaurus\n","Eealosaurus\n","Trognesaurus\n","\n","\n","Iteration: 16000, Loss: 42.363199\n","\n","Meuspsanerontasptasaurus\n","Indaa\n","Iuspsargosaurus\n","Macacosaurus\n","Yusocllan\n","Caaesia\n","Trpangosaurus\n","\n","\n","Iteration: 20000, Loss: 24.203858\n","\n","Meutroenesaurus\n","Kolaacosaurus\n","Lytosaurus\n","Macalosaurus\n","Ytrodon\n","Eiaepona\n","Trochkosaurus\n","\n","\n","Iteration: 24000, Loss: 14.867045\n","\n","Meutrong\n","Indabbosaurus\n","Iutosaurus\n","Macaisphcarperatosaurus\n","Yushandosaurus\n","Daadosaurus\n","Trraparosphorochirhosaurus\n","\n","\n","Iteration: 28000, Loss: 22.454632\n","\n","Piutrong\n","Llacaisaurus\n","Lytrocephiatitar\n","Pacaessan\n","Yusichasaurus\n","Eiaeosalarosaurus\n","Trocheosaurus\n","\n","\n","Iteration: 32000, Loss: 24.966068\n","\n","Maxusianatiasaurus\n","Incabasia\n","Kyusianasaurus\n","Macaishbachymonanvialvanosaurus\n","Yusianasaurus\n","Eeahiradantaurus\n","Trodonosaurus\n","\n","\n","Iteration: 36000, Loss: 21.331395\n","\n","Matrsiaiainauhoroconghorantavenathes\n","Incaaesodebhrosaurus\n","Jusshaongohus\n","Macalosaurus\n","Yusianchodon\n","Ehairona\n","Trocenathus\n","\n","\n","Iteration: 40000, Loss: 17.452910\n","\n","Mestrolominaveratops\n","Inecagosaurus\n","Jussofnatortorex\n","Madalpsaurus\n","Yrus\n","Gaberthedrops\n","Sroimenjis\n","\n","\n","Iteration: 44000, Loss: 14.897942\n","\n","Meustoljeosaurus\n","Incecasaurus\n","Ivrosaurus\n","Mecaismdeblonykheus\n","Yusidon\n","Egahosaurus\n","Troingosaurus\n","\n","\n","Iteration: 48000, Loss: 34.890034\n","\n","Mitrosaurus\n","Inecaishacbisaurus\n","Itrwpbolophus\n","Mecakosaurus\n","Ytrodon\n","Eiaeptod\n","Trterbosaurus\n","\n","\n","Iteration: 52000, Loss: 20.088159\n","\n","Mexusocensaurus\n","Inecalosaurus\n","Ixussasaurus\n","Macaisteedisaurus\n","Xutrephoravesaurus\n","Edacosaurus\n","Trodonsaurus\n","\n","\n","Iteration: 56000, Loss: 25.654661\n","\n","Mitrosaurus\n","Inecansinachus\n","Istronoplomsaurus\n","Macanosaurus\n","Yuskeriosaurus\n","Gaagrosaurus\n","Stringosaurus\n","\n","\n","Iteration: 60000, Loss: 24.655747\n","\n","Litrrichingcripton\n","Ilgaacis\n","Itrypholophus\n","Ledalosaurus\n","Ystodon\n","Egaeosaurus\n","Trodon\n","\n","\n","Iteration: 64000, Loss: 17.235328\n","\n","Lixurodom\n","Ilea\n","Ixusmanasaurus\n","Licalosaurus\n","Yusmanasaurus\n","Eeadrosaurus\n","Trrhinosaurus\n","\n","\n","Iteration: 68000, Loss: 22.911729\n","\n","Kotrus\n","Hlacagsidaa\n","Itrysaurus\n","Lecagskegabulsceptor\n","Yutringosaurus\n","Gaafus\n","Wurgolophyasaurus\n","\n","\n","Iteration: 72000, Loss: 19.022905\n","\n","Jotspoliachaverates\n","Hiceacosaurus\n","Hustognatorsaurus\n","Jecaeskacarqholantoraxakus\n","Yussasaurus\n","Efaetora\n","Trratosaurus\n","\n","\n","Iteration: 76000, Loss: 43.904918\n","\n","Loustrii\n","Huecaisroi\n","Hyutodon\n","Lecalosaurus\n","Yutokia\n","Gaagron\n","Trriocephurtes\n","\n","\n","Iteration: 80000, Loss: 22.814213\n","\n","Kotrronganolterosaurus\n","Indcaeron\n","Itrus\n","Kacaeosaurus\n","Yuspandorastospaneopsiantiurhanehualia\n","Edanropeeotosaurus\n","Trraphopeus\n","\n","\n","Iteration: 84000, Loss: 26.244811\n","\n","Klxosegnchods\n","Hieebdosaurus\n","Hystodong\n","Kecalosaurus\n","Yuvicephilus\n","Egadrong\n","Troenator\n","\n","\n","Iteration: 88000, Loss: 17.981023\n","\n","Llystoloninatisaurus\n","Holcalosaurus\n","Itrus\n","Licalosaurus\n","Yrssaomimiumusuenidesaceravelapantaliadefchatoosau\n","Eiaersanasaurus\n","Troinosaurus\n","\n","\n","Iteration: 92000, Loss: 22.049809\n","\n","Motytinosaurus\n","Ingaaeskelbosaurus\n","Ittrophaosaurus\n","Macalosaurus\n","Wropenator\n","Ehalosaurus\n","Stomilorax\n","\n","\n","Iteration: 96000, Loss: 23.078263\n","\n","Meusus\n","Ila\n","Iustrilestes\n","Macaisaurus\n","Yussaurus\n","Edakron\n","Trodocipaurus\n","\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"bOzFYdI4ptQH"},"source":["<font color = green >\n","\n","## Gated Recurrent Unit (GRU)\n","\n","</font>\n","\n","It introduses gates $\\mathcal{\\Gamma}_{r}$ (as responsible for relevancy) and $\\mathcal{\\Gamma}_{u}$ (as responsible for update) and additional computation of $\\tilde {C\\,}^{<t>}$ as candidate to update the input activation $A^{<t-1>}$\n","\n","$$C^{<t-1>} = A^{<t-1>}\\\\\n","\\mathcal{\\Gamma}_{r} = \\sigma (W_{rc} @ C^{<t-1>} + W_{rx} @ {x\\,}^{<t>} + b_{r}) \\\\\n","\\mathcal{\\Gamma}_{u} = \\sigma (W_{uc} @ C^{<t-1>} + W_{ux} @ {x\\,}^{<t>} + b_{u}) \\\\\n","\\tilde {C\\,}^{<t>} = tanh (W_{cc} @  {C\\,}^{<t-1>} \\cdot \\mathcal{\\Gamma}_{r}  + W_{cx} @ {x\\,}^{<t>} + b_{c})\\\\\n","{A\\,}^{<t>}  = {C\\,}^{<t>} = \\mathcal{\\Gamma}_{u}  \\cdot \\tilde {C\\,}^{<t>} + (1-\\mathcal{\\Gamma}_{u})\\cdot  {C\\,}^{<t-1>}\\\\ \\text{ }\\\\\n","y^{<t>}= softmax (W_{ay} @ A^{<t>} + b_{y})$$"]},{"cell_type":"markdown","metadata":{"id":"imB2WLPEptQO"},"source":["<font color = green >\n","\n","## LSTM cell\n","\n","</font>\n","It introduces separate line of activation units $C^{<t>}$ and uses 3 gates:\n","\n","- $\\mathcal{\\Gamma}_{u}$ (update) \n","- $\\mathcal{\\Gamma}_{f}$ (forget) \n","- $\\mathcal{\\Gamma}_{o}$ (output) \n","\n","\n","\n","<img src = \"images/LSTM.png\" align = 'left' width = 800, heaight = 800> \n","<img src = \"images/LSTM_2.png\" align = 'left' width = 800, heaight = 800> \n","\n","<div style=\"clear:left;\"></div>\n","\n","$\\quad y^{<t>}= softmax (W_{ay} @ A^{<t>} + b_{y})$"]},{"cell_type":"markdown","metadata":{"id":"qKA8xhZAptQP"},"source":["<font color = green >\n","\n","## Bidirectional\n","\n","</font>\n","Computation is performed in 2 directions and then both activations values $A_{right}^{<t>}$ and $A_{left}^{<t>}$ of the same time $t$ are considered for $y^{<t>}$:\n","\n","<img src = \"images/lesson_21_bidirectional2.png\" align = 'left' width = 800, heaight = 800> \n","\n","<div style=\"clear:left;\"></div>\n","\n","$\\quad y^{<t>}= g (W_{ay \\,right} @ A_{right}^{<t>} +  W_{ay \\,left} @ A_{left}^{<t>} + b_{y})$"]},{"cell_type":"markdown","metadata":{"id":"8oC_6yOTptQQ"},"source":["<font color = green >\n","\n","## Deep RNN\n","\n","</font>\n","<img src = \"images/lesson_21_deep_rnn1.png\" align = 'left' width = 400, heaight = 400> \n"]},{"cell_type":"code","metadata":{"id":"-JsrbgN4ptQQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tGrYuojjptQR"},"source":["<font color = green >\n","\n","## Sample 2: language model using tensorflow\n","\n","</font>\n","\n","Word level language model is implemented as 2layer bidirectional LSTM \n","\n","#### Note: See [colab](https://drive.google.com/file/d/1xeYVoCOiO6GUANGb4GF0d0V0fKxa_9WP/view?usp=sharing)\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wLr7xGVns_Fp","executionInfo":{"status":"ok","timestamp":1634481991183,"user_tz":-180,"elapsed":244,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"624059f7-558d-483f-cd2c-a42304205303"},"source":["!ls /content/drive/MyDrive/ds_camp/lesson_24_rnn/"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["dinos.txt  lesson_24_rnn.ipynb\t\t\t    Shevchenko_T._Kobzar.txt\n","images\t   lesson_24_tf_language_model_colab.ipynb\n"]}]},{"cell_type":"code","metadata":{"id":"V30KxisxptQR","executionInfo":{"status":"ok","timestamp":1634482101987,"user_tz":-180,"elapsed":411,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}}},"source":["import os\n","cwd= os.getcwd() # current working directory\n","path = os.path.join(cwd,'data') \n","save_model_path =  os.path.join(path , 'model_rnn.ckpt') \n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"id":"ztHsE9GpptQS","executionInfo":{"status":"error","timestamp":1634482126056,"user_tz":-180,"elapsed":8564,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"8a78584e-ed87-4af5-98f6-026e7414aae6"},"source":["'''\n","v_9\n","\n","- bidirectional layers implemented (using native rnn.stack_bidirectional_dynamic_rnn)\n","- Multi bidirectional layers implemented\n","\n","\n","v_8\n","\n","- the bidirectional manually as two lstm\n","- uses two separated inputs contexts: x_fw, x_bw\n","- uses two separated parameters:  and just add the results at the last (output layer)\n","\n","v_7\n","\n","- bidirectional\n"," 1) input is input+ target+ input e.g. len of 9 (4+1+4 ) vector\n"," 2) it uses the only layer of\n"," 3) use the rnn bidirectional\n","\n","v_6:\n","- minibatch  [General Accuracy: 88.0%]\n","\n","v_5\n","- sampling (no just argmax )\n","-  2 layers (lstm)\n","-   from graph\n","\n","v_4\n","- saving restoring models from scratch\n","\n","v_3\n","- refacrtored \n"," \n","\n","v_2\n","    Code is based on sample:\n","    https://towardsdatascience.com/lstm-by-example-using-tensorflow-feb0c1968537\n","\n","    it considers 3 words (n_input)\n","    the input data is 3 integers NOT the one-hot vector\n","    but output data is probabilities distribution vector\n","\n","    The dimensions are modified comparing to ones in the sample due to no need of redundant dimension\n","\n","'''\n","\n","\n","from string import ascii_lowercase\n","import re\n","import collections\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.contrib import rnn\n","import os\n","\n","import random\n","import math\n","\n","# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","\n","def load_data():\n","    file_name =  os.path.join(path , 'belling_the_cat.txt') \n","    ''':returns ndarray of words  '''\n","\n","    with open(file_name) as f:\n","        content = f.readlines()\n","    content = [x.strip() for x in content]\n","    content = [word for i in range(len(content)) for word in content[i].split()] # currently there is only line but in case of multi line...\n","    content.append('_target_')\n","    content = np.array(content)\n","    print('Words amount: {} '.format(len(content)-1))\n","    word_ind, ind_word = build_dataset(content)\n","    vocab_size = len(word_ind)  # n_x\n","    print('Vocab_size : {:,}'.format(vocab_size))\n","\n","    X = []\n","    Y = []\n","    cursor = 0\n","    while cursor + 2 * n_input < len(content)-1: # -1 = due to added the target word to vocabulary\n","        x_context_left = [word_ind[str(content[i])] for i in range(cursor, cursor + n_input)]\n","        x_context_right = [word_ind[str(content[i])] for i in range(cursor+n_input+1, cursor + 2 * n_input+1)]\n","\n","        x_context = x_context_left + [ word_ind['_target_']] + x_context_right\n","        X.append(x_context)\n","\n","        y_onehot = np.zeros([vocab_size], dtype=float)\n","\n","        y_onehot[word_ind[str(content[cursor + n_input])]] = 1.0  # next word\n","\n","        Y.append(y_onehot)\n","        cursor += 1\n","    X= np.array(X)\n","    X= np.reshape(X, [X.shape[0], X.shape[1], 1]) # required by stack_bidirectional_dynamic_rnn - the axis for features\n","    Y = np.array(Y)\n","\n","    print('Training set len: {:,}'.format(X.shape[0]))\n","\n","    return X, Y, word_ind, ind_word\n","\n","\n","def build_dataset(words):\n","    '''words -  the list of words '''\n","    count = collections.Counter(words).most_common()\n","    dictionary = dict()\n","    for word, _ in count:\n","        dictionary[word] = len(dictionary)\n","    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n","    return dictionary, reverse_dictionary\n","\n","\n","\n","def initialize_parameters(n_hidden, vocab_size):\n","    \"\"\"\n","    Initialize parameters with small random values\n","\n","    \"\"\"\n","    W = tf.get_variable(\"W\", [n_hidden *2 , vocab_size], initializer=tf.contrib.layers.xavier_initializer(seed=1)) # to use tf.nn.static_bidirectional_rnn which retutn outputs  - a length T list of outputs (one for each input), which are depth-concatenated forward and backward outputs\n","    b = tf.get_variable(\"b\", [vocab_size], initializer=tf.zeros_initializer())\n","\n","    parameters = {\"W\": W, \"b\": b}\n","\n","    return parameters\n","\n","\n","def create_placeholders(n_input, vocab_size):\n","    # X[batch_size, n_context]  - Note: it will be splitted by last dimension to pass to RNN - the value represented is the int number the number in vocab\n","\n","    # Let's add 1 as the last dimension which means there is only 1 feature - you may use it to pass one hot vector or whatever features\n","    X = tf.placeholder(tf.float32, shape=[None, n_input * 2 +1, 1], name='X')  # batch_size, context, single id in vocabulary (last layer is added due to required by tf layer)\n","\n","    # Y [batch_size, len_of_vocabulary]  - Note: we need to use it as one-hot vector to calculate the cross entropy cost\n","    Y = tf.placeholder(tf.float32, shape=[None, vocab_size] , name='Y')  #  one-hot vector\n","    return (X,Y)\n","\n","\n","def forward_propagation(X, parameters, n_hidden, layers=2):\n","\n","    # looks as batch size = 1\n","\n","    print('\\nShape of input =  {}'.format(X))\n","\n","\n","    # Note: the following is required for static_bidirectional_rnn but not for stack_bidirectional_dynamic_rnn !!!\n","    # X = tf.split(X, (n_input* 2+ 1) , axis=-1)  #  default axis=0\n","\n","    cells_fw = [tf.nn.rnn_cell.LSTMCell(num_units=n_hidden, state_is_tuple=True) for i in range(layers)]\n","    cells_bw = [tf.nn.rnn_cell.LSTMCell(num_units=n_hidden, state_is_tuple=True) for i in range(layers)]\n","\n","    outputs, output_state_fw, output_state_bw =  rnn.stack_bidirectional_dynamic_rnn(cells_fw= cells_fw, cells_bw= cells_bw, inputs= X, dtype=tf.float32) # returns a tuple (outputs, output_state_fw, output_state_bw) where: * outputs: Output Tensor shaped: batch_size, max_time, layers_output]. Where layers_output are depth-concatenated forward and backward outputs.\n","\n","    # tf.add(tf.matmul(outputs[:, n_input+1], parameters['W']), parameters['b'])\n","\n","    Z = tf.nn.softmax(tf.add(tf.matmul(outputs[:, n_input+1], parameters['W']), parameters['b']),         name='Z')\n","    print('\\nOutput of RNN (\"Z\") =  {}'.format(Z))\n","    return Z\n","\n","\n","def compute_cost(Z, Y):\n","    \"\"\"\n","    Returns:\n","    cost - Tensor of the cost function\n","        e.g. value 2.2901573\n","    \"\"\"\n","    # Make sure sum over rows = 1\n","    # labels = np.array(Y, dtype=np.float32)\n","    # labels_sum = tf.reduce_sum(labels, axis=-1)\n","    # print(labels_sum)\n","\n","\n","    cost_cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z, labels=Y))\n","    # Defaulted  axis is -1 which is the last dimension.\n","    # each row of labels[i] must be a valid probability distribution\n","\n","    return cost_cross_entropy\n","\n","\n","\n","def random_mini_batches(X, Y, mini_batch_size=64, seed=0):  # todo\n","    \"\"\"\n","    Creates a list of random minibatches from (X, Y)\n","\n","    Arguments:\n","    X -- input data, of shape (number of examples, n_context)\n","    Y -- true \"label\" , of shape (number of examples, vocab_size )\n","    mini_batch_size - size of the mini-batches, integer\n","    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n","\n","    Returns:\n","    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n","    \"\"\"\n","\n","    m = X.shape[0]  # number of training examples\n","    mini_batches = []\n","    np.random.seed(seed)\n","\n","    # Step 1: Shuffle (X, Y)\n","    permutation = list(np.random.permutation(m))\n","    shuffled_X = X[permutation, :]\n","    shuffled_Y = Y[permutation, :] #.reshape((Y.shape[0], m))\n","\n","    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n","    num_complete_minibatches = math.floor(\n","        m / mini_batch_size)  # number of mini batches of size mini_batch_size in your partitionning\n","    for k in range(0, num_complete_minibatches):\n","        mini_batch_X = shuffled_X[k * mini_batch_size: k * mini_batch_size + mini_batch_size, :]\n","        mini_batch_Y = shuffled_Y[k * mini_batch_size: k * mini_batch_size + mini_batch_size:, :]\n","        mini_batch = (mini_batch_X, mini_batch_Y)\n","        mini_batches.append(mini_batch)\n","\n","    # Handling the end case (last mini-batch < mini_batch_size)\n","    if m % mini_batch_size != 0:\n","        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size: m, :]\n","        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size: m, :]\n","        mini_batch = (mini_batch_X, mini_batch_Y)\n","        mini_batches.append(mini_batch)\n","\n","    return mini_batches\n","\n","\n","def model(data, save_model_path, learning_rate=0.001, n_input = 3, n_hidden=512, num_epochs = 500, minibatch_size = 32, layers= 2):\n","    '''\n","    :param data:\n","    :param learning_rate:\n","    :param n_input: int - len of context\n","    :param n_hidden: int - number of units in RNN cell\n","    :param training_iters: int\n","    :param display_step: int\n","    :param save_model_path: str\n","    :return:\n","    '''\n","\n","    tf.reset_default_graph()  # to be able to rerun the model without overwriting tf variables - actually I dont understand what it is for\n","\n","    X_train, Y_train, word_ind, ind_word = data\n","    m, vocab_size = Y_train.shape # len(word_ind)\n","\n","\n","    # Initialize parameters\n","    parameters = initialize_parameters(n_hidden, vocab_size)\n","\n","    # Create Placeholders of shape (n_x, n_y)\n","    X, Y = create_placeholders(n_input, vocab_size)\n","\n","    # Forward propagation: Build the forward propagation in the tensorflow graph\n","    Z = forward_propagation(X, parameters,n_hidden, layers)\n","\n","    cost = compute_cost(Z, Y)\n","\n","    # costs = []  # To keep track of the cost\n","\n","    # Define the tensorflow optimizer. Use an AdamOptimizer.\n","    optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n","\n","\n","    # Model evaluation\n","    correct_pred = tf.equal(tf.argmax(Z, -1), tf.argmax(Y, -1))\n","    # accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name = 'Acc')\n","\n","    # use to save model\n","    saver = tf.train.Saver()\n","\n","\n","    # Initialize all the variables\n","    init = tf.global_variables_initializer()\n","    seed = 3  # to keep consistent results\n","    costs = []  # To keep track of the cost\n","\n","    print('\\nTrainable variables: ')\n","    with tf.Session() as sess:\n","        sess.run(init)\n","        vars = tf.trainable_variables()\n","        for var in vars:\n","            print(var)\n","\n","    # Start the session to compute the tensorflow graph\n","    print('\\nTraining model...')\n","    with tf.Session() as sess:\n","        # Run the initialization\n","        sess.run(init)\n","\n","        # Do the training loop\n","        for epoch in range(1,num_epochs+1): # to avoid print at first iter\n","            epoch_cost = 0.  # Defines a cost related to an epoch\n","            acc_epoch = 0\n","            # acc_troubleshooting = []\n","            num_minibatches = math.ceil(m / minibatch_size)\n","\n","            seed = seed + 1\n","            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n","\n","            for minibatch in minibatches:\n","                # Select a minibatch\n","                (minibatch_X, minibatch_Y) = minibatch\n","\n","                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n","                _, acc, minibatch_cost = sess.run([optimizer, accuracy, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n","                # acc_troubleshooting.append(acc)\n","                epoch_cost += minibatch_cost / num_minibatches\n","\n","                acc_epoch += acc / num_minibatches\n","\n","\n","            # Print the cost every epoch\n","            if  epoch % 10 == 0:\n","                print(\"\\n===\\nCost after epoch %i: %f\" % (epoch, epoch_cost))\n","                print(\"Average Accuracy (during performance of last epoch)= {:.1%}\".format(acc_epoch))\n","                # print (acc_troubleshooting)\n","\n","                general_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n","                print(\"General Accuracy: {:.1%}\".format (general_accuracy))\n","\n","\n","            if epoch % 5 == 0:\n","                costs.append(epoch_cost)\n","\n","        print(\"Optimization Finished!\")\n","\n","        # Save the variables to disk\n","        save_path = saver.save(sess, save_model_path)\n","        print(\"Model saved in path: {}\".format(save_path))\n","\n","        print ('\\nCheck at saving')\n","        print(sess.run('W:0'))\n","\n","\n","\n","\n","n_input = 5\n","n_hidden = 64\n","minibatch_size=2\n","layers= 1\n","num_epochs = 1000\n","\n","\n","data = load_data()\n","\n","model(data, save_model_path=save_model_path, learning_rate=0.001, n_input=n_input, n_hidden=n_hidden,\n","      num_epochs=num_epochs, minibatch_size=minibatch_size, layers=layers)\n","\n","\n","\n","# n_input = 5\n","# n_hidden = 64\n","# minibatch_size=4\n","# layers= 1\n","# num_epochs = 1000\n","# is_to_train = 1\n","\n","# results: \n","\n","# Cost after epoch 700: 3.757871\n","# Average Accuracy (during performance of last epoch)= 98.5%\n","# General Accuracy: 98.5%\n"],"execution_count":4,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-1a2633fc185a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m model(data, save_model_path=save_model_path, learning_rate=0.001, n_input=n_input, n_hidden=n_hidden,\n","\u001b[0;32m<ipython-input-4-1a2633fc185a>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m''':returns ndarray of words  '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/belling_the_cat.txt'"]}]},{"cell_type":"code","metadata":{"id":"bvIJXdCNptQU"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":346},"id":"q-9gf9RkptQU","executionInfo":{"status":"error","timestamp":1634482148967,"user_tz":-180,"elapsed":1759,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"6a5d544b-0300-4a22-eb3e-85789cb812ee"},"source":["\n","'''\n","v_6\n","\n","Implemented :\n","    minibatch\n","\n","'''\n","\n","from string import ascii_lowercase\n","import re\n","import collections\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.contrib import rnn\n","import os\n","\n","import random\n","import math\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","\n","def load_data():\n","    file_name =  os.path.join(path , 'belling_the_cat.txt') \n","    ''':returns ndarray of words ,  '''\n","\n","    with open(file_name) as f:\n","        content = f.readlines()\n","    content = [x.strip() for x in content]\n","    content = [word for i in range(len(content)) for word in content[i].split()] # currently there is only line but in case of multi line...\n","    content = np.array(content)\n","    print('Words amount: {} '.format(len(content)))\n","    word_ind, ind_word = build_dataset(content)\n","    vocab_size = len(word_ind)  # n_x\n","    print('Vocab_size : {:,}'.format(vocab_size))\n","\n","    X = []\n","    Y= []\n","    cursor = 0\n","    while cursor + n_input < len(content): # exclude the last since we get content[cursor + n_input] for y\n","        x_context = [word_ind[str(content[i])] for i in range(cursor, cursor + n_input)]\n","        # x_context = np.reshape(x_context, [1, -1])\n","        X.append(x_context)\n","\n","        y_onehot = np.zeros([vocab_size], dtype=float)\n","\n","        y_onehot[word_ind[str(content[cursor + n_input])]] = 1.0  # next word\n","\n","        Y.append(y_onehot)\n","        cursor += 1\n","    X= np.array(X)\n","    Y = np.array(Y)\n","\n","    print('Training set len: {:,}'.format(X.shape[0]))\n","\n","    return X,Y, word_ind, ind_word\n","\n","\n","def build_dataset(words):\n","    '''words -  the list of words '''\n","    count = collections.Counter(words).most_common()\n","    dictionary = dict()\n","    for word, _ in count:\n","        dictionary[word] = len(dictionary)\n","    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n","    return dictionary, reverse_dictionary\n","\n","\n","\n","\n","\n","def initialize_parameters(n_hidden, vocab_size):\n","    \"\"\"\n","    Initialize parameters with small random values\n","\n","    \"\"\"\n","\n","    # Note: configure the output layer whereas the parameters of rnn are declared automatically\n","    W = tf.get_variable(\"W\", [n_hidden, vocab_size], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n","    b = tf.get_variable(\"b\", [vocab_size], initializer=tf.zeros_initializer())\n","\n","    parameters = {\"W\": W, \"b\": b}\n","\n","    return parameters\n","\n","\n","def create_placeholders(n_input, vocab_size):\n","    # X[batch_size, n_context]  - Note: it will be splitted by last dimension to pass to RNN - the value represented is the int number the number in vocab\n","    X = tf.placeholder(tf.float32, shape=[None, n_input], name='X')  # note this is not the one-hot vector - first is the number of words to consider, another dim is the len of vector - is 1 because  we pass the integer value for every word\n","    # Y [batch_size, len_of_vocabulary]  - Note: we need to use it as one-hot vector to calculate the cross entropy cost\n","    Y = tf.placeholder(tf.float32, shape=[None, vocab_size] , name='Y')  #  one-hot vector\n","    return (X,Y)\n","\n","\n","def forward_propagation(X, parameters, n_hidden, layers=2):\n","\n","    # looks as batch size = 1\n","\n","    print('\\nShape of input =  {}'.format(X))\n","\n","    # Generate a n_input-element sequence of inputs\n","    # (eg. [had] [a] [general] -> [20] [6] [33])\n","\n","    X = tf.split(X, n_input, axis=-1)  #  default axis=0\n","    # print(X) # [<tf.Tensor 'split:0' shape=(1, 1) dtype=float32>, <tf.Tensor 'split:1' shape=(1, 1) dtype=float32>, <tf.Tensor 'split:2' shape=(1, 1) dtype=float32>]\n","\n","    if layers == 2:\n","        # 2-layer LSTM, each layer has n_hidden units.\n","        # Average Accuracy= 95.20% at 50k iter\n","\n","        rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])\n","\n","        # general sample\n","            # num_units = [128, 64]\n","            # cells = [BasicLSTMCell(num_units=n) for n in num_units]\n","            # stacked_rnn_cell = MultiRNNCell(cells)\n","\n","    elif layers == 1 :\n","        # 1-layer LSTM with n_hidden units but with lower accuracy.\n","        # Average Accuracy= 90.60% 50k iter\n","        # Uncomment line below to test but comment out the 2-layer rnn.MultiRNNCell above\n","        rnn_cell = rnn.BasicLSTMCell(n_hidden)\n","\n","    else: # could be used for case 2\n","        # general sample\n","        # num_units = [n_hidden for i in range(layers)]\n","        cells = [rnn.BasicLSTMCell(num_units=n_hidden) for i in range(layers)]\n","        rnn_cell = rnn.MultiRNNCell(cells)\n","\n","    # generate prediction\n","    outputs, states = rnn.static_rnn(rnn_cell, X, dtype=tf.float32)  # inputs: A length T list of inputs, each a Tensor of shape [batch_size, input_size], or a nested tuple of such elements.\n","    # print(outputs, states)\n","\n","    # there are n_input outputs but  we only want the last output\n","    # Z = tf.matmul(outputs[-1], parameters['W']) + parameters['b']\n","    Z = tf.nn.softmax(tf.add (tf.matmul(outputs[-1], parameters['W']), parameters['b']), name='Z')\n","    print('\\nOutput of RNN (\"Z\") =  {}'.format(Z))\n","    return Z\n","\n","\n","def compute_cost(Z, Y):\n","    \"\"\"\n","    Returns:\n","    cost - Tensor of the cost function\n","        e.g. value 2.2901573\n","    \"\"\"\n","    # Make sure sum over rows = 1\n","    # labels = np.array(Y, dtype=np.float32)\n","    # labels_sum = tf.reduce_sum(labels, axis=-1)\n","    # print(labels_sum)\n","\n","    # logits = tf.transpose(Z)  # use if necessary\n","    # labels = tf.transpose(Y)\n","\n","    cost_cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z, labels=Y))\n","    # Defaulted  axis is -1 which is the last dimension.\n","    # each row of labels[i] must be a valid probability distribution\n","\n","    return cost_cross_entropy\n","\n","\n","\n","def random_mini_batches(X, Y, mini_batch_size=64, seed=0):  # todo\n","    \"\"\"\n","    Creates a list of random minibatches from (X, Y)\n","\n","    Arguments:\n","    X -- input data, of shape (number of examples, n_context)\n","    Y -- true \"label\" , of shape (number of examples, vocab_size )\n","    mini_batch_size - size of the mini-batches, integer\n","    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n","\n","    Returns:\n","    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n","    \"\"\"\n","\n","    m = X.shape[0]  # number of training examples\n","    mini_batches = []\n","    np.random.seed(seed)\n","\n","    # Step 1: Shuffle (X, Y)\n","    permutation = list(np.random.permutation(m))\n","    shuffled_X = X[permutation, :]\n","    shuffled_Y = Y[permutation, :] #.reshape((Y.shape[0], m))\n","\n","    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n","    num_complete_minibatches = math.floor(\n","        m / mini_batch_size)  # number of mini batches of size mini_batch_size in your partitionning\n","    for k in range(0, num_complete_minibatches):\n","        mini_batch_X = shuffled_X[k * mini_batch_size: k * mini_batch_size + mini_batch_size, :]\n","        mini_batch_Y = shuffled_Y[k * mini_batch_size: k * mini_batch_size + mini_batch_size:, :]\n","        mini_batch = (mini_batch_X, mini_batch_Y)\n","        mini_batches.append(mini_batch)\n","\n","    # Handling the end case (last mini-batch < mini_batch_size)\n","    if m % mini_batch_size != 0:\n","        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size: m, :]\n","        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size: m, :]\n","        mini_batch = (mini_batch_X, mini_batch_Y)\n","        mini_batches.append(mini_batch)\n","\n","    return mini_batches\n","\n","\n","def model(data, save_model_path, learning_rate=0.001, n_input = 3, n_hidden=512, num_epochs = 500, minibatch_size = 32, layers= 2):\n","    '''\n","    :param data:\n","    :param learning_rate:\n","    :param n_input: int - len of context\n","    :param n_hidden: int - number of units in RNN cell\n","    :param training_iters: int\n","    :param display_step: int\n","    :param save_model_path: str\n","    :return:\n","    '''\n","\n","    tf.reset_default_graph()  # to be able to rerun the model without overwriting tf variables - actually I dont understand what it is for\n","\n","    X_train, Y_train, word_ind, ind_word = data\n","    m, vocab_size = Y_train.shape # len(word_ind)\n","\n","\n","    # Initialize parameters\n","    parameters = initialize_parameters(n_hidden, vocab_size)\n","\n","    # Create Placeholders of shape (n_x, n_y)\n","    X, Y = create_placeholders(n_input, vocab_size)\n","\n","    # Forward propagation: Build the forward propagation in the tensorflow graph\n","    Z = forward_propagation(X, parameters,n_hidden, layers)\n","\n","    cost = compute_cost(Z, Y)\n","\n","    # costs = []  # To keep track of the cost\n","\n","    # Define the tensorflow optimizer. Use an AdamOptimizer.\n","    optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n","\n","\n","    # Model evaluation\n","    correct_pred = tf.equal(tf.argmax(Z, -1), tf.argmax(Y, -1))\n","    # accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name = 'Acc')\n","\n","\n","\n","\n","    # use to save model\n","    saver = tf.train.Saver()\n","    # tf.add_to_collection('Z', Z)\n","\n","    # Initialize all the variables\n","    init = tf.global_variables_initializer()\n","    seed = 3  # to keep consistent results\n","    costs = []  # To keep track of the cost\n","\n","    print('\\nTrainable variables: ')\n","    with tf.Session() as sess:\n","        sess.run(init)\n","        vars = tf.trainable_variables()\n","        for var in vars:\n","            print(var)\n","\n","    # Start the session to compute the tensorflow graph\n","    print('\\nTraining model...')\n","    with tf.Session() as sess:\n","        # Run the initialization\n","        sess.run(init)\n","\n","        # Do the training loop\n","        for epoch in range(1,num_epochs+1): # to avoid print at first iter\n","            epoch_cost = 0.  # Defines a cost related to an epoch\n","            acc_epoch = 0\n","            acc_troubleshooting = []\n","            num_minibatches = math.ceil(m / minibatch_size)\n","            # print('num_minibatches :', num_minibatches )\n","            seed = seed + 1\n","            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n","\n","            for minibatch in minibatches:\n","                # Select a minibatch\n","                (minibatch_X, minibatch_Y) = minibatch\n","\n","                # IMPORTANT: The line that runs the graph on a minibatch.\n","                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n","                _, acc, minibatch_cost = sess.run([optimizer, accuracy, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n","                acc_troubleshooting.append(acc)\n","                epoch_cost += minibatch_cost / num_minibatches\n","\n","                acc_epoch += acc / num_minibatches\n","\n","\n","            # Print the cost every epoch\n","            if  epoch % 10 == 0:\n","                print(\"\\n===\\nCost after epoch %i: %f\" % (epoch, epoch_cost))\n","                print(\"Average Accuracy (during performance of last epoch)= {:.1%}\".format(acc_epoch))\n","                print (acc_troubleshooting)\n","\n","                general_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n","                print(\"General Accuracy: {:.1%}\".format (general_accuracy))\n","\n","                print_predictions(sess, X, Z, X_train, Y_train, word_ind, ind_word, n_input, number=50)\n","\n","            if epoch % 5 == 0:\n","                costs.append(epoch_cost)\n","\n","\n","        print(\"Optimization Finished!\")\n","\n","        # Save the variables to disk.\n","        save_path = saver.save(sess, save_model_path)\n","        print(\"Model saved in path: {}\".format(save_path))\n","\n","        print ('\\nCheck at saving')\n","        print(sess.run('W:0'))\n","\n","\n","\n","def print_predictions(sess, X, Z, X_train, Y_train, word_ind, ind_word, n_input, start=0, number = None):\n","\n","    accuracy=[]\n","    cursor = start\n","    if not number:\n","        end = len(X_train)\n","    else:\n","        end = min(len(X_train), number + start)  # to cover al\n","    print('\\nDemonstrate the predictions for contexts in range ({}, {}):'.format(start, end))\n","    while cursor < end:\n","        # x_context = [word_ind[str(content[i])] for i in range(cursor, cursor + n_input)]\n","        # x_context = np.reshape(x_context, [1, -1])\n","\n","        x_batch = X_train[cursor].reshape(1,-1)\n","        pred_onehot = sess.run(Z, feed_dict={X: x_batch})\n","        pred_index = int(tf.argmax(pred_onehot, 1).eval())\n","        pred_word = ind_word[pred_index]\n","\n","        true_index = np.argmax(Y_train[cursor])\n","        true_word = ind_word[true_index]\n","        print('{} -> {} [{}]'.format(' '.join(ind_word[i] for i in X_train[cursor]), pred_word, true_word))\n","        cursor += 1\n","        accuracy.append(pred_index == true_index)\n","    print('\\nFactual Accuracy for range of {} contexts = {:.1%}'.format(number, np.average(accuracy)))\n","\n","\n","def generate_sample_index(pred_tf):\n","    '''\n","    :param pred is tensor\n","    :return: tf - index of sampled word\n","    Note : here is all operations ared performed with tensors not with np objects\n","    need to eval to get int value\n","    '''\n","\n","    # sampling due to probability distribution\n","    pred_tf = tf.squeeze(pred_tf) # to exclude dimensionals of 1 - could be resolved by reshape\n","    dist = tf.distributions.Multinomial(total_count=1., probs = pred_tf)  # response with larger dimension - first dumension is dedicated for number of samples\n","    # here could be provided the ndarray or list e.g.   p = [.2, .3, .5]\n","\n","    sample_tf = dist.sample(1)\n","    return tf.argmax(sample_tf, axis=1)[0] # since the sample_tf is tf of size 2 tf.argmax returns the array of size 1 - to get value we take first element\n","\n","\n","\n","def use_trained_model(save_model_path, data):\n","    tf.reset_default_graph()\n","\n","    X_train, Y_train, word_ind, ind_word = data\n","\n","    with tf.Session() as sess:\n","\n","        # sess.run(init)\n","        save_graph_path =  save_model_path+ '.meta'\n","        saver = tf.train.import_meta_graph(save_graph_path)\n","\n","        # Restore variables from disk.\n","        saver.restore(sess, save_model_path)\n","        print(\"\\nModel restored.\")\n","\n","        graph = tf.get_default_graph()\n","        X = graph.get_tensor_by_name(\"X:0\")\n","\n","        # print('\\nCheck at restoring')\n","        # print(sess.run(W))\n","\n","        Z = graph.get_tensor_by_name(\"Z:0\")\n","\n","        Y = graph.get_tensor_by_name(\"Y:0\")\n","        accuracy=  graph.get_tensor_by_name(\"Acc:0\")\n","\n","        general_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n","        print(\"General Accuracy: {:.1%}\".format(general_accuracy))\n","\n","\n","        #  lets predict for every context:\n","        # print_predictions(sess, X, Z, X_train, Y_train, word_ind, ind_word, n_input ) # , number=10)\n","\n","        is_continue  =  True\n","\n","        while is_continue:\n","            prompt = \"\\nProvide {} words (leave blank to generate from next words of text): \".format(n_input)\n","            sentence = input(prompt)\n","            sentence = sentence.strip()\n","            words = sentence.split(' ')\n","            if len(words) > n_input:\n","                words = words[:n_input]\n","                print('It will use first {} words: {}\\n'.format(n_input, words))\n","\n","            x_batch = [word_ind[str(words[i])] for i in range(len(words))]\n","            sentence+=' -> '\n","\n","            for i in range(200):\n","                x_batch = np.reshape(x_batch, [1, -1]) # make sure it is row\n","\n","                sample_ind_tf = generate_sample_index(Z)\n","                sample_ind = sess.run(sample_ind_tf, feed_dict={X:x_batch})\n","                # print ('Sampling: ', ind_word[sample_ind])\n","\n","                pred_index = int(tf.argmax(Z, axis = 1).eval(feed_dict={X:x_batch}))\n","                if pred_index!= sample_ind:\n","                    print ('Sampling {} [argmax: {}]'.format( ind_word[sample_ind], ind_word[pred_index]))\n","                else:\n","                    print('Sampling {}'.format(ind_word[sample_ind]))\n","                sentence = \"{} {}\".format (sentence,ind_word[sample_ind])\n","                x_batch = x_batch[:,1:] # exclude fisrt word\n","                x_batch = np.concatenate((x_batch, [[sample_ind]]), axis=-1) # add last word\n","\n","            print('\\n=====\\n',sentence)\n","\n","\n","\n","\n","\n","n_input = 4 # len of context\n","n_hidden = 64\n","minibatch_size=4\n","layers= 2\n","is_to_train = 1\n","data = load_data()\n","\n","\n","if is_to_train:\n","     model (data, save_model_path = save_model_path, learning_rate=0.001, n_input = n_input, n_hidden=n_hidden, num_epochs = 500, minibatch_size=minibatch_size, layers= layers)\n","use_trained_model(save_model_path, data)\n","\n","\n"],"execution_count":5,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-4ca48ab4ed82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0mis_to_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-4ca48ab4ed82>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;34m''':returns ndarray of words ,  '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/belling_the_cat.txt'"]}]},{"cell_type":"markdown","metadata":{"id":"PfHr3v1aptQX"},"source":["<font color = green >\n","\n","## Sample 3: language model using keras \n","\n","</font>\n","\n","Word level language model is implemented as LSTM for poem of T.Shevchenko \n"]},{"cell_type":"code","metadata":{"id":"MV-TPFMEptQY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wb431jYEptQZ","executionInfo":{"status":"ok","timestamp":1634482612112,"user_tz":-180,"elapsed":569,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}}},"source":["from __future__ import print_function\n","from keras.callbacks import LambdaCallback\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","# from keras.optimizers import RMSprop\n","from tensorflow.keras.optimizers import RMSprop\n","from keras.utils.data_utils import get_file\n","import numpy as np\n","import random\n","import sys\n","import io\n","# import PyPDF2"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"fY2qh8bjptQZ","executionInfo":{"status":"ok","timestamp":1634482618852,"user_tz":-180,"elapsed":776,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}}},"source":["import re\n","from sklearn.feature_extraction.text import CountVectorizer"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IglsKPRdu0Pb","executionInfo":{"status":"ok","timestamp":1634482234200,"user_tz":-180,"elapsed":394,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"e63762b5-347e-4ae8-a410-f03af5788b00"},"source":["!ls /content/drive/MyDrive/ds_camp/lesson_24_rnn/"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["dinos.txt  lesson_24_rnn.ipynb\t\t\t    Shevchenko_T._Kobzar.txt\n","images\t   lesson_24_tf_language_model_colab.ipynb\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S9JONbatptQb","executionInfo":{"status":"ok","timestamp":1634482624807,"user_tz":-180,"elapsed":965,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"3860d2c9-af6f-4291-8989-2c5c0d7803e6"},"source":["fn = '/content/drive/MyDrive/ds_camp/lesson_24_rnn/Shevchenko_T._Kobzar.txt'\n","with open(fn) as f:\n","    text = f.read().lower()\n","# print('corpus length = {\",\"}', len(text)) \n","text = re.sub(r'\\[.*\\]', \"\", text)\n","text = re.sub(r'\\d+', \"\", text)\n","text = re.sub(r'«|»', \"\", text)\n","\n","\n","\n","\n","print ('Len of original text= {:,}'.format (len(text)))\n","keep = 0.2\n","text =  text[: int (len(text)* keep)]\n","print ('Len of snippet= {:,}'.format (len(text)))\n","\n","print (text[:5000])\n","\n","\n","\n"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Len of original text= 507,759\n","Len of snippet= 101,551\n","причинна \n","реве та стогне дніпр широкий, сердитий вітер завива, додолу верби гне високі, горами хвилю підійма.\n","і блідний місяць на ту пору із хмари де-де виглядав, неначе човен в синім морі, то виринав, то потопав. ще треті півні не співали, ніхто нігде не гомонів, сичі в гаю перекликались, та ясен раз у раз скрипів.\n","в таку добу під горою, біля того гаю,\n","що чорніє над водою, щось біле блукає.\n","може, вийшла русалонька матері шукати,\n","а може, жде козаченька, щоб залоскотати.\n","не русалонька блукає: то дівчина ходить,\n","й сама не зна (бо причинна), що такеє робить.\n","так ворожка поробила,\n","щоб менше скучала,\n","щоб, бач, ходя опівночі, спала й виглядала козаченька молодого, що торік покинув. обіщався вернутися,\n","та, мабуть, і згинув!\n","не китайкою  покрились козацькії очі,\n","не вимили біле личко слізоньки дівочі:\n","орел вийняв карі очі\n","на чужому полі,\n","біле тіло вовки з'їли,— така його доля.\n","дарма щоніч дівчинонька його виглядає.\n","не вернеться чорнобривий та й не привітає,\n","не розплете довгу косу, хустку не зав'яже,\n","не на ліжко — в домовину сиротою ляже!\n","\n","така її доля... о боже мій милий!\n","за що ж ти караєш її, молоду?\n","за те, що так щиро вона полюбила козацькії очі?.. прости сироту!\n","кого ж їй любити? ні батька, ні неньки; одна, як та пташка в далекім краю. пошли ж ти їй долю,— вона молоденька, бо люде чужії її засміють.\n","чи винна ж голубка, що голуба любить? чи винен той голуб, що сокіл убив? сумує, воркує, білим світом нудить, літає, шукає, дума — заблудив. щаслива голубка: високо літає,\n","полине до бога — милого питать. кого ж сиротина, кого запитає,\n","і хто їй розкаже, і хто теє знає,\n","де милий ночує: чи в темному гаю, чи в бистрім дунаю коня напува, чи, може, з другою, другую кохає, її, чорнобриву, уже забува? якби-то далися орлинії крила,\n","за синім би морем милого знайшла; живого б любила. другу б задушила,\n","а до неживого у яму б лягла.\n","не так серце любить, щоб з ким поділиться, не так воно хоче, як бог нам дає:\n","воно жить не хоче, не хоче журиться. журись,— каже думка, жалю завдає. о боже мій милий! така твоя воля, таке її щастя, така її доля!\n","вона все ходить, з уст ні пари. широкий дніпр не гомонить: розбивши вітер чорні хмари, ліг біля моря одпочить,\n","а з неба місяць так і сяє;\n","і над водою, і над гаєм,\n","кругом, як в усі, все мовчить.\n","аж гульк — з дніпра повиринали малії діти, сміючись.\n","ходімо гріться! — закричали.— зійшло вже сонце! (голі скрізь: з осоки коси, бо дівчата).\n","......\n","чи всі ви тута? — кличе мати. ходім шукати вечерять. пограємось, погуляймо\n","та пісеньку заспіваймо:\n","ух! ух!\n","солом'яний дух, дух!\n","мене мати породила, нехрещену положила. місяченьку!\n","наш голубоньку!\n","\n","ходи до нас вечеряти:\n","у нас козак в очереті,\n","в очереті, в осоці,\n","срібний перстень на руці; молоденький, чорнобровий; знайшли вчора у діброві.\n","світи довше в чистім полі, щоб нагулятись доволі.\n","поки відьми ще літають,\n","поки півні не співають, посвіти нам... он щось ходить! он під дубом щось там робить. ух! ух!\n","солом'яний дух, дух! мене мати породила, нехрещену положила.\n","зареготались нехрещені... гай обізвався; галас, зик, орда мов ріже. мов скажені, летять до дуба... нічичирк... схаменулись нехреіцені, дивляться — мелькає,\n","щось лізе вверх по стовбуру до самого краю.\n","ото ж тая дівчинонька,\n","що сонна блудила: отаку-то їй причину ворожка зробила!\n","на самий верх на гіллячці стала... в серце коле! подивилась на всі боки та й лізе додолу.\n","кругом дуба русалоньки мовчки дожидали; взяли її, сердешную,\n","та й залоскотали. довго, довго дивовались на її уроду...\n","треті півні: кукуріку! — шелеснули в воду. защебетав жайворонок, угору летючи;\n","закувала зозуленька, на дубу сидячи; защебетав соловейко — пішла луна гаєм; червоніє за горою; плугатар співає.\n","чорніє гай над водою, де ляхи ходили; засиніли понад дніпром високі могили;\n","пішов шелест по діброві; \n","шепчуть густі лози.\n","а дівчина спить під дубом при битій дорозі.\n","знать, добре спить, що не чує, як кує зозуля,\n","що не лічить, чи довго жить... знать, добре заснула.\n","а тим часом із діброви\n","козак виїжджає;\n","під ним коник вороненький насилу ступає.\n","ізнемігся, товаришу!\n","сьогодні спочинем:\n","близько хата, де дівчина ворота одчинить.\n","а може, вже одчинила\n","не мені, другому...\n","швидше, коню, швидше, коню, поспішай додому!\n","утомився вороненький,\n","іде, спотикнеться,—\n","коло серця козацького\n","як гадина в'ється.\n","ось і дуб той кучерявий... вона! боже милий!\n","бач, заснула виглядавши,\n","моя сизокрила!\n","кинув коня та до неї:\n","боже ти мій, боже!\n","кличе її та цілує...\n","ні, вже не поможе!\n","за що ж вони розлучили\n","мене із тобою?\n","зареготавсь, розігнався —\n","та в дуб головою!\n","ідуть дівчата в поле жати\n","та, знай, співають ідучи:\n","як проводжала сина мати,\n","як бивсь татарин уночі.\n","ідуть — під дубом зелененьким кінь замордований стоїть,\n","а біля його молоденький\n","козак та дівчина лежить. цікаві (нігде правди діти) підкралися, щоб ізлякать;\n","коли подивляться, що вбитий, - з переполоху ну втікать!\n","збиралися подруженьки, слізоньки втирають; збиралися товариші\n","\n","та ями копають;\n","прийшли попи з корогвами, задзвонили дз\n"]}]},{"cell_type":"code","metadata":{"id":"5CYWcwhYptQc","executionInfo":{"status":"ok","timestamp":1634482628822,"user_tz":-180,"elapsed":217,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}}},"source":["vectorizer = CountVectorizer(token_pattern=r'(?u)(?:\\b\\w+\\b|\\.|\\,|\\!|\\?|\\-|\\n)').fit([text])\n","# max_features= 10000"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5H0hncPrptQd","executionInfo":{"status":"ok","timestamp":1634482630094,"user_tz":-180,"elapsed":7,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"e482134d-6fe8-4d5a-84c2-348ba80f890c"},"source":["print ('len of features = {:,}\\n'.format(len(vectorizer.get_feature_names())))\n","vocab = vectorizer.get_feature_names()\n","print (vocab[:100])\n"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["len of features = 4,587\n","\n","['\\n', '!', ',', '-', '.', '?', 'ii', 'iii', 'iv', 'my', 'narodowi', 'nie', 'polska', 'pozwalam', 'v', 'zginela', 'zyjemy', 'а', 'аби', 'абичию', 'або', 'аж', 'аи', 'альта', 'альту', 'андреевичу', 'анове', 'ану', 'ані', 'анітелень', 'апреля', 'архістратига', 'б', 'ба', 'баба', 'бабу', 'бабусенько', 'бабусю', 'багатии', 'багато', 'багатого', 'багатому', 'багаті', 'базар', 'базари', 'базару', 'базарі', 'базиліан', 'баи', 'балака', 'бандуристе', 'барвінком', 'барився', 'барись', 'бариші', 'батечку', 'батогами', 'батька', 'батьки', 'батько', 'батьком', 'батьку', 'батьків', 'батьківщина', 'бач', 'бачать', 'бачив', 'бачила', 'бачили', 'бачите', 'бачить', 'бачиш', 'бачся', 'бачте', 'бачу', 'бевзь', 'без', 'безбатченком', 'безголов', 'безкрає', 'безкраі', 'безславному', 'безумную', 'белькотали', 'бенкет', 'бенкетували', 'бенкетують', 'бенкетує', 'бенкеті', 'бере', 'берлин', 'берлині', 'беріть', 'бестія', 'би', 'бивсь', 'бився', 'бии', 'била', 'били']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"728G42sdptQe","executionInfo":{"status":"ok","timestamp":1634482631205,"user_tz":-180,"elapsed":8,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"3b33d3de-ec46-4c89-9576-d69a6eada101"},"source":["word2index = vectorizer.vocabulary_\n","# word2index['UNK'] = len(word2index)\n","word2index"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'причинна': 3108,\n"," '\\n': 0,\n"," 'реве': 3241,\n"," 'та': 3870,\n"," 'стогне': 3765,\n"," 'дніпр': 909,\n"," 'широкии': 4393,\n"," ',': 2,\n"," 'сердитии': 3478,\n"," 'вітер': 597,\n"," 'завива': 1203,\n"," 'додолу': 942,\n"," 'верби': 300,\n"," 'гне': 669,\n"," 'високі': 420,\n"," 'горами': 736,\n"," 'хвилю': 4144,\n"," 'підіи': 3203,\n"," 'ма': 1977,\n"," '.': 4,\n"," 'і': 4549,\n"," 'бліднии': 125,\n"," 'місяць': 2180,\n"," 'на': 2185,\n"," 'ту': 3994,\n"," 'пору': 2958,\n"," 'із': 4563,\n"," 'хмари': 4165,\n"," 'де': 859,\n"," '-': 3,\n"," 'виглядав': 355,\n"," 'неначе': 2320,\n"," 'човен': 4302,\n"," 'в': 240,\n"," 'синім': 3517,\n"," 'морі': 2130,\n"," 'то': 3946,\n"," 'виринав': 401,\n"," 'потопав': 3000,\n"," 'ще': 4453,\n"," 'треті': 3977,\n"," 'півні': 3185,\n"," 'не': 2275,\n"," 'співали': 3695,\n"," 'ніхто': 2408,\n"," 'нігде': 2397,\n"," 'гомонів': 727,\n"," 'сичі': 3531,\n"," 'гаю': 636,\n"," 'перекликались': 2663,\n"," 'ясен': 4522,\n"," 'раз': 3226,\n"," 'у': 4022,\n"," 'скрипів': 3549,\n"," 'таку': 3881,\n"," 'добу': 925,\n"," 'під': 3189,\n"," 'горою': 745,\n"," 'біля': 237,\n"," 'того': 3952,\n"," 'що': 4466,\n"," 'чорніє': 4329,\n"," 'над': 2214,\n"," 'водою': 473,\n"," 'щось': 4473,\n"," 'біле': 232,\n"," 'блукає': 124,\n"," 'може': 2095,\n"," 'вии': 370,\n"," 'шла': 4408,\n"," 'русалонька': 3362,\n"," 'матері': 2010,\n"," 'шукати': 4444,\n"," 'а': 17,\n"," 'жде': 1118,\n"," 'козаченька': 1670,\n"," 'щоб': 4467,\n"," 'залоскотати': 1261,\n"," 'дівчина': 1062,\n"," 'ходить': 4178,\n"," 'и': 1528,\n"," 'сама': 3405,\n"," 'зна': 1458,\n"," 'бо': 127,\n"," 'такеє': 3875,\n"," 'робить': 3256,\n"," 'так': 3871,\n"," 'ворожка': 502,\n"," 'поробила': 2953,\n"," 'менше': 2031,\n"," 'скучала': 3554,\n"," 'бач': 64,\n"," 'ходя': 4182,\n"," 'опівночі': 2512,\n"," 'спала': 3649,\n"," 'виглядала': 358,\n"," 'молодого': 2113,\n"," 'торік': 3969,\n"," 'покинув': 2855,\n"," 'обіщався': 2436,\n"," 'вернутися': 311,\n"," 'мабуть': 1978,\n"," 'згинув': 1413,\n"," '!': 1,\n"," 'китаи': 1614,\n"," 'кою': 1736,\n"," 'покрились': 2867,\n"," 'козацькіі': 1668,\n"," 'очі': 2585,\n"," 'вимили': 385,\n"," 'личко': 1891,\n"," 'слізоньки': 3582,\n"," 'дівочі': 1058,\n"," 'орел': 2516,\n"," 'няв': 2390,\n"," 'карі': 1568,\n"," 'чужому': 4346,\n"," 'полі': 2904,\n"," 'тіло': 4017,\n"," 'вовки': 465,\n"," 'з': 1176,\n"," 'ли': 1868,\n"," 'така': 3872,\n"," 'ого': 2442,\n"," 'доля': 957,\n"," 'дарма': 848,\n"," 'щоніч': 4472,\n"," 'дівчинонька': 1064,\n"," 'виглядає': 361,\n"," 'вернеться': 305,\n"," 'чорнобривии': 4315,\n"," 'привітає': 3072,\n"," 'розплете': 3325,\n"," 'довгу': 930,\n"," 'косу': 1723,\n"," 'хустку': 4216,\n"," 'зав': 1196,\n"," 'яже': 4480,\n"," 'ліжко': 1957,\n"," 'домовину': 963,\n"," 'сиротою': 3527,\n"," 'ляже': 1943,\n"," 'о': 2413,\n"," 'боже': 137,\n"," 'міи': 2176,\n"," 'милии': 2048,\n"," 'за': 1177,\n"," 'ж': 1096,\n"," 'ти': 3929,\n"," 'караєш': 1562,\n"," 'молоду': 2115,\n"," '?': 5,\n"," 'те': 3910,\n"," 'щиро': 4463,\n"," 'вона': 492,\n"," 'полюбила': 2898,\n"," 'прости': 3148,\n"," 'сироту': 3528,\n"," 'кого': 1647,\n"," 'любити': 1916,\n"," 'ні': 2393,\n"," 'батька': 57,\n"," 'неньки': 2321,\n"," 'одна': 2461,\n"," 'як': 4486,\n"," 'пташка': 3172,\n"," 'далекім': 836,\n"," 'краю': 1748,\n"," 'пошли': 3037,\n"," 'долю': 956,\n"," 'молоденька': 2106,\n"," 'люде': 1922,\n"," 'чужіі': 4351,\n"," 'засміють': 1343,\n"," 'чи': 4283,\n"," 'винна': 392,\n"," 'голубка': 718,\n"," 'голуба': 716,\n"," 'любить': 1917,\n"," 'винен': 389,\n"," 'тои': 3954,\n"," 'голуб': 715,\n"," 'сокіл': 3629,\n"," 'убив': 4024,\n"," 'сумує': 3811,\n"," 'воркує': 495,\n"," 'білим': 233,\n"," 'світом': 3455,\n"," 'нудить': 2382,\n"," 'літає': 1972,\n"," 'шукає': 4446,\n"," 'дума': 1018,\n"," 'заблудив': 1183,\n"," 'щаслива': 4451,\n"," 'високо': 417,\n"," 'полине': 2884,\n"," 'до': 914,\n"," 'бога': 129,\n"," 'милого': 2050,\n"," 'питать': 2697,\n"," 'сиротина': 3524,\n"," 'запитає': 1298,\n"," 'хто': 4210,\n"," 'розкаже': 3285,\n"," 'теє': 3928,\n"," 'знає': 1470,\n"," 'ночує': 2375,\n"," 'темному': 3916,\n"," 'бистрім': 104,\n"," 'дунаю': 1026,\n"," 'коня': 1703,\n"," 'напува': 2249,\n"," 'другою': 995,\n"," 'другую': 997,\n"," 'кохає': 1734,\n"," 'чорнобриву': 4317,\n"," 'уже': 4040,\n"," 'забува': 1186,\n"," 'якби': 4488,\n"," 'далися': 838,\n"," 'орлиніі': 2519,\n"," 'крила': 1758,\n"," 'би': 94,\n"," 'морем': 2125,\n"," 'знаи': 1461,\n"," 'живого': 1128,\n"," 'б': 32,\n"," 'любила': 1914,\n"," 'другу': 996,\n"," 'задушила': 1238,\n"," 'неживого': 2310,\n"," 'яму': 4502,\n"," 'лягла': 1940,\n"," 'серце': 3481,\n"," 'ким': 1606,\n"," 'поділиться': 2818,\n"," 'воно': 494,\n"," 'хоче': 4197,\n"," 'бог': 128,\n"," 'нам': 2239,\n"," 'дає': 852,\n"," 'жить': 1150,\n"," 'журиться': 1170,\n"," 'журись': 1168,\n"," 'каже': 1534,\n"," 'думка': 1024,\n"," 'жалю': 1100,\n"," 'завдає': 1198,\n"," 'твоя': 3907,\n"," 'воля': 490,\n"," 'таке': 3874,\n"," 'щастя': 4452,\n"," 'все': 522,\n"," 'уст': 4092,\n"," 'пари': 2633,\n"," 'гомонить': 724,\n"," 'розбивши': 3272,\n"," 'чорні': 4326,\n"," 'ліг': 1955,\n"," 'моря': 2129,\n"," 'одпочить': 2473,\n"," 'неба': 2276,\n"," 'сяє': 3847,\n"," 'гаєм': 637,\n"," 'кругом': 1782,\n"," 'усі': 4094,\n"," 'мовчить': 2085,\n"," 'аж': 21,\n"," 'гульк': 800,\n"," 'дніпра': 910,\n"," 'повиринали': 2753,\n"," 'маліі': 2001,\n"," 'діти': 1084,\n"," 'сміючись': 3601,\n"," 'ходімо': 4184,\n"," 'гріться': 781,\n"," 'закричали': 1253,\n"," 'зіи': 1523,\n"," 'шло': 4411,\n"," 'вже': 340,\n"," 'сонце': 3635,\n"," 'голі': 723,\n"," 'скрізь': 3551,\n"," 'осоки': 2529,\n"," 'коси': 1719,\n"," 'дівчата': 1060,\n"," 'всі': 539,\n"," 'ви': 351,\n"," 'тута': 4002,\n"," 'кличе': 1624,\n"," 'мати': 2011,\n"," 'ходім': 4183,\n"," 'вечерять': 335,\n"," 'пограємось': 2793,\n"," 'погуляи': 2795,\n"," 'мо': 2076,\n"," 'пісеньку': 3210,\n"," 'заспіваи': 1353,\n"," 'ух': 4110,\n"," 'солом': 3631,\n"," 'янии': 4509,\n"," 'дух': 1036,\n"," 'мене': 2030,\n"," 'породила': 2956,\n"," 'нехрещену': 2339,\n"," 'положила': 2891,\n"," 'місяченьку': 2182,\n"," 'наш': 2264,\n"," 'голубоньку': 721,\n"," 'ходи': 4175,\n"," 'нас': 2254,\n"," 'вечеряти': 334,\n"," 'козак': 1650,\n"," 'очереті': 2582,\n"," 'осоці': 2530,\n"," 'срібнии': 3710,\n"," 'перстень': 2674,\n"," 'руці': 3365,\n"," 'молоденькии': 2107,\n"," 'чорнобровии': 4319,\n"," 'шли': 4409,\n"," 'вчора': 568,\n"," 'діброві': 1054,\n"," 'світи': 3449,\n"," 'довше': 934,\n"," 'чистім': 4296,\n"," 'нагулятись': 2213,\n"," 'доволі': 933,\n"," 'поки': 2848,\n"," 'відьми': 574,\n"," 'літають': 1970,\n"," 'співають': 3700,\n"," 'посвіти': 2963,\n"," 'он': 2503,\n"," 'дубом': 1011,\n"," 'там': 3884,\n"," 'зареготались': 1325,\n"," 'нехрещені': 2340,\n"," 'гаи': 617,\n"," 'обізвався': 2433,\n"," 'галас': 619,\n"," 'зик': 1440,\n"," 'орда': 2514,\n"," 'мов': 2077,\n"," 'ріже': 3387,\n"," 'скажені': 3535,\n"," 'летять': 1863,\n"," 'дуба': 1009,\n"," 'нічичирк': 2410,\n"," 'схаменулись': 3819,\n"," 'нехреіцені': 2341,\n"," 'дивляться': 887,\n"," 'мелькає': 2029,\n"," 'лізе': 1959,\n"," 'вверх': 276,\n"," 'по': 2726,\n"," 'стовбуру': 3764,\n"," 'самого': 3410,\n"," 'ото': 2563,\n"," 'тая': 3903,\n"," 'сонна': 3633,\n"," 'блудила': 121,\n"," 'отаку': 2556,\n"," 'причину': 3109,\n"," 'зробила': 1502,\n"," 'самии': 3407,\n"," 'верх': 318,\n"," 'гіллячці': 812,\n"," 'стала': 3716,\n"," 'коле': 1680,\n"," 'подивилась': 2804,\n"," 'боки': 143,\n"," 'русалоньки': 3363,\n"," 'мовчки': 2086,\n"," 'дожидали': 945,\n"," 'взяли': 346,\n"," 'сердешную': 3477,\n"," 'залоскотали': 1260,\n"," 'довго': 929,\n"," 'дивовались': 890,\n"," 'уроду': 4084,\n"," 'кукуріку': 1793,\n"," 'шелеснули': 4376,\n"," 'воду': 474,\n"," 'защебетав': 1384,\n"," 'жаи': 1098,\n"," 'воронок': 508,\n"," 'угору': 4035,\n"," 'летючи': 1862,\n"," 'закувала': 1256,\n"," 'зозуленька': 1482,\n"," 'дубу': 1012,\n"," 'сидячи': 3491,\n"," 'соловеи': 3630,\n"," 'ко': 1636,\n"," 'пішла': 3216,\n"," 'луна': 1903,\n"," 'червоніє': 4272,\n"," 'плугатар': 2725,\n"," 'співає': 3702,\n"," 'ляхи': 1950,\n"," 'ходили': 4177,\n"," 'засиніли': 1340,\n"," 'понад': 2923,\n"," 'дніпром': 913,\n"," 'могили': 2089,\n"," 'пішов': 3218,\n"," 'шелест': 4377,\n"," 'шепчуть': 4383,\n"," 'густі': 810,\n"," 'лози': 1898,\n"," 'спить': 3670,\n"," 'при': 3058,\n"," 'битіи': 109,\n"," 'дорозі': 970,\n"," 'знать': 1466,\n"," 'добре': 916,\n"," 'чує': 4361,\n"," 'кує': 1815,\n"," 'зозуля': 1483,\n"," 'лічить': 1975,\n"," 'заснула': 1348,\n"," 'тим': 3931,\n"," 'часом': 4258,\n"," 'діброви': 1052,\n"," 'виі': 445,\n"," 'жджає': 1120,\n"," 'ним': 2349,\n"," 'коник': 1697,\n"," 'вороненькии': 505,\n"," 'насилу': 2255,\n"," 'ступає': 3795,\n"," 'ізнемігся': 4565,\n"," 'товаришу': 3949,\n"," 'сьогодні': 3838,\n"," 'спочинем': 3683,\n"," 'близько': 116,\n"," 'хата': 4129,\n"," 'ворота': 512,\n"," 'одчинить': 2481,\n"," 'одчинила': 2480,\n"," 'мені': 2032,\n"," 'другому': 994,\n"," 'швидше': 4375,\n"," 'коню': 1702,\n"," 'поспішаи': 2981,\n"," 'додому': 943,\n"," 'утомився': 4101,\n"," 'іде': 4557,\n"," 'спотикнеться': 3677,\n"," 'коло': 1685,\n"," 'серця': 3483,\n"," 'козацького': 1663,\n"," 'гадина': 613,\n"," 'ється': 4544,\n"," 'ось': 2546,\n"," 'дуб': 1008,\n"," 'кучерявии': 1813,\n"," 'виглядавши': 356,\n"," 'моя': 2150,\n"," 'сизокрила': 3495,\n"," 'кинув': 1608,\n"," 'неі': 2345,\n"," 'цілує': 4248,\n"," 'поможе': 2909,\n"," 'вони': 493,\n"," 'розлучили': 3303,\n"," 'тобою': 3947,\n"," 'зареготавсь': 1324,\n"," 'розігнався': 3337,\n"," 'головою': 704,\n"," 'ідуть': 4560,\n"," 'поле': 2873,\n"," 'жати': 1114,\n"," 'ідучи': 4561,\n"," 'проводжала': 3114,\n"," 'сина': 3502,\n"," 'бивсь': 95,\n"," 'татарин': 3900,\n"," 'уночі': 4073,\n"," 'зелененьким': 1429,\n"," 'кінь': 1820,\n"," 'замордовании': 1274,\n"," 'стоі': 3780,\n"," 'ть': 4004,\n"," 'лежить': 1857,\n"," 'цікаві': 4244,\n"," 'правди': 3043,\n"," 'підкралися': 3195,\n"," 'ізлякать': 4564,\n"," 'коли': 1681,\n"," 'подивляться': 2810,\n"," 'вбитии': 272,\n"," 'переполоху': 2667,\n"," 'ну': 2378,\n"," 'втікать': 563,\n"," 'збиралися': 1389,\n"," 'подруженьки': 2813,\n"," 'втирають': 548,\n"," 'товариші': 3950,\n"," 'ями': 4501,\n"," 'копають': 1706,\n"," 'прии': 3083,\n"," 'попи': 2934,\n"," 'корогвами': 1711,\n"," 'задзвонили': 1230,\n"," 'дзвони': 872,\n"," 'поховали': 3012,\n"," 'громадою': 771,\n"," 'слід': 3579,\n"," 'закону': 1249,\n"," 'насипали': 2256,\n"," 'краи': 1741,\n"," 'дороги': 968,\n"," 'дві': 858,\n"," 'житі': 1151,\n"," 'нема': 2317,\n"," 'кому': 1691,\n"," 'запитати': 1297,\n"," 'х': 4120,\n"," 'убито': 4028,\n"," 'посадили': 2961,\n"," 'козаком': 1655,\n"," 'явір': 4478,\n"," 'ялину': 4499,\n"," 'головах': 699,\n"," 'дівчини': 1063,\n"," 'червону': 4268,\n"," 'калину': 1546,\n"," 'прилітає': 3088,\n"," 'ними': 2350,\n"," 'кувати': 1791,\n"," 'щебетати': 4455,\n"," 'виспівує': 424,\n"," 'щебече': 4457,\n"," 'тіі': 4021,\n"," 'грітись': 780,\n"," 'дуть': 1034,\n"," 'тече': 3927,\n"," 'вода': 469,\n"," 'синє': 3513,\n"," 'море': 2124,\n"," 'витікає': 434,\n"," 'шука': 4440,\n"," 'свою': 3428,\n"," 'долі': 958,\n"," 'немає': 2318,\n"," 'світ': 3446,\n"," 'грає': 762,\n"," 'козацькеє': 1661,\n"," 'говорить': 680,\n"," 'куди': 1792,\n"," 'деш': 870,\n"," 'спитавшись': 3663,\n"," 'неньку': 2323,\n"," 'старенькую': 3726,\n"," 'дівчину': 1065,\n"," 'чужині': 4344,\n"," 'ті': 4013,\n"," 'тяжко': 4009,\n"," 'жити': 1148,\n"," 'буде': 193,\n"," 'поплакати': 2937,\n"," 'поговорити': 2790,\n"," 'сидить': 3489,\n"," 'тім': 4020,\n"," 'боці': 155,\n"," 'думав': 1019,\n"," 'зустрінеться': 1514,\n"," 'спіткалося': 3706,\n"," 'горе': 737,\n"," 'журавлі': 1161,\n"," 'собі': 3623,\n"," 'ключами': 1626,\n"," 'плаче': 2715,\n"," 'шляхи': 4422,\n"," 'биті': 108,\n"," 'заросли': 1330,\n"," 'тернами': 3923,\n"," 'вітре': 599,\n"," 'бучнии': 222,\n"," 'буи': 209,\n"," 'нии': 2347,\n"," 'говориш': 681,\n"," 'збуди': 1393,\n"," 'заграи': 1222,\n"," 'спитаи': 3664,\n"," 'носило': 2367,\n"," 'скаже': 3532,\n"," 'поділо': 2819,\n"," 'втопило': 555,\n"," 'розбии': 3273,\n"," 'піду': 3201,\n"," 'шукать': 4445,\n"," 'миленького': 2047,\n"," 'втоплю': 556,\n"," 'своє': 3430,\n"," 'недоленьку': 2303,\n"," 'русалкою': 3361,\n"," 'стану': 3723,\n"," 'пошукаю': 3039,\n"," 'чорних': 4313,\n"," 'хвилях': 4145,\n"," 'дно': 906,\n"," 'кану': 1553,\n"," 'наи': 2227,\n"," 'ду': 1007,\n"," 'пригорнуся': 3075,\n"," 'серці': 3484,\n"," 'зомлію': 1491,\n"," 'тоді': 3953,\n"," 'хвиле': 4143,\n"," 'неси': 2330,\n"," 'милим': 2049,\n"," 'віє': 609,\n"," 'несенькии': 2328,\n"," 'знаєш': 1473,\n"," 'він': 589,\n"," 'розмовляєш': 3313,\n"," 'я': 4476,\n"," 'плачу': 2718,\n"," 'співаю': 3699,\n"," 'погибаю': 2786,\n"," 'тогді': 3951,\n"," 'мою': 2149,\n"," 'душу': 1043,\n"," 'туди': 3996,\n"," 'червоною': 4267,\n"," 'калиною': 1545,\n"," 'постав': 2983,\n"," 'могилі': 2092,\n"," 'легше': 1848,\n"," 'чужім': 4350,\n"," 'сироті': 3529,\n"," 'лежати': 1855,\n"," 'мила': 2046,\n"," 'квіткою': 1594,\n"," 'стояти': 3778,\n"," 'цвісти': 4226,\n"," 'буду': 203,\n"," 'пекло': 2651,\n"," 'чуже': 4340,\n"," 'топтали': 3963,\n"," 'ввечері': 278,\n"," 'посумую': 2992,\n"," 'вранці': 518,\n"," 'поплачу': 2938,\n"," 'утру': 4107,\n"," 'сльози': 3576,\n"," 'побачить': 2730,\n"," 'важко': 244,\n"," 'світі': 3457,\n"," 'без': 76,\n"," 'роду': 3266,\n"," 'прихилиться': 3106,\n"," 'хоч': 4196,\n"," 'гори': 739,\n"," 'утопився': 4104,\n"," 'дітись': 1085,\n"," 'полем': 2874,\n"," 'колоски': 1687,\n"," 'збирає': 1392,\n"," 'десь': 864,\n"," 'ледащиця': 1850,\n"," 'тому': 3955,\n"," 'багатому': 41,\n"," 'люди': 1924,\n"," 'знають': 1468,\n"," 'зо': 1478,\n"," 'мною': 2075,\n"," 'зустрінуться': 1516,\n"," 'недобачають': 2298,\n"," 'багатого': 40,\n"," 'губатого': 792,\n"," 'шанує': 4370,\n"," 'надо': 2216,\n"," 'сміється': 3606,\n"," 'кепкує': 1598,\n"," 'тобі': 3948,\n"," 'вродливии': 520,\n"," 'тебе': 3911,\n"," 'вдався': 282,\n"," 'люблю': 1918,\n"," 'сміявся': 3603,\n"," 'люби': 1912,\n"," 'моє': 2151,\n"," 'сміи': 3593,\n"," 'ся': 3841,\n"," 'згадаєш': 1408,\n"," 'світа': 3447,\n"," 'чужіи': 4349,\n"," 'сторонці': 3774,\n"," 'кращу': 1747,\n"," 'або': 20,\n"," 'згину': 1412,\n"," 'лист': 1877,\n"," 'сонці': 3638,\n"," 'сумуючи': 3810,\n"," 'нікого': 2399,\n"," 'шукав': 4441,\n"," 'загинув': 1216,\n"," 'умираючи': 4063,\n"," 'дивився': 877,\n"," 'сонечко': 3632,\n"," 'умирати': 4062,\n"," 'гатчина': 635,\n"," 'ноября': 2377,\n"," 'року': 3341,\n"," 'нащо': 2274,\n"," 'брови': 186,\n"," 'літа': 1967,\n"," 'молодіі': 2117,\n"," 'веселі': 326,\n"," 'моі': 2153,\n"," 'марно': 2008,\n"," 'пропадають': 3140,\n"," 'плачуть': 2719,\n"," 'од': 2446,\n"," 'вітру': 602,\n"," 'линяють': 1876,\n"," 'яне': 4506,\n"," 'волі': 491,\n"," 'краса': 1743,\n"," 'сім': 3855,\n"," 'своі': 3433,\n"," 'говорити': 679,\n"," 'розпитати': 3320,\n"," 'чого': 4305,\n"," 'розказати': 3290,\n"," 'день': 862,\n"," 'ніч': 2409,\n"," 'питає': 2700,\n"," 'чужі': 4348,\n"," 'спитають': 3668,\n"," 'питати': 2696,\n"," 'нехаи': 2336,\n"," 'тратить': 3973,\n"," 'плач': 2714,\n"," 'же': 1121,\n"," 'плачте': 2717,\n"," 'заснули': 1349,\n"," 'голосніше': 713,\n"," 'жалібніше': 1101,\n"," 'вітри': 600,\n"," 'почули': 3030,\n"," 'понесли': 2926,\n"," 'несенькі': 2329,\n"," 'синєє': 3514,\n"," 'чорнявому': 4324,\n"," 'зрадливому': 1500,\n"," 'лютеє': 1935,\n"," 'вічну': 604,\n"," 'пам': 2601,\n"," 'ять': 4531,\n"," 'котляревському': 1726,\n"," 'гріє': 790,\n"," 'поля': 2899,\n"," 'долину': 952,\n"," 'вербою': 301,\n"," 'калині': 1547,\n"," 'одиноке': 2457,\n"," 'гніздечко': 677,\n"," 'гои': 694,\n"," 'дівся': 1059,\n"," 'питаи': 2693,\n"," 'згадаи': 1402,\n"," 'лихо': 1886,\n"," 'баи': 48,\n"," 'дуже': 1014,\n"," 'минулось': 2063,\n"," 'пропало': 3144,\n"," 'чому': 4308,\n"," 'осталось': 2537,\n"," 'отож': 2564,\n"," 'гляну': 664,\n"," 'згадаю': 1404,\n"," 'було': 214,\n"," 'смеркає': 3586,\n"," 'защебече': 1385,\n"," 'минає': 2056,\n"," 'багатии': 38,\n"," 'дитину': 898,\n"," 'убирає': 4026,\n"," 'доглядає': 938,\n"," 'мине': 2057,\n"," 'сирота': 3521,\n"," 'встає': 533,\n"," 'працювати': 3052,\n"," 'опиниться': 2510,\n"," 'послухає': 2977,\n"," 'батько': 59,\n"," 'розпитують': 3324,\n"," 'розмовляють': 3311,\n"," 'любо': 1919,\n"," 'божии': 139,\n"," 'великдень': 290,\n"," 'щодень': 4468,\n"," 'сохне': 3646,\n"," 'піде': 3191,\n"," 'шлях': 4413,\n"," 'подивитись': 2808,\n"," 'сохнуть': 3648,\n"," 'дрібні': 1005,\n"," 'усміхнеться': 4089,\n"," 'темним': 3914,\n"," 'ніби': 2394,\n"," 'розмовляла': 3308,\n"," 'дрібно': 1004,\n"," 'рівно': 3383,\n"," 'благає': 111,\n"," 'злодіи': 1445,\n"," 'погулять': 2798,\n"," 'ножем': 2364,\n"," 'халяві': 4126,\n"," 'руна': 3360,\n"," 'замовкне': 1271,\n"," 'щебетать': 4456,\n"," 'запеклую': 1292,\n"," 'злодія': 1446,\n"," 'спинить': 3657,\n"," 'тільки': 4018,\n"," 'стратить': 3783,\n"," 'голос': 709,\n"," 'добру': 922,\n"," 'навчить': 2193,\n"," 'лютує': 1938,\n"," 'сам': 3404,\n"," 'загине': 1213,\n"," 'безголов': 78,\n"," 'ворон': 504,\n"," 'прокричить': 3133,\n"," 'засне': 1346,\n"," 'долина': 951,\n"," 'задріма': 1235,\n"," 'повіє': 2769,\n"," 'долині': 953,\n"," 'дібровою': 1053,\n"," 'гуляє': 807,\n"," 'божа': 136,\n"," 'мова': 2078,\n"," 'встануть': 531,\n"," 'сердеги': 3473,\n"," 'працювать': 3053,\n"," 'корови': 1709,\n"," 'підуть': 3202,\n"," 'брать': 174,\n"," 'гляне': 662,\n"," 'раи': 3228,\n"," 'годі': 693,\n"," 'верба': 299,\n"," 'свято': 3440,\n"," 'заплаче': 1306,\n"," 'лютии': 1936,\n"," 'перш': 2675,\n"," 'тепер': 3921,\n"," 'дивись': 879,\n"," 'недавно': 2297,\n"," 'украі': 4047,\n"," 'старии': 3728,\n"," 'котляревськии': 1725,\n"," 'отак': 2551,\n"," 'щебетав': 4454,\n"," 'замовк': 1270,\n"," 'неборака': 2283,\n"," 'сиротами': 3522,\n"," 'перше': 2677,\n"," 'витав': 427,\n"," 'ватагу': 259,\n"," 'прои': 3120,\n"," 'дисвіта': 895,\n"," 'водив': 471,\n"," 'собою': 3622,\n"," 'руі': 3373,\n"," 'ни': 2346,\n"," 'троі': 3983,\n"," 'слава': 3555,\n"," 'сонцем': 3636,\n"," 'засіяла': 1364,\n"," 'вмре': 453,\n"," 'кобзар': 1637,\n"," 'навіки': 2194,\n"," 'привітала': 3070,\n"," 'будеш': 196,\n"," 'батьку': 61,\n"," 'панувати': 2623,\n"," 'живуть': 1131,\n"," 'забудуть': 1192,\n"," 'праведная': 3046,\n"," 'душе': 1040,\n"," 'ми': 2043,\n"," 'мову': 2080,\n"," 'мудру': 2160,\n"," 'щиру': 4464,\n"," 'привітаи': 3069,\n"," 'кинь': 1611,\n"," 'прилини': 3084,\n"," 'одно': 2464,\n"," 'слово': 3563,\n"," 'про': 3111,\n"," 'дивлячись': 888,\n"," 'всю': 534,\n"," 'славу': 3559,\n"," 'козацьку': 1665,\n"," 'словом': 3564,\n"," 'єдиним': 4536,\n"," 'переніс': 2666,\n"," 'убогу': 4033,\n"," 'хату': 4136,\n"," 'сироти': 3523,\n"," 'прилинь': 3085,\n"," 'сизии': 3494,\n"," 'орле': 2517,\n"," 'одинокии': 2458,\n"," 'дивлюся': 886,\n"," 'широке': 4391,\n"," 'глибоке': 658,\n"," 'поплив': 2940,\n"," 'бік': 231,\n"," 'човна': 4303,\n"," 'дають': 851,\n"," 'бнея': 126,\n"," 'родину': 3265,\n"," 'заплачу': 1308,\n"," 'дитина': 896,\n"," 'хвилі': 4146,\n"," 'ревуть': 3243,\n"," 'темнии': 3913,\n"," 'нічого': 2412,\n"," 'бачу': 74,\n"," 'злая': 1442,\n"," 'усюди': 4093,\n"," 'осміють': 2527,\n"," 'сміялись': 3604,\n"," 'ясніше': 4526,\n"," 'сія': 3867,\n"," 'вітром': 601,\n"," 'могила': 2088,\n"," 'степу': 3759,\n"," 'розмовляє': 3312,\n"," 'був': 190,\n"," 'нею': 2344,\n"," 'катерина': 1572,\n"," 'василию': 255,\n"," 'андреевичу': 25,\n"," 'жуковскому': 1156,\n"," 'память': 2602,\n"," 'апреля': 30,\n"," 'года': 684,\n"," 'кохаи': 1728,\n"," 'теся': 3926,\n"," 'чорнобриві': 4318,\n"," 'москалями': 2138,\n"," 'москалі': 2139,\n"," 'роблять': 3259,\n"," 'вами': 248,\n"," 'москаль': 2135,\n"," 'жартуючи': 1109,\n"," 'кине': 1607,\n"," 'московщину': 2145,\n"," 'гине': 651,\n"," 'стара': 3725,\n"," 'привела': 3065,\n"," 'мусить': 2167,\n"," 'погибати': 2785,\n"," 'співаючи': 3701,\n"," 'побачать': 2727,\n"," 'скажуть': 3539,\n"," 'ледащо': 1852,\n"," 'знущаються': 1475,\n"," 'слухала': 3567,\n"," 'москалика': 2132,\n"," 'знало': 1464,\n"," 'серденько': 3474,\n"," 'садочок': 3402,\n"," 'ходила': 4176,\n"," 'себе': 3459,\n"," 'занапастила': 1280,\n"," 'донька': 965,\n"," 'жартує': 1110,\n"," 'москаликом': 2134,\n"," 'заночує': 1284,\n"," 'ночі': 2376,\n"," 'цілувала': 4246,\n"," 'село': 3464,\n"," 'недобрая': 2300,\n"," 'хотять': 4191,\n"," 'говорять': 682,\n"," 'вкралося': 448,\n"," 'вісти': 595,\n"," 'недобріі': 2302,\n"," 'поход': 3017,\n"," 'затрубили': 1371,\n"," 'туреччину': 4000,\n"," 'катрусю': 1582,\n"," 'накрили': 2230,\n"," 'незчулася': 2316,\n"," 'коса': 1718,\n"," 'покрита': 2868,\n"," 'співати': 3696,\n"," 'потужити': 3002,\n"," ...}"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"yMgRJ22ZptQe"},"source":["# import operator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eYLZJq3nptQf","executionInfo":{"status":"ok","timestamp":1634482695272,"user_tz":-180,"elapsed":243,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"533b2f98-b4dc-4957-f09d-1744910b3f9f"},"source":["index2word = {v:k for k,v in word2index.items()}\n","index2word"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{3108: 'причинна',\n"," 0: '\\n',\n"," 3241: 'реве',\n"," 3870: 'та',\n"," 3765: 'стогне',\n"," 909: 'дніпр',\n"," 4393: 'широкии',\n"," 2: ',',\n"," 3478: 'сердитии',\n"," 597: 'вітер',\n"," 1203: 'завива',\n"," 942: 'додолу',\n"," 300: 'верби',\n"," 669: 'гне',\n"," 420: 'високі',\n"," 736: 'горами',\n"," 4144: 'хвилю',\n"," 3203: 'підіи',\n"," 1977: 'ма',\n"," 4: '.',\n"," 4549: 'і',\n"," 125: 'бліднии',\n"," 2180: 'місяць',\n"," 2185: 'на',\n"," 3994: 'ту',\n"," 2958: 'пору',\n"," 4563: 'із',\n"," 4165: 'хмари',\n"," 859: 'де',\n"," 3: '-',\n"," 355: 'виглядав',\n"," 2320: 'неначе',\n"," 4302: 'човен',\n"," 240: 'в',\n"," 3517: 'синім',\n"," 2130: 'морі',\n"," 3946: 'то',\n"," 401: 'виринав',\n"," 3000: 'потопав',\n"," 4453: 'ще',\n"," 3977: 'треті',\n"," 3185: 'півні',\n"," 2275: 'не',\n"," 3695: 'співали',\n"," 2408: 'ніхто',\n"," 2397: 'нігде',\n"," 727: 'гомонів',\n"," 3531: 'сичі',\n"," 636: 'гаю',\n"," 2663: 'перекликались',\n"," 4522: 'ясен',\n"," 3226: 'раз',\n"," 4022: 'у',\n"," 3549: 'скрипів',\n"," 3881: 'таку',\n"," 925: 'добу',\n"," 3189: 'під',\n"," 745: 'горою',\n"," 237: 'біля',\n"," 3952: 'того',\n"," 4466: 'що',\n"," 4329: 'чорніє',\n"," 2214: 'над',\n"," 473: 'водою',\n"," 4473: 'щось',\n"," 232: 'біле',\n"," 124: 'блукає',\n"," 2095: 'може',\n"," 370: 'вии',\n"," 4408: 'шла',\n"," 3362: 'русалонька',\n"," 2010: 'матері',\n"," 4444: 'шукати',\n"," 17: 'а',\n"," 1118: 'жде',\n"," 1670: 'козаченька',\n"," 4467: 'щоб',\n"," 1261: 'залоскотати',\n"," 1062: 'дівчина',\n"," 4178: 'ходить',\n"," 1528: 'и',\n"," 3405: 'сама',\n"," 1458: 'зна',\n"," 127: 'бо',\n"," 3875: 'такеє',\n"," 3256: 'робить',\n"," 3871: 'так',\n"," 502: 'ворожка',\n"," 2953: 'поробила',\n"," 2031: 'менше',\n"," 3554: 'скучала',\n"," 64: 'бач',\n"," 4182: 'ходя',\n"," 2512: 'опівночі',\n"," 3649: 'спала',\n"," 358: 'виглядала',\n"," 2113: 'молодого',\n"," 3969: 'торік',\n"," 2855: 'покинув',\n"," 2436: 'обіщався',\n"," 311: 'вернутися',\n"," 1978: 'мабуть',\n"," 1413: 'згинув',\n"," 1: '!',\n"," 1614: 'китаи',\n"," 1736: 'кою',\n"," 2867: 'покрились',\n"," 1668: 'козацькіі',\n"," 2585: 'очі',\n"," 385: 'вимили',\n"," 1891: 'личко',\n"," 3582: 'слізоньки',\n"," 1058: 'дівочі',\n"," 2516: 'орел',\n"," 2390: 'няв',\n"," 1568: 'карі',\n"," 4346: 'чужому',\n"," 2904: 'полі',\n"," 4017: 'тіло',\n"," 465: 'вовки',\n"," 1176: 'з',\n"," 1868: 'ли',\n"," 3872: 'така',\n"," 2442: 'ого',\n"," 957: 'доля',\n"," 848: 'дарма',\n"," 4472: 'щоніч',\n"," 1064: 'дівчинонька',\n"," 361: 'виглядає',\n"," 305: 'вернеться',\n"," 4315: 'чорнобривии',\n"," 3072: 'привітає',\n"," 3325: 'розплете',\n"," 930: 'довгу',\n"," 1723: 'косу',\n"," 4216: 'хустку',\n"," 1196: 'зав',\n"," 4480: 'яже',\n"," 1957: 'ліжко',\n"," 963: 'домовину',\n"," 3527: 'сиротою',\n"," 1943: 'ляже',\n"," 2413: 'о',\n"," 137: 'боже',\n"," 2176: 'міи',\n"," 2048: 'милии',\n"," 1177: 'за',\n"," 1096: 'ж',\n"," 3929: 'ти',\n"," 1562: 'караєш',\n"," 2115: 'молоду',\n"," 5: '?',\n"," 3910: 'те',\n"," 4463: 'щиро',\n"," 492: 'вона',\n"," 2898: 'полюбила',\n"," 3148: 'прости',\n"," 3528: 'сироту',\n"," 1647: 'кого',\n"," 1916: 'любити',\n"," 2393: 'ні',\n"," 57: 'батька',\n"," 2321: 'неньки',\n"," 2461: 'одна',\n"," 4486: 'як',\n"," 3172: 'пташка',\n"," 836: 'далекім',\n"," 1748: 'краю',\n"," 3037: 'пошли',\n"," 956: 'долю',\n"," 2106: 'молоденька',\n"," 1922: 'люде',\n"," 4351: 'чужіі',\n"," 1343: 'засміють',\n"," 4283: 'чи',\n"," 392: 'винна',\n"," 718: 'голубка',\n"," 716: 'голуба',\n"," 1917: 'любить',\n"," 389: 'винен',\n"," 3954: 'тои',\n"," 715: 'голуб',\n"," 3629: 'сокіл',\n"," 4024: 'убив',\n"," 3811: 'сумує',\n"," 495: 'воркує',\n"," 233: 'білим',\n"," 3455: 'світом',\n"," 2382: 'нудить',\n"," 1972: 'літає',\n"," 4446: 'шукає',\n"," 1018: 'дума',\n"," 1183: 'заблудив',\n"," 4451: 'щаслива',\n"," 417: 'високо',\n"," 2884: 'полине',\n"," 914: 'до',\n"," 129: 'бога',\n"," 2050: 'милого',\n"," 2697: 'питать',\n"," 3524: 'сиротина',\n"," 1298: 'запитає',\n"," 4210: 'хто',\n"," 3285: 'розкаже',\n"," 3928: 'теє',\n"," 1470: 'знає',\n"," 2375: 'ночує',\n"," 3916: 'темному',\n"," 104: 'бистрім',\n"," 1026: 'дунаю',\n"," 1703: 'коня',\n"," 2249: 'напува',\n"," 995: 'другою',\n"," 997: 'другую',\n"," 1734: 'кохає',\n"," 4317: 'чорнобриву',\n"," 4040: 'уже',\n"," 1186: 'забува',\n"," 4488: 'якби',\n"," 838: 'далися',\n"," 2519: 'орлиніі',\n"," 1758: 'крила',\n"," 94: 'би',\n"," 2125: 'морем',\n"," 1461: 'знаи',\n"," 1128: 'живого',\n"," 32: 'б',\n"," 1914: 'любила',\n"," 996: 'другу',\n"," 1238: 'задушила',\n"," 2310: 'неживого',\n"," 4502: 'яму',\n"," 1940: 'лягла',\n"," 3481: 'серце',\n"," 1606: 'ким',\n"," 2818: 'поділиться',\n"," 494: 'воно',\n"," 4197: 'хоче',\n"," 128: 'бог',\n"," 2239: 'нам',\n"," 852: 'дає',\n"," 1150: 'жить',\n"," 1170: 'журиться',\n"," 1168: 'журись',\n"," 1534: 'каже',\n"," 1024: 'думка',\n"," 1100: 'жалю',\n"," 1198: 'завдає',\n"," 3907: 'твоя',\n"," 490: 'воля',\n"," 3874: 'таке',\n"," 4452: 'щастя',\n"," 522: 'все',\n"," 4092: 'уст',\n"," 2633: 'пари',\n"," 724: 'гомонить',\n"," 3272: 'розбивши',\n"," 4326: 'чорні',\n"," 1955: 'ліг',\n"," 2129: 'моря',\n"," 2473: 'одпочить',\n"," 2276: 'неба',\n"," 3847: 'сяє',\n"," 637: 'гаєм',\n"," 1782: 'кругом',\n"," 4094: 'усі',\n"," 2085: 'мовчить',\n"," 21: 'аж',\n"," 800: 'гульк',\n"," 910: 'дніпра',\n"," 2753: 'повиринали',\n"," 2001: 'маліі',\n"," 1084: 'діти',\n"," 3601: 'сміючись',\n"," 4184: 'ходімо',\n"," 781: 'гріться',\n"," 1253: 'закричали',\n"," 1523: 'зіи',\n"," 4411: 'шло',\n"," 340: 'вже',\n"," 3635: 'сонце',\n"," 723: 'голі',\n"," 3551: 'скрізь',\n"," 2529: 'осоки',\n"," 1719: 'коси',\n"," 1060: 'дівчата',\n"," 539: 'всі',\n"," 351: 'ви',\n"," 4002: 'тута',\n"," 1624: 'кличе',\n"," 2011: 'мати',\n"," 4183: 'ходім',\n"," 335: 'вечерять',\n"," 2793: 'пограємось',\n"," 2795: 'погуляи',\n"," 2076: 'мо',\n"," 3210: 'пісеньку',\n"," 1353: 'заспіваи',\n"," 4110: 'ух',\n"," 3631: 'солом',\n"," 4509: 'янии',\n"," 1036: 'дух',\n"," 2030: 'мене',\n"," 2956: 'породила',\n"," 2339: 'нехрещену',\n"," 2891: 'положила',\n"," 2182: 'місяченьку',\n"," 2264: 'наш',\n"," 721: 'голубоньку',\n"," 4175: 'ходи',\n"," 2254: 'нас',\n"," 334: 'вечеряти',\n"," 1650: 'козак',\n"," 2582: 'очереті',\n"," 2530: 'осоці',\n"," 3710: 'срібнии',\n"," 2674: 'перстень',\n"," 3365: 'руці',\n"," 2107: 'молоденькии',\n"," 4319: 'чорнобровии',\n"," 4409: 'шли',\n"," 568: 'вчора',\n"," 1054: 'діброві',\n"," 3449: 'світи',\n"," 934: 'довше',\n"," 4296: 'чистім',\n"," 2213: 'нагулятись',\n"," 933: 'доволі',\n"," 2848: 'поки',\n"," 574: 'відьми',\n"," 1970: 'літають',\n"," 3700: 'співають',\n"," 2963: 'посвіти',\n"," 2503: 'он',\n"," 1011: 'дубом',\n"," 3884: 'там',\n"," 1325: 'зареготались',\n"," 2340: 'нехрещені',\n"," 617: 'гаи',\n"," 2433: 'обізвався',\n"," 619: 'галас',\n"," 1440: 'зик',\n"," 2514: 'орда',\n"," 2077: 'мов',\n"," 3387: 'ріже',\n"," 3535: 'скажені',\n"," 1863: 'летять',\n"," 1009: 'дуба',\n"," 2410: 'нічичирк',\n"," 3819: 'схаменулись',\n"," 2341: 'нехреіцені',\n"," 887: 'дивляться',\n"," 2029: 'мелькає',\n"," 1959: 'лізе',\n"," 276: 'вверх',\n"," 2726: 'по',\n"," 3764: 'стовбуру',\n"," 3410: 'самого',\n"," 2563: 'ото',\n"," 3903: 'тая',\n"," 3633: 'сонна',\n"," 121: 'блудила',\n"," 2556: 'отаку',\n"," 3109: 'причину',\n"," 1502: 'зробила',\n"," 3407: 'самии',\n"," 318: 'верх',\n"," 812: 'гіллячці',\n"," 3716: 'стала',\n"," 1680: 'коле',\n"," 2804: 'подивилась',\n"," 143: 'боки',\n"," 3363: 'русалоньки',\n"," 2086: 'мовчки',\n"," 945: 'дожидали',\n"," 346: 'взяли',\n"," 3477: 'сердешную',\n"," 1260: 'залоскотали',\n"," 929: 'довго',\n"," 890: 'дивовались',\n"," 4084: 'уроду',\n"," 1793: 'кукуріку',\n"," 4376: 'шелеснули',\n"," 474: 'воду',\n"," 1384: 'защебетав',\n"," 1098: 'жаи',\n"," 508: 'воронок',\n"," 4035: 'угору',\n"," 1862: 'летючи',\n"," 1256: 'закувала',\n"," 1482: 'зозуленька',\n"," 1012: 'дубу',\n"," 3491: 'сидячи',\n"," 3630: 'соловеи',\n"," 1636: 'ко',\n"," 3216: 'пішла',\n"," 1903: 'луна',\n"," 4272: 'червоніє',\n"," 2725: 'плугатар',\n"," 3702: 'співає',\n"," 1950: 'ляхи',\n"," 4177: 'ходили',\n"," 1340: 'засиніли',\n"," 2923: 'понад',\n"," 913: 'дніпром',\n"," 2089: 'могили',\n"," 3218: 'пішов',\n"," 4377: 'шелест',\n"," 4383: 'шепчуть',\n"," 810: 'густі',\n"," 1898: 'лози',\n"," 3670: 'спить',\n"," 3058: 'при',\n"," 109: 'битіи',\n"," 970: 'дорозі',\n"," 1466: 'знать',\n"," 916: 'добре',\n"," 4361: 'чує',\n"," 1815: 'кує',\n"," 1483: 'зозуля',\n"," 1975: 'лічить',\n"," 1348: 'заснула',\n"," 3931: 'тим',\n"," 4258: 'часом',\n"," 1052: 'діброви',\n"," 445: 'виі',\n"," 1120: 'жджає',\n"," 2349: 'ним',\n"," 1697: 'коник',\n"," 505: 'вороненькии',\n"," 2255: 'насилу',\n"," 3795: 'ступає',\n"," 4565: 'ізнемігся',\n"," 3949: 'товаришу',\n"," 3838: 'сьогодні',\n"," 3683: 'спочинем',\n"," 116: 'близько',\n"," 4129: 'хата',\n"," 512: 'ворота',\n"," 2481: 'одчинить',\n"," 2480: 'одчинила',\n"," 2032: 'мені',\n"," 994: 'другому',\n"," 4375: 'швидше',\n"," 1702: 'коню',\n"," 2981: 'поспішаи',\n"," 943: 'додому',\n"," 4101: 'утомився',\n"," 4557: 'іде',\n"," 3677: 'спотикнеться',\n"," 1685: 'коло',\n"," 3483: 'серця',\n"," 1663: 'козацького',\n"," 613: 'гадина',\n"," 4544: 'ється',\n"," 2546: 'ось',\n"," 1008: 'дуб',\n"," 1813: 'кучерявии',\n"," 356: 'виглядавши',\n"," 2150: 'моя',\n"," 3495: 'сизокрила',\n"," 1608: 'кинув',\n"," 2345: 'неі',\n"," 4248: 'цілує',\n"," 2909: 'поможе',\n"," 493: 'вони',\n"," 3303: 'розлучили',\n"," 3947: 'тобою',\n"," 1324: 'зареготавсь',\n"," 3337: 'розігнався',\n"," 704: 'головою',\n"," 4560: 'ідуть',\n"," 2873: 'поле',\n"," 1114: 'жати',\n"," 4561: 'ідучи',\n"," 3114: 'проводжала',\n"," 3502: 'сина',\n"," 95: 'бивсь',\n"," 3900: 'татарин',\n"," 4073: 'уночі',\n"," 1429: 'зелененьким',\n"," 1820: 'кінь',\n"," 1274: 'замордовании',\n"," 3780: 'стоі',\n"," 4004: 'ть',\n"," 1857: 'лежить',\n"," 4244: 'цікаві',\n"," 3043: 'правди',\n"," 3195: 'підкралися',\n"," 4564: 'ізлякать',\n"," 1681: 'коли',\n"," 2810: 'подивляться',\n"," 272: 'вбитии',\n"," 2667: 'переполоху',\n"," 2378: 'ну',\n"," 563: 'втікать',\n"," 1389: 'збиралися',\n"," 2813: 'подруженьки',\n"," 548: 'втирають',\n"," 3950: 'товариші',\n"," 4501: 'ями',\n"," 1706: 'копають',\n"," 3083: 'прии',\n"," 2934: 'попи',\n"," 1711: 'корогвами',\n"," 1230: 'задзвонили',\n"," 872: 'дзвони',\n"," 3012: 'поховали',\n"," 771: 'громадою',\n"," 3579: 'слід',\n"," 1249: 'закону',\n"," 2256: 'насипали',\n"," 1741: 'краи',\n"," 968: 'дороги',\n"," 858: 'дві',\n"," 1151: 'житі',\n"," 2317: 'нема',\n"," 1691: 'кому',\n"," 1297: 'запитати',\n"," 4120: 'х',\n"," 4028: 'убито',\n"," 2961: 'посадили',\n"," 1655: 'козаком',\n"," 4478: 'явір',\n"," 4499: 'ялину',\n"," 699: 'головах',\n"," 1063: 'дівчини',\n"," 4268: 'червону',\n"," 1546: 'калину',\n"," 3088: 'прилітає',\n"," 2350: 'ними',\n"," 1791: 'кувати',\n"," 4455: 'щебетати',\n"," 424: 'виспівує',\n"," 4457: 'щебече',\n"," 4021: 'тіі',\n"," 780: 'грітись',\n"," 1034: 'дуть',\n"," 3927: 'тече',\n"," 469: 'вода',\n"," 3513: 'синє',\n"," 2124: 'море',\n"," 434: 'витікає',\n"," 4440: 'шука',\n"," 3428: 'свою',\n"," 958: 'долі',\n"," 2318: 'немає',\n"," 3446: 'світ',\n"," 762: 'грає',\n"," 1661: 'козацькеє',\n"," 680: 'говорить',\n"," 1792: 'куди',\n"," 870: 'деш',\n"," 3663: 'спитавшись',\n"," 2323: 'неньку',\n"," 3726: 'старенькую',\n"," 1065: 'дівчину',\n"," 4344: 'чужині',\n"," 4013: 'ті',\n"," 4009: 'тяжко',\n"," 1148: 'жити',\n"," 193: 'буде',\n"," 2937: 'поплакати',\n"," 2790: 'поговорити',\n"," 3489: 'сидить',\n"," 4020: 'тім',\n"," 155: 'боці',\n"," 1019: 'думав',\n"," 1514: 'зустрінеться',\n"," 3706: 'спіткалося',\n"," 737: 'горе',\n"," 1161: 'журавлі',\n"," 3623: 'собі',\n"," 1626: 'ключами',\n"," 2715: 'плаче',\n"," 4422: 'шляхи',\n"," 108: 'биті',\n"," 1330: 'заросли',\n"," 3923: 'тернами',\n"," 599: 'вітре',\n"," 222: 'бучнии',\n"," 209: 'буи',\n"," 2347: 'нии',\n"," 681: 'говориш',\n"," 1393: 'збуди',\n"," 1222: 'заграи',\n"," 3664: 'спитаи',\n"," 2367: 'носило',\n"," 3532: 'скаже',\n"," 2819: 'поділо',\n"," 555: 'втопило',\n"," 3273: 'розбии',\n"," 3201: 'піду',\n"," 4445: 'шукать',\n"," 2047: 'миленького',\n"," 556: 'втоплю',\n"," 3430: 'своє',\n"," 2303: 'недоленьку',\n"," 3361: 'русалкою',\n"," 3723: 'стану',\n"," 3039: 'пошукаю',\n"," 4313: 'чорних',\n"," 4145: 'хвилях',\n"," 906: 'дно',\n"," 1553: 'кану',\n"," 2227: 'наи',\n"," 1007: 'ду',\n"," 3075: 'пригорнуся',\n"," 3484: 'серці',\n"," 1491: 'зомлію',\n"," 3953: 'тоді',\n"," 4143: 'хвиле',\n"," 2330: 'неси',\n"," 2049: 'милим',\n"," 609: 'віє',\n"," 2328: 'несенькии',\n"," 1473: 'знаєш',\n"," 589: 'він',\n"," 3313: 'розмовляєш',\n"," 4476: 'я',\n"," 2718: 'плачу',\n"," 3699: 'співаю',\n"," 2786: 'погибаю',\n"," 3951: 'тогді',\n"," 2149: 'мою',\n"," 1043: 'душу',\n"," 3996: 'туди',\n"," 4267: 'червоною',\n"," 1545: 'калиною',\n"," 2983: 'постав',\n"," 2092: 'могилі',\n"," 1848: 'легше',\n"," 4350: 'чужім',\n"," 3529: 'сироті',\n"," 1855: 'лежати',\n"," 2046: 'мила',\n"," 1594: 'квіткою',\n"," 3778: 'стояти',\n"," 4226: 'цвісти',\n"," 203: 'буду',\n"," 2651: 'пекло',\n"," 4340: 'чуже',\n"," 3963: 'топтали',\n"," 278: 'ввечері',\n"," 2992: 'посумую',\n"," 518: 'вранці',\n"," 2938: 'поплачу',\n"," 4107: 'утру',\n"," 3576: 'сльози',\n"," 2730: 'побачить',\n"," 244: 'важко',\n"," 3457: 'світі',\n"," 76: 'без',\n"," 3266: 'роду',\n"," 3106: 'прихилиться',\n"," 4196: 'хоч',\n"," 739: 'гори',\n"," 4104: 'утопився',\n"," 1085: 'дітись',\n"," 2874: 'полем',\n"," 1687: 'колоски',\n"," 1392: 'збирає',\n"," 864: 'десь',\n"," 1850: 'ледащиця',\n"," 3955: 'тому',\n"," 41: 'багатому',\n"," 1924: 'люди',\n"," 1468: 'знають',\n"," 1478: 'зо',\n"," 2075: 'мною',\n"," 1516: 'зустрінуться',\n"," 2298: 'недобачають',\n"," 40: 'багатого',\n"," 792: 'губатого',\n"," 4370: 'шанує',\n"," 2216: 'надо',\n"," 3606: 'сміється',\n"," 1598: 'кепкує',\n"," 3948: 'тобі',\n"," 520: 'вродливии',\n"," 3911: 'тебе',\n"," 282: 'вдався',\n"," 1918: 'люблю',\n"," 3603: 'сміявся',\n"," 1912: 'люби',\n"," 2151: 'моє',\n"," 3593: 'сміи',\n"," 3841: 'ся',\n"," 1408: 'згадаєш',\n"," 3447: 'світа',\n"," 4349: 'чужіи',\n"," 3774: 'сторонці',\n"," 1747: 'кращу',\n"," 20: 'або',\n"," 1412: 'згину',\n"," 1877: 'лист',\n"," 3638: 'сонці',\n"," 3810: 'сумуючи',\n"," 2399: 'нікого',\n"," 4441: 'шукав',\n"," 1216: 'загинув',\n"," 4063: 'умираючи',\n"," 877: 'дивився',\n"," 3632: 'сонечко',\n"," 4062: 'умирати',\n"," 635: 'гатчина',\n"," 2377: 'ноября',\n"," 3341: 'року',\n"," 2274: 'нащо',\n"," 186: 'брови',\n"," 1967: 'літа',\n"," 2117: 'молодіі',\n"," 326: 'веселі',\n"," 2153: 'моі',\n"," 2008: 'марно',\n"," 3140: 'пропадають',\n"," 2719: 'плачуть',\n"," 2446: 'од',\n"," 602: 'вітру',\n"," 1876: 'линяють',\n"," 4506: 'яне',\n"," 491: 'волі',\n"," 1743: 'краса',\n"," 3855: 'сім',\n"," 3433: 'своі',\n"," 679: 'говорити',\n"," 3320: 'розпитати',\n"," 4305: 'чого',\n"," 3290: 'розказати',\n"," 862: 'день',\n"," 2409: 'ніч',\n"," 2700: 'питає',\n"," 4348: 'чужі',\n"," 3668: 'спитають',\n"," 2696: 'питати',\n"," 2336: 'нехаи',\n"," 3973: 'тратить',\n"," 2714: 'плач',\n"," 1121: 'же',\n"," 2717: 'плачте',\n"," 1349: 'заснули',\n"," 713: 'голосніше',\n"," 1101: 'жалібніше',\n"," 600: 'вітри',\n"," 3030: 'почули',\n"," 2926: 'понесли',\n"," 2329: 'несенькі',\n"," 3514: 'синєє',\n"," 4324: 'чорнявому',\n"," 1500: 'зрадливому',\n"," 1935: 'лютеє',\n"," 604: 'вічну',\n"," 2601: 'пам',\n"," 4531: 'ять',\n"," 1726: 'котляревському',\n"," 790: 'гріє',\n"," 2899: 'поля',\n"," 952: 'долину',\n"," 301: 'вербою',\n"," 1547: 'калині',\n"," 2457: 'одиноке',\n"," 677: 'гніздечко',\n"," 694: 'гои',\n"," 1059: 'дівся',\n"," 2693: 'питаи',\n"," 1402: 'згадаи',\n"," 1886: 'лихо',\n"," 48: 'баи',\n"," 1014: 'дуже',\n"," 2063: 'минулось',\n"," 3144: 'пропало',\n"," 4308: 'чому',\n"," 2537: 'осталось',\n"," 2564: 'отож',\n"," 664: 'гляну',\n"," 1404: 'згадаю',\n"," 214: 'було',\n"," 3586: 'смеркає',\n"," 1385: 'защебече',\n"," 2056: 'минає',\n"," 38: 'багатии',\n"," 898: 'дитину',\n"," 4026: 'убирає',\n"," 938: 'доглядає',\n"," 2057: 'мине',\n"," 3521: 'сирота',\n"," 533: 'встає',\n"," 3052: 'працювати',\n"," 2510: 'опиниться',\n"," 2977: 'послухає',\n"," 59: 'батько',\n"," 3324: 'розпитують',\n"," 3311: 'розмовляють',\n"," 1919: 'любо',\n"," 139: 'божии',\n"," 290: 'великдень',\n"," 4468: 'щодень',\n"," 3646: 'сохне',\n"," 3191: 'піде',\n"," 4413: 'шлях',\n"," 2808: 'подивитись',\n"," 3648: 'сохнуть',\n"," 1005: 'дрібні',\n"," 4089: 'усміхнеться',\n"," 3914: 'темним',\n"," 2394: 'ніби',\n"," 3308: 'розмовляла',\n"," 1004: 'дрібно',\n"," 3383: 'рівно',\n"," 111: 'благає',\n"," 1445: 'злодіи',\n"," 2798: 'погулять',\n"," 2364: 'ножем',\n"," 4126: 'халяві',\n"," 3360: 'руна',\n"," 1271: 'замовкне',\n"," 4456: 'щебетать',\n"," 1292: 'запеклую',\n"," 1446: 'злодія',\n"," 3657: 'спинить',\n"," 4018: 'тільки',\n"," 3783: 'стратить',\n"," 709: 'голос',\n"," 922: 'добру',\n"," 2193: 'навчить',\n"," 1938: 'лютує',\n"," 3404: 'сам',\n"," 1213: 'загине',\n"," 78: 'безголов',\n"," 504: 'ворон',\n"," 3133: 'прокричить',\n"," 1346: 'засне',\n"," 951: 'долина',\n"," 1235: 'задріма',\n"," 2769: 'повіє',\n"," 953: 'долині',\n"," 1053: 'дібровою',\n"," 807: 'гуляє',\n"," 136: 'божа',\n"," 2078: 'мова',\n"," 531: 'встануть',\n"," 3473: 'сердеги',\n"," 3053: 'працювать',\n"," 1709: 'корови',\n"," 3202: 'підуть',\n"," 174: 'брать',\n"," 662: 'гляне',\n"," 3228: 'раи',\n"," 693: 'годі',\n"," 299: 'верба',\n"," 3440: 'свято',\n"," 1306: 'заплаче',\n"," 1936: 'лютии',\n"," 2675: 'перш',\n"," 3921: 'тепер',\n"," 879: 'дивись',\n"," 2297: 'недавно',\n"," 4047: 'украі',\n"," 3728: 'старии',\n"," 1725: 'котляревськии',\n"," 2551: 'отак',\n"," 4454: 'щебетав',\n"," 1270: 'замовк',\n"," 2283: 'неборака',\n"," 3522: 'сиротами',\n"," 2677: 'перше',\n"," 427: 'витав',\n"," 259: 'ватагу',\n"," 3120: 'прои',\n"," 895: 'дисвіта',\n"," 471: 'водив',\n"," 3622: 'собою',\n"," 3373: 'руі',\n"," 2346: 'ни',\n"," 3983: 'троі',\n"," 3555: 'слава',\n"," 3636: 'сонцем',\n"," 1364: 'засіяла',\n"," 453: 'вмре',\n"," 1637: 'кобзар',\n"," 2194: 'навіки',\n"," 3070: 'привітала',\n"," 196: 'будеш',\n"," 61: 'батьку',\n"," 2623: 'панувати',\n"," 1131: 'живуть',\n"," 1192: 'забудуть',\n"," 3046: 'праведная',\n"," 1040: 'душе',\n"," 2043: 'ми',\n"," 2080: 'мову',\n"," 2160: 'мудру',\n"," 4464: 'щиру',\n"," 3069: 'привітаи',\n"," 1611: 'кинь',\n"," 3084: 'прилини',\n"," 2464: 'одно',\n"," 3563: 'слово',\n"," 3111: 'про',\n"," 888: 'дивлячись',\n"," 534: 'всю',\n"," 3559: 'славу',\n"," 1665: 'козацьку',\n"," 3564: 'словом',\n"," 4536: 'єдиним',\n"," 2666: 'переніс',\n"," 4033: 'убогу',\n"," 4136: 'хату',\n"," 3523: 'сироти',\n"," 3085: 'прилинь',\n"," 3494: 'сизии',\n"," 2517: 'орле',\n"," 2458: 'одинокии',\n"," 886: 'дивлюся',\n"," 4391: 'широке',\n"," 658: 'глибоке',\n"," 2940: 'поплив',\n"," 231: 'бік',\n"," 4303: 'човна',\n"," 851: 'дають',\n"," 126: 'бнея',\n"," 3265: 'родину',\n"," 1308: 'заплачу',\n"," 896: 'дитина',\n"," 4146: 'хвилі',\n"," 3243: 'ревуть',\n"," 3913: 'темнии',\n"," 2412: 'нічого',\n"," 74: 'бачу',\n"," 1442: 'злая',\n"," 4093: 'усюди',\n"," 2527: 'осміють',\n"," 3604: 'сміялись',\n"," 4526: 'ясніше',\n"," 3867: 'сія',\n"," 601: 'вітром',\n"," 2088: 'могила',\n"," 3759: 'степу',\n"," 3312: 'розмовляє',\n"," 190: 'був',\n"," 2344: 'нею',\n"," 1572: 'катерина',\n"," 255: 'василию',\n"," 25: 'андреевичу',\n"," 1156: 'жуковскому',\n"," 2602: 'память',\n"," 30: 'апреля',\n"," 684: 'года',\n"," 1728: 'кохаи',\n"," 3926: 'теся',\n"," 4318: 'чорнобриві',\n"," 2138: 'москалями',\n"," 2139: 'москалі',\n"," 3259: 'роблять',\n"," 248: 'вами',\n"," 2135: 'москаль',\n"," 1109: 'жартуючи',\n"," 1607: 'кине',\n"," 2145: 'московщину',\n"," 651: 'гине',\n"," 3725: 'стара',\n"," 3065: 'привела',\n"," 2167: 'мусить',\n"," 2785: 'погибати',\n"," 3701: 'співаючи',\n"," 2727: 'побачать',\n"," 3539: 'скажуть',\n"," 1852: 'ледащо',\n"," 1475: 'знущаються',\n"," 3567: 'слухала',\n"," 2132: 'москалика',\n"," 1464: 'знало',\n"," 3474: 'серденько',\n"," 3402: 'садочок',\n"," 4176: 'ходила',\n"," 3459: 'себе',\n"," 1280: 'занапастила',\n"," 965: 'донька',\n"," 1110: 'жартує',\n"," 2134: 'москаликом',\n"," 1284: 'заночує',\n"," 2376: 'ночі',\n"," 4246: 'цілувала',\n"," 3464: 'село',\n"," 2300: 'недобрая',\n"," 4191: 'хотять',\n"," 682: 'говорять',\n"," 448: 'вкралося',\n"," 595: 'вісти',\n"," 2302: 'недобріі',\n"," 3017: 'поход',\n"," 1371: 'затрубили',\n"," 4000: 'туреччину',\n"," 1582: 'катрусю',\n"," 2230: 'накрили',\n"," 2316: 'незчулася',\n"," 1718: 'коса',\n"," 2868: 'покрита',\n"," 3696: 'співати',\n"," 3002: 'потужити',\n"," ...}"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PnM4vcjNptQf","executionInfo":{"status":"ok","timestamp":1634482657162,"user_tz":-180,"elapsed":212,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"9307845f-7b02-4064-aa30-370f9966e144"},"source":["word_tokenizer = vectorizer.build_tokenizer()\n","raw_tokens = word_tokenizer(text) \n","\n","tokens = sorted(set(raw_tokens))\n","print('len of all tokens = {:,}'.format(len(raw_tokens)))\n","print('len of unique tokens = {:,}'.format(len(tokens)))"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["len of all tokens = 26,094\n","len of unique tokens = 4,587\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1eAmLTrhptQg","executionInfo":{"status":"ok","timestamp":1634482659446,"user_tz":-180,"elapsed":227,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"00b335a2-364f-4fa8-8727-07df40ae6f96"},"source":["n_context  = 7\n","step = 1 # shift to build new sample \n","contexts = []\n","targets = []\n","for i in range(0, len(raw_tokens) - n_context, step):\n","    contexts.append(raw_tokens[i: i + n_context])\n","    targets.append(raw_tokens[i + n_context])\n","print('len(samples) = {:,}'.format(len(contexts)))\n","\n","for i in range (20):\n","    print ('{} -> {}'.format (contexts[i], targets[i]))\n"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["len(samples) = 26,087\n","['причинна', '\\n', 'реве', 'та', 'стогне', 'дніпр', 'широкии'] -> ,\n","['\\n', 'реве', 'та', 'стогне', 'дніпр', 'широкии', ','] -> сердитии\n","['реве', 'та', 'стогне', 'дніпр', 'широкии', ',', 'сердитии'] -> вітер\n","['та', 'стогне', 'дніпр', 'широкии', ',', 'сердитии', 'вітер'] -> завива\n","['стогне', 'дніпр', 'широкии', ',', 'сердитии', 'вітер', 'завива'] -> ,\n","['дніпр', 'широкии', ',', 'сердитии', 'вітер', 'завива', ','] -> додолу\n","['широкии', ',', 'сердитии', 'вітер', 'завива', ',', 'додолу'] -> верби\n","[',', 'сердитии', 'вітер', 'завива', ',', 'додолу', 'верби'] -> гне\n","['сердитии', 'вітер', 'завива', ',', 'додолу', 'верби', 'гне'] -> високі\n","['вітер', 'завива', ',', 'додолу', 'верби', 'гне', 'високі'] -> ,\n","['завива', ',', 'додолу', 'верби', 'гне', 'високі', ','] -> горами\n","[',', 'додолу', 'верби', 'гне', 'високі', ',', 'горами'] -> хвилю\n","['додолу', 'верби', 'гне', 'високі', ',', 'горами', 'хвилю'] -> підіи\n","['верби', 'гне', 'високі', ',', 'горами', 'хвилю', 'підіи'] -> ма\n","['гне', 'високі', ',', 'горами', 'хвилю', 'підіи', 'ма'] -> .\n","['високі', ',', 'горами', 'хвилю', 'підіи', 'ма', '.'] -> \n","\n","[',', 'горами', 'хвилю', 'підіи', 'ма', '.', '\\n'] -> і\n","['горами', 'хвилю', 'підіи', 'ма', '.', '\\n', 'і'] -> бліднии\n","['хвилю', 'підіи', 'ма', '.', '\\n', 'і', 'бліднии'] -> місяць\n","['підіи', 'ма', '.', '\\n', 'і', 'бліднии', 'місяць'] -> на\n"]}]},{"cell_type":"code","metadata":{"id":"MfJk1XsVptQh","executionInfo":{"status":"ok","timestamp":1634482663763,"user_tz":-180,"elapsed":2,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}}},"source":["import numpy as np "],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hh8DxBayptQh","executionInfo":{"status":"ok","timestamp":1634482665231,"user_tz":-180,"elapsed":403,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"d6fccb02-7d9e-40b4-a4f3-237884b5fafc"},"source":["print('Converting to one-hot vectors...')\n","x = np.zeros((len(contexts), n_context, len(tokens)), dtype=np.bool)\n","y = np.zeros((len(contexts), len(tokens)), dtype=np.bool)\n","for i, context in enumerate(contexts):\n","    for t, token in enumerate(context):\n","        x[i, t, word2index[token]] = 1\n","    y[i, word2index[targets[i]]] = 1\n","print('Done.')"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Converting to one-hot vectors...\n","Done.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6zZQxaD2ptQi","executionInfo":{"status":"ok","timestamp":1634483385006,"user_tz":-180,"elapsed":685230,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"b4f2ae94-f237-4615-e711-84901e3ac269"},"source":["print('Build model (single LSTM)...')\n","model = Sequential()\n","model.add(LSTM(128, input_shape=(n_context, len(tokens))))\n","model.add(Dense(len(tokens), activation='softmax'))\n","\n","optimizer = RMSprop(lr=0.01)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n","\n","def sample(preds, diversity=1.0):\n","    # helper function to sample an index from a probability array\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / diversity\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)\n","\n","\n","def on_epoch_end(epoch, _):\n","    # Function invoked at end of each epoch. Prints generated text.    \n","    print('\\n----- Generating text after Epoch: %d' % epoch)\n","\n","    start_index = random.randint(0, len(raw_tokens) - n_context - 1)\n","    for diversity in [0.2, 0.5, 1.0, 1.2]:\n","        print('--- diversity:', diversity)        \n","        context = raw_tokens[start_index: start_index + n_context]\n","        print('--- Generated with the following context: {}'.format(context))\n","        # sys.stdout.write(generated)\n","        orig_context = list (context)\n","        generated = []\n","        for i in range(40): # number of tokens to gerenerate \n","            x_pred = np.zeros((1, n_context, len(tokens)))\n","            for t, token in enumerate(context):\n","                x_pred[0, t, word2index[token]] = 1.\n","\n","            preds = model.predict(x_pred, verbose=0)[0]\n","            next_index = sample(preds, diversity)\n","            next_word = index2word[next_index]\n","\n","            generated += [next_word]\n","            \n","            # update context for next pass             \n","            context = context[1:] + [next_word]\n","\n","        print ('{} -> {}'.format(' '.join(orig_context) , ' '.join(generated)))\n","            #             sys.stdout.write(next_char)\n","            #             sys.stdout.flush()\n","\n","print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n","\n","model.fit(x, y,\n","          batch_size=128,\n","          epochs=60,\n","          callbacks=[print_callback])"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Build model (single LSTM)...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","204/204 [==============================] - 6s 17ms/step - loss: 5.9322\n","\n","----- Generating text after Epoch: 0\n","--- diversity: 0.2\n","--- Generated with the following context: ['.', '\\n', 'без', 'милого', 'батько', ',', 'мати']\n",". \n"," без милого батько , мати -> , \n"," не и ого , \n"," не не . . \n"," а не и , \n"," а не ого , \n"," та и ого , \n"," а не , \n"," не страшне , \n"," та и и ого ,\n","--- diversity: 0.5\n","--- Generated with the following context: ['.', '\\n', 'без', 'милого', 'батько', ',', 'мати']\n",". \n"," без милого батько , мати -> . \n"," а тои , \n"," \n"," та и ого багато , \n"," що важко якби , \n"," а і , не заспіваю . \n"," а , ви , \n"," , що не закуривши , \n"," та и ого мене\n","--- diversity: 1.0\n","--- Generated with the following context: ['.', '\\n', 'без', 'милого', 'батько', ',', 'мати']\n",". \n"," без милого батько , мати -> страшно , даваи ламаи , над гетьманом , на оглянувся , \n"," а земля сліпии ! \n"," місяць . \n"," і ким попову боці завзята , \n"," моє гетьмани не живе , \n"," муки , як ляхам , живуть бо\n","--- diversity: 1.2\n","--- Generated with the following context: ['.', '\\n', 'без', 'милого', 'батько', ',', 'мати']\n",". \n"," без милого батько , мати -> глянем сизии і що ! що , \n"," може ? ляхам на ? ? чом земля , . . поміркує такии . ще побили небудь було ? співають і х залізняком , вражі нічого , а тополя недолю , ,\n","Epoch 2/60\n","204/204 [==============================] - 3s 17ms/step - loss: 5.2755\n","\n","----- Generating text after Epoch: 1\n","--- diversity: 0.2\n","--- Generated with the following context: ['.', '\\n', 'квіти', 'моі', ',', 'діти', '!']\n",". \n"," квіти моі , діти ! -> \n"," \n"," і и ого и ого , \n"," а не чує , \n"," не , як , \n"," \n"," а не знає , \n"," \n"," не и ого , \n"," \n"," а не . . . . . .\n","--- diversity: 0.5\n","--- Generated with the following context: ['.', '\\n', 'квіти', 'моі', ',', 'діти', '!']\n",". \n"," квіти моі , діти ! -> \n"," ти , друже , я , \n"," та не , \n"," як , було , \n"," а в нуте . \n"," \n"," та и ого , \n"," в щира , \n"," і з хаті ? \n"," за тои ду\n","--- diversity: 1.0\n","--- Generated with the following context: ['.', '\\n', 'квіти', 'моі', ',', 'діти', '!']\n",". \n"," квіти моі , діти ! -> \n"," весною те сина , \n"," \n"," чи вчора чорнявии спить моі троі встать , одно пари ляхи скажені . \n"," коли послухаю , чуть таке , \n"," як божии , голуба \n"," щоб ти гармати ! пропали чого ,\n","--- diversity: 1.2\n","--- Generated with the following context: ['.', '\\n', 'квіти', 'моі', ',', 'діти', '!']\n",". \n"," квіти моі , діти ! -> коню ! учора ! меж походжають од багатии ! сміх спита росу , ти те , солом - виспівує ! \n"," всім самии дітьми гаи казать . \n"," кого чорні заплакала ще треті ми де що котляревськии ж хатині вас\n","Epoch 3/60\n","204/204 [==============================] - 4s 18ms/step - loss: 4.8475\n","\n","----- Generating text after Epoch: 2\n","--- diversity: 0.2\n","--- Generated with the following context: ['!', 'знявши', 'шапку', ',', 'став', ',', 'мов']\n","! знявши шапку , став , мов -> не знає , \n"," що и ого , \n"," що я ? \n"," а я . . . \n"," а я . . . \n"," а и ого , що и ого , \n"," що ти ? \n"," і и\n","--- diversity: 0.5\n","--- Generated with the following context: ['!', 'знявши', 'шапку', ',', 'став', ',', 'мов']\n","! знявши шапку , став , мов -> не брате , \n"," що я опиниться , \n"," воно , \n"," і ята , \n"," і х , і х , \n"," і и ого , \n"," що я ? \n"," я ніхто не не . . . а\n","--- diversity: 1.0\n","--- Generated with the following context: ['!', 'знявши', 'шапку', ',', 'став', ',', 'мов']\n","! знявши шапку , став , мов -> тиждень . \n"," залізняком каже , для тином . . . вже знала , не зіроньки козаками , \n"," слово злості москаль \n"," та щебече , хто кого синєє , \n"," що деш , краи говорять . \n"," щоб козачии\n","--- diversity: 1.2\n","--- Generated with the following context: ['!', 'знявши', 'шапку', ',', 'став', ',', 'мов']\n","! знявши шапку , став , мов -> щебетати \n"," встать шукала . \n"," здоров з пожартую плаче мені таку нудить серце горе \n"," оксано моі ти \n"," пропала згадаи де поворкуєм \n"," и ого ними бенкет \n"," а засміється , панків горить побиті , чорним очі ,\n","Epoch 4/60\n","204/204 [==============================] - 3s 17ms/step - loss: 4.4604\n","\n","----- Generating text after Epoch: 3\n","--- diversity: 0.2\n","--- Generated with the following context: ['ходім', ',', 'брате', '!', '\\n', 'взяв', 'максима']\n","ходім , брате ! \n"," взяв максима -> , \n"," і над водою , і х , \n"," як ті дитину , \n"," а тим часом \n"," \n"," а за ним \n"," і и ого , \n"," а за що , \n"," як батько , \n"," як свою\n","--- diversity: 0.5\n","--- Generated with the following context: ['ходім', ',', 'брате', '!', '\\n', 'взяв', 'максима']\n","ходім , брате ! \n"," взяв максима -> , \n"," і х мов серце , \n"," і х насміються , \n"," та и ого . . . \n"," в степу трупом . \n"," а за що ? . . \n"," а я , не ті , \n"," \n","\n","--- diversity: 1.0\n","--- Generated with the following context: ['ходім', ',', 'брате', '!', '\\n', 'взяв', 'максима']\n","ходім , брате ! \n"," взяв максима -> , \n"," не вип вами , хоче танець , \n"," віє и москалі . би , серце діти ! мою убитии . \n"," хто з торбина , поважають на треба кропилами вари , без душу робить , не жидами ,\n","--- diversity: 1.2\n","--- Generated with the following context: ['ходім', ',', 'брате', '!', '\\n', 'взяв', 'максима']\n","ходім , брате ! \n"," взяв максима -> із зав криницю \n"," б боса покинув . \n"," так запорожець - чому не так прокляту інтродукція кадилами річеи коли граи , \n"," палала садами недоля . \n"," нігде ніби сумує \n"," літа ється голуба хатині \n"," вітре лісами ,\n","Epoch 5/60\n","204/204 [==============================] - 4s 17ms/step - loss: 4.1297\n","\n","----- Generating text after Epoch: 4\n","--- diversity: 0.2\n","--- Generated with the following context: ['як', 'руі', 'ни', 'троі', '.', '\\n', 'все']\n","як руі ни троі . \n"," все -> так , все знає , \n"," і і и не . . . \n"," не знає , \n"," не до мене , \n"," не знає , \n"," що и ого не ? \n"," не знає , то и не знає\n","--- diversity: 0.5\n","--- Generated with the following context: ['як', 'руі', 'ни', 'троі', '.', '\\n', 'все']\n","як руі ни троі . \n"," все -> би , все , и люде , \n"," що и ого не ? \n"," не що до , де щоб не б ? \n"," на нас не треба . . . \n"," як з ким діти , \n"," а над\n","--- diversity: 1.0\n","--- Generated with the following context: ['як', 'руі', 'ни', 'троі', '.', '\\n', 'все']\n","як руі ни троі . \n"," все -> все улиці ! . . очі чи серце ? \n"," кругом и ого и здорові , дою и буде , \n"," а ти і і не чуєш , \n"," ви не міи села ? \n"," я не сотники . \n","\n","--- diversity: 1.2\n","--- Generated with the following context: ['як', 'руі', 'ни', 'троі', '.', '\\n', 'все']\n","як руі ни троі . \n"," все -> світить , треба сліпии ляхів він и ого , гриця яку от я могилі гуляють . \n"," якби любе , ним посвіти вітрами . . кого прибуде - \n"," тут . . . по гине украі ! пішла б вии\n","Epoch 6/60\n","204/204 [==============================] - 3s 17ms/step - loss: 3.8360\n","\n","----- Generating text after Epoch: 5\n","--- diversity: 0.2\n","--- Generated with the following context: ['серденько', 'дівоче', ',', 'що', 'плаче', ',', 'сміється']\n","серденько дівоче , що плаче , сміється -> , і тои люде . . . \n"," а я з так і х , що ? \n"," що ж ти ? чи ти , не не знаю ? \n"," не знає , що я ? \n"," чи не ?\n","--- diversity: 0.5\n","--- Generated with the following context: ['серденько', 'дівоче', ',', 'що', 'плаче', ',', 'сміється']\n","серденько дівоче , що плаче , сміється -> , і буде . \n"," не собі , як я , \n"," не знає , то и я не світ \n"," не катерина , не бачить , \n"," а ми не співають . \n"," не співає те , бо не\n","--- diversity: 1.0\n","--- Generated with the following context: ['серденько', 'дівоче', ',', 'що', 'плаче', ',', 'сміється']\n","серденько дівоче , що плаче , сміється -> , і пісню журились . \n"," а тим часом неба давно яму ? заспіває червоніє , а щоб не неба поєднались , співа , одинокии . \n"," кого од водою , не проклята пісню , \n"," щоб коня не лихо\n","--- diversity: 1.2\n","--- Generated with the following context: ['серденько', 'дівоче', ',', 'що', 'плаче', ',', 'сміється']\n","серденько дівоче , що плаче , сміється -> \n"," тяжко и знає , нехаи тіі польщі \n"," убогая б таки хатину . водою ? . . ого ще ! . . ще раз \n"," гаи дамаки . було и ого . . . брать огонь бо за є\n","Epoch 7/60\n","204/204 [==============================] - 3s 17ms/step - loss: 3.6240\n","\n","----- Generating text after Epoch: 6\n","--- diversity: 0.2\n","--- Generated with the following context: ['слова', ',', '\\n', 'що', 'так', 'вона', 'щиро']\n","слова , \n"," що так вона щиро -> колись колись - то я . . . \n"," щоб не я ж , не б б не б б у б ні , а за що ж и ого , \n"," не так , як я , \n"," то\n","--- diversity: 0.5\n","--- Generated with the following context: ['слова', ',', '\\n', 'що', 'так', 'вона', 'щиро']\n","слова , \n"," що так вона щиро -> колись один на світі полі не так того люде , як милии ! ні , ні , ні з ким під синє , нема и ого мати . . . \n"," та и знову . . . \n"," мов та\n","--- diversity: 1.0\n","--- Generated with the following context: ['слова', ',', '\\n', 'що', 'так', 'вона', 'щиро']\n","слова , \n"," що так вона щиро -> про полі над якби ґвалт б од мене , що и ого буду старии пішов серденько люде ! та не дамаки аж данах \n"," та и волі на гне з того , но , тебе очі ? . нехаи б\n","--- diversity: 1.2\n","--- Generated with the following context: ['слова', ',', '\\n', 'що', 'так', 'вона', 'щиро']\n","слова , \n"," що так вона щиро -> ні хату , \n"," ти ку . . . вернуться тяжко тяжко весело згадаю куплю , тополю ! хмарі ! \n"," ходить , при весело \n"," недоленьку чого ярема ! ко піди засміються мов козачество же пекла сліду ! світить\n","Epoch 8/60\n","204/204 [==============================] - 4s 17ms/step - loss: 3.3991\n","\n","----- Generating text after Epoch: 7\n","--- diversity: 0.2\n","--- Generated with the following context: ['шляхтою', ',', 'татарами', 'засідала', 'поле', ',', '\\n']\n","шляхтою , татарами засідала поле , \n"," -> а може , з так і і , що и де , \n"," що він з і де - де ? \n"," де він , де ти ? де ж ? \n"," не б б в , бо а там\n","--- diversity: 0.5\n","--- Generated with the following context: ['шляхтою', ',', 'татарами', 'засідала', 'поле', ',', '\\n']\n","шляхтою , татарами засідала поле , \n"," -> \n"," поле свою долю . а за що ? в хаті ! \n"," коли . . . \n"," \n"," лихо мені , діти ! \n"," де мені де там \n"," де де і де і де ? \n"," де ж\n","--- diversity: 1.0\n","--- Generated with the following context: ['шляхтою', ',', 'татарами', 'засідала', 'поле', ',', '\\n']\n","шляхтою , татарами засідала поле , \n"," -> як свою з лии , те , буду доля , \n"," а і . . . згадає ! \n"," \n"," думка боже милии ! \n"," нащо серце плаче , що богу тебе з ну , ним вже не даи в\n","--- diversity: 1.2\n","--- Generated with the following context: ['шляхтою', ',', 'татарами', 'засідала', 'поле', ',', '\\n']\n","шляхтою , татарами засідала поле , \n"," -> \n"," і гори прокляті . дівчата , підпанки гіркими , мов я колись зірки , \n"," за душі коло не тілько ои степу вони проклятии корови , шло танцювати знову - zyjemy на оддам , нічого шукати \n"," кінь ть\n","Epoch 9/60\n","204/204 [==============================] - 3s 17ms/step - loss: 3.2035\n","\n","----- Generating text after Epoch: 8\n","--- diversity: 0.2\n","--- Generated with the following context: ['улицю', ',', 'колише', 'дитинку', 'поглядає', 'нема', ',']\n","улицю , колише дитинку поглядає нема , -> нема . . . у і х , \n"," що ти не знає , \n"," то и не так \n"," гаи дамаки . \n"," як та на - то . . . \n"," та що , люде ? . .\n","--- diversity: 0.5\n","--- Generated with the following context: ['улицю', ',', 'колише', 'дитинку', 'поглядає', 'нема', ',']\n","улицю , колише дитинку поглядає нема , -> нема . . . громада не плаче ? \n"," тяжко ! . . а дівчата \n"," ся ! . . \n"," \n"," тим часом на за базару \n"," з щоб , не ми , бо не мене . . .\n","--- diversity: 1.0\n","--- Generated with the following context: ['улицю', ',', 'колише', 'дитинку', 'поглядає', 'нема', ',']\n","улицю , колише дитинку поглядає нема , -> нема . . . сльозами и леи треба чорнобрива безголов ту , діброві як мене воля , що ти , ? серця лягли тихесенько . хату , \n"," я приі сім \n"," жить а . я . \n"," в доню\n","--- diversity: 1.2\n","--- Generated with the following context: ['улицю', ',', 'колише', 'дитинку', 'поглядає', 'нема', ',']\n","улицю , колише дитинку поглядає нема , -> нема . . . у ярема в дубом . . . \n"," собі міи подивіться \n"," розказать до краю , і тебе дівчина біле ои як та цілувала , коли коня украи на зіи годі недоленьку вже злякаю не ляхів\n","Epoch 10/60\n","204/204 [==============================] - 3s 17ms/step - loss: 3.0326\n","\n","----- Generating text after Epoch: 9\n","--- diversity: 0.2\n","--- Generated with the following context: ['\\n', 'мертвими', 'словами', '\\n', 'та', 'якогось', '-']\n","\n"," мертвими словами \n"," та якогось - -> то лихо \n"," коло и ого . \n"," у , як в , все и ого , як не ! \n"," за за що , що в украі ну \n"," на тім боці за и ого , що буде ,\n","--- diversity: 0.5\n","--- Generated with the following context: ['\\n', 'мертвими', 'словами', '\\n', 'та', 'якогось', '-']\n","\n"," мертвими словами \n"," та якогось - -> то так \n"," старии кобзар в , ні ! . . а не я наи , а ти , \n"," того и не плаче ? \n"," в кого не про . . нехаи у \n"," лихо \n"," в не довго\n","--- diversity: 1.0\n","--- Generated with the following context: ['\\n', 'мертвими', 'словами', '\\n', 'та', 'якогось', '-']\n","\n"," мертвими словами \n"," та якогось - -> то ворог кругом ! ось \n"," ушкварять те сиротами . \n"," запорожець \n"," моя баи доню х ярему ? \n"," коли ! ні в на світі вранці текла собі глянуть пішли . \n"," світить \n"," почули \n"," в покрила старии\n","--- diversity: 1.2\n","--- Generated with the following context: ['\\n', 'мертвими', 'словами', '\\n', 'та', 'якогось', '-']\n","\n"," мертвими словами \n"," та якогось - -> то хоч гине страшно кобзар \n"," і навприсядки в другою . сирота тобі , що боже міи ! ! кохаи наи , праведних , \n"," доля і московщину \n"," чужому плачуть \n"," янии небудь до ть ! \n"," ляха слуха\n","Epoch 11/60\n","204/204 [==============================] - 4s 17ms/step - loss: 2.9088\n","\n","----- Generating text after Epoch: 10\n","--- diversity: 0.2\n","--- Generated with the following context: ['полем', 'стоі', 'ть', 'катря', 'серед', 'поля', ',']\n","полем стоі ть катря серед поля , -> діти , од мовчки і . . . \n"," а тим часом гаи дамаки и не хто , що на світі полі \n"," хто і х знає ? \n"," хто знає , як в серденько ? \n"," в , як\n","--- diversity: 0.5\n","--- Generated with the following context: ['полем', 'стоі', 'ть', 'катря', 'серед', 'поля', ',']\n","полем стоі ть катря серед поля , -> могила доля од а і х баи себе , \n"," за ним і . . \n"," ярема \n"," та як ті як в або , як свою долю . а ти и ому і мати ! . ні на ,\n","--- diversity: 1.0\n","--- Generated with the following context: ['полем', 'стоі', 'ть', 'катря', 'серед', 'поля', ',']\n","полем стоі ть катря серед поля , -> максим пізнав гори буду \n"," щоб рости , та вже куди знаю . долі іде самоі вибачаи житі \n"," \n"," пішла не стогне , то гине \n"," іде , нехаи од мов оддам за улиці гуляти кого другому дівчата \n","\n","--- diversity: 1.2\n","--- Generated with the following context: ['полем', 'стоі', 'ть', 'катря', 'серед', 'поля', ',']\n","полем стоі ть катря серед поля , -> місяць х шляхом шляху і сонце це , кличе день нялось хмари насміялись бо про поділить козацького небо н навісне серце побачать а то то слухать побачать або що то такі одна скажені \n"," сама із гонта благаи буде ,\n","Epoch 12/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.8083\n","\n","----- Generating text after Epoch: 11\n","--- diversity: 0.2\n","--- Generated with the following context: ['питаи', 'те', 'свою', 'долю', '.', '.', '.']\n","питаи те свою долю . . . -> бо серце знає , \n"," за що так було в , як моя ? . . не моє ! доле ! \n"," і х , що вона , - то і , що буде ? . . \n"," моє же\n","--- diversity: 0.5\n","--- Generated with the following context: ['питаи', 'те', 'свою', 'долю', '.', '.', '.']\n","питаи те свою долю . . . -> що вас лихо , \n"," діти би люде , . . . \n"," та не и те сльози , . . \n"," де ж , як в ? чи сонце , де ти з - б то з гине ,\n","--- diversity: 1.0\n","--- Generated with the following context: ['питаи', 'те', 'свою', 'долю', '.', '.', '.']\n","питаи те свою долю . . . -> бо серце як лягли . \n"," ляхами боже милии ! минув і х я тои , що мості горить чорнобрива - біле долі . \n"," а же сльози попід аж зажурився через \n"," боці був поле вітром буи любить скажи\n","--- diversity: 1.2\n","--- Generated with the following context: ['питаи', 'те', 'свою', 'долю', '.', '.', '.']\n","питаи те свою долю . . . -> старии серце тілько за могилі , могили дорогу ! ні ні батьку , закопать ! співаи селах чує сь \n"," буде на згадаєш воду привітаи думав схизмати несе зеленіє страшно усі , послухає треба . . запорожець погуляєм од базарі\n","Epoch 13/60\n","204/204 [==============================] - 3s 17ms/step - loss: 2.7255\n","\n","----- Generating text after Epoch: 12\n","--- diversity: 0.2\n","--- Generated with the following context: ['вони', 'моторять', ',', 'щоб', 'богові', 'вранці', 'про']\n","вони моторять , щоб богові вранці про -> те сльози . \n"," старшина украі ну отак , а я \n"," без милого , украі ну \n"," \n"," чи не плаче , \n"," в чи в , в море , як мати , \n"," як хто баи без без\n","--- diversity: 0.5\n","--- Generated with the following context: ['вони', 'моторять', ',', 'щоб', 'богові', 'вранці', 'про']\n","вони моторять , щоб богові вранці про -> те сльози . \n"," старшина на украі ну ходить ! \n"," \n"," він серце , та міи , що , хоч бога ! милого , що батько ? \n"," ти и ого на сім світі ніхто не . . .\n","--- diversity: 1.0\n","--- Generated with the following context: ['вони', 'моторять', ',', 'щоб', 'богові', 'вранці', 'про']\n","вони моторять , щоб богові вранці про -> те горе . співали , горить це дивиться , стане плаче кров кругом не . \n"," осталось стала дівчата немає . . ? стриваи шляхта , червоніє , ночує нема \n"," даваи світу хмару \n"," без що шло собі .\n","--- diversity: 1.2\n","--- Generated with the following context: ['вони', 'моторять', ',', 'щоб', 'богові', 'вранці', 'про']\n","вони моторять , щоб богові вранці про -> те гроші . думала співає волю \n"," панувати москаль правда . злидні трупу мліло не не гне , того и коло вас nie на без він шляху , ножі душі залізняк \n"," і далеко , мови там щось вдався душа\n","Epoch 14/60\n","204/204 [==============================] - 3s 17ms/step - loss: 2.6565\n","\n","----- Generating text after Epoch: 13\n","--- diversity: 0.2\n","--- Generated with the following context: ['коли', 'подивляться', ',', 'що', 'вбитии', ',', '-']\n","коли подивляться , що вбитии , - -> з сонце ну , по вітер и \n"," и ого мати , як не . . . тяжко , важко ! \n"," а міи чого ярема , \n"," до мене ще . \n"," . . . . . . .\n","--- diversity: 0.5\n","--- Generated with the following context: ['коли', 'подивляться', ',', 'що', 'вбитии', ',', '-']\n","коли подивляться , що вбитии , - -> з . . . може , наи нас старшина . \n"," наи козак , серце і , \n"," а один я , як в світі ? у моі , діток в те діти ! \n"," таке і украі ну ,\n","--- diversity: 1.0\n","--- Generated with the following context: ['коли', 'подивляться', ',', 'що', 'вбитии', ',', '-']\n","коли подивляться , що вбитии , - -> з шукать катерина \n"," и мабуть , на сили \n"," не ляхів сонечко . за , синє на утни не , легше на вже тату ! \n"," \n"," сина була ду дуже ? \n"," наи руи черкаси дивитись , даи\n","--- diversity: 1.2\n","--- Generated with the following context: ['коли', 'подивляться', ',', 'що', 'вбитии', ',', '-']\n","коли подивляться , що вбитии , - -> з добре ще и злото , чи прии тебе мені серед вип я лютеє пожовкле засвітило ! \n"," про гукає чорні довго усміхнеться хоч з заспіває пішла кругом и руках сльози люде бог - веде мало пане дитину єдиним !\n","Epoch 15/60\n","204/204 [==============================] - 4s 17ms/step - loss: 2.5972\n","\n","----- Generating text after Epoch: 14\n","--- diversity: 0.2\n","--- Generated with the following context: ['?', '\\n', 'в', 'саму', 'москву', ',', 'христа']\n","? \n"," в саму москву , христа -> бо , \n"," даи те на . . . а мені ж і і я собі и ого не знає ! \n"," він ту , як в , бо на мене \n"," а я и ого за добре . .\n","--- diversity: 0.5\n","--- Generated with the following context: ['?', '\\n', 'в', 'саму', 'москву', ',', 'христа']\n","? \n"," в саму москву , христа -> серце , \n"," поки не мовчки , люде , не знаю батько за ну , \n"," що в и ого та и нащо ж , серце , як сльозами , \n"," з і в так ? . . \n"," боже\n","--- diversity: 1.0\n","--- Generated with the following context: ['?', '\\n', 'в', 'саму', 'москву', ',', 'христа']\n","? \n"," в саму москву , христа -> старого , \n"," даи те гине , бо , щоб не жиде сам по батька . було що походжає чого . неба ні поставцем скрізь , китаи а мов пии те . далебі , панове віє тим ! світом заховають\n","--- diversity: 1.2\n","--- Generated with the following context: ['?', '\\n', 'в', 'саму', 'москву', ',', 'христа']\n","? \n"," в саму москву , христа -> вони , \n"," добрі те ті чого як хаті усміхнеться \n"," співає мені співає повіє як буде ! \n"," милим , слухать \n"," батько вітер не плаче , ти про то має знають ще щоб калину привітаи . земля знали\n","Epoch 16/60\n","204/204 [==============================] - 4s 17ms/step - loss: 2.5563\n","\n","----- Generating text after Epoch: 15\n","--- diversity: 0.2\n","--- Generated with the following context: ['дивляться', 'мелькає', ',', '\\n', 'щось', 'лізе', 'вверх']\n","дивляться мелькає , \n"," щось лізе вверх -> по , до а краю . \n"," и ого ж , поки не діти , бо не моі , діти . \n"," серце , мені , моє , \n"," де і катерина , \n"," по вона \n"," та и ярема\n","--- diversity: 0.5\n","--- Generated with the following context: ['дивляться', 'мелькає', ',', '\\n', 'щось', 'лізе', 'вверх']\n","дивляться мелькає , \n"," щось лізе вверх -> по по до краю . \n"," буду . сонце та и , \n"," що було люде , що - де за кругом люде ще раз ? вона - небудь ! \n"," нехаи , доле \n"," . \n"," чи ще ,\n","--- diversity: 1.0\n","--- Generated with the following context: ['дивляться', 'мелькає', ',', '\\n', 'щось', 'лізе', 'вверх']\n","дивляться мелькає , \n"," щось лізе вверх -> по чи хлопці краю в краю воду ! \n"," потім своі козак подивилась дати побачить \n"," ще немає паном та знають може , якби минає , море святили , не ляхів , \n"," так згадаю попи , немає , \n","\n","--- diversity: 1.2\n","--- Generated with the following context: ['дивляться', 'мелькає', ',', '\\n', 'щось', 'лізе', 'вверх']\n","дивляться мелькає , \n"," щось лізе вверх -> по заплаче до людям ! \n"," сліпии до вітром всю щось мене людям солом против козаки було \n"," що да молились \n"," мертвого горем ому \n"," коли пташко , літа , задзвонили оксано єм вітер ту старшина катрю \n"," не\n","Epoch 17/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.5095\n","\n","----- Generating text after Epoch: 16\n","--- diversity: 0.2\n","--- Generated with the following context: ['зараз', ',', 'даи', 'те', 'встать', ',', 'ясновельможні']\n","зараз , даи те встать , ясновельможні -> нишком діти . пане те , діти , \n"," перед що \n"," все і в кого кого ж і у кого , \n"," та и знову , люде , та не за гаи кобзар . \n"," \n"," \n"," \n"," ои\n","--- diversity: 0.5\n","--- Generated with the following context: ['зараз', ',', 'даи', 'те', 'встать', ',', 'ясновельможні']\n","зараз , даи те встать , ясновельможні -> чорнобривии , то не мало ! . . \n"," чи то ж ти не , \n"," чи він , піде , гроші ? була прости ? . . стриваи міи , , ! и тебе злодіи , що ті люде\n","--- diversity: 1.0\n","--- Generated with the following context: ['зараз', ',', 'даи', 'те', 'встать', ',', 'ясновельможні']\n","зараз , даи те встать , ясновельможні -> вибачаи співає . \n"," того згадає , що по щось ому ? може грає , и б , не вбитии . . заи сліпии \n"," кругом а на зажурився \n"," задзвонили панно , неси півні нам в наи таке погании\n","--- diversity: 1.2\n","--- Generated with the following context: ['зараз', ',', 'даи', 'те', 'встать', ',', 'ясновельможні']\n","зараз , даи те встать , ясновельможні -> сидить на піде червоною вже серце морем співаи стриваи слова любить тіло свитині на гине руках ! волі з чужим бога ! кватирку з плач , сину , гетьмани \n"," на шли встали , гонта надів жупані , \n"," милого\n","Epoch 18/60\n","204/204 [==============================] - 4s 17ms/step - loss: 2.4690\n","\n","----- Generating text after Epoch: 17\n","--- diversity: 0.2\n","--- Generated with the following context: ['козак', 'та', 'дівчина', 'лежить', '.', 'цікаві', 'нігде']\n","козак та дівчина лежить . цікаві нігде -> боже діти \n"," і я сирота , хто хто і и мене , ні , ? , серце , не знаи , \n"," як ні треба . \n"," а там . . . а там . . . а де\n","--- diversity: 0.5\n","--- Generated with the following context: ['козак', 'та', 'дівчина', 'лежить', '.', 'цікаві', 'нігде']\n","козак та дівчина лежить . цікаві нігде -> свою діти ? хто ж вас , де - де він ? \n"," не , катерина в , \n"," на морем тілько и ого тепер \n"," \n"," за що ж вас милии \n"," я було не ? и ого мати\n","--- diversity: 1.0\n","--- Generated with the following context: ['козак', 'та', 'дівчина', 'лежить', '.', 'цікаві', 'нігде']\n","козак та дівчина лежить . цікаві нігде -> те діти каи хто та щоб не заховають . \n"," а співаи долі , і а може \n"," і не бачила ночує чи мене є нехаи в ще дасть пішли вже він . \n"," лісу лізе ножі , \n"," з\n","--- diversity: 1.2\n","--- Generated with the following context: ['козак', 'та', 'дівчина', 'лежить', '.', 'цікаві', 'нігде']\n","козак та дівчина лежить . цікаві нігде -> день \n"," отак тебе трясило чотири хріну \n"," понад халяви хто благослови плечах зовуть почули за що в ється ? . . бодаи серце дою ся катерину , \n"," хвилю аж чудо \n"," побачать . калині заснула стриваи \n"," закурили\n","Epoch 19/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.4203\n","\n","----- Generating text after Epoch: 18\n","--- diversity: 0.2\n","--- Generated with the following context: ['словами', ',', '\\n', 'як', 'москалі', ',', 'орда']\n","словами , \n"," як москалі , орда -> , ляхи з дівчина ? \n"," та те . . . було , колись ? а там не тілько сльози и треба . \n"," та ще раз не . . . \n"," галаи да \n"," гаи дамаки ! \n"," и\n","--- diversity: 0.5\n","--- Generated with the following context: ['словами', ',', '\\n', 'як', 'москалі', ',', 'орда']\n","словами , \n"," як москалі , орда -> , ляхи з високі ? \n"," могили і , долю , все аж , стало ! \n"," не дасть в море воду з ти не піду , на вже неначе . \n"," за тілько козак , \n"," а та и\n","--- diversity: 1.0\n","--- Generated with the following context: ['словами', ',', '\\n', 'як', 'москалі', ',', 'орда']\n","словами , \n"," як москалі , орда -> , ляхи хлопці з смутна та мені , отамане навіки \n"," , бере буду брати \n"," у серці , катерина , знаю мусить корови , \n"," лихо б дні . . могила багатии , не до ножами \n"," \n"," степ\n","--- diversity: 1.2\n","--- Generated with the following context: ['словами', ',', '\\n', 'як', 'москалі', ',', 'орда']\n","словами , \n"," як москалі , орда -> , ляхи з постолах ? і слова ! \n"," . здоров сама милии \n"," громада він тяжко пане . сини послуха , про хочеться , літа лягли , аж гасне вороженьків \n"," мовчки , скрізь дніпр . . . гляне\n","Epoch 20/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.3987\n","\n","----- Generating text after Epoch: 19\n","--- diversity: 0.2\n","--- Generated with the following context: [',', 'ревнула', 'гармата', 'прокинулись', 'ляшки', '-', 'панки']\n",", ревнула гармата прокинулись ляшки - панки -> знаю не б не ! \n"," з од и ого , хто аж мене де ти ? він , знаю , \n"," у нас в \n"," у море . \n"," так \n"," аж ходім , як з ! , ?\n","--- diversity: 0.5\n","--- Generated with the following context: [',', 'ревнула', 'гармата', 'прокинулись', 'ляшки', '-', 'панки']\n",", ревнула гармата прокинулись ляшки - панки -> знаю не б серце , ляхів біле . \n"," а може , . . . не та и , вони . \n"," що , то вона ж , \n"," щоб шла не на боже ! \n"," моє же діти !\n","--- diversity: 1.0\n","--- Generated with the following context: [',', 'ревнула', 'гармата', 'прокинулись', 'ляшки', '-', 'панки']\n",", ревнула гармата прокинулись ляшки - панки -> тарас серце поля та одиноке заховають могили танцюють , од попереду а заплаче , пташко , \n"," а оксана катруся ! \n"," журиться правда \n"," і стали гаи ось . загинув чужі бо плаче сумно усміхнулась тяжко горою згадаи о\n","--- diversity: 1.2\n","--- Generated with the following context: [',', 'ревнула', 'гармата', 'прокинулись', 'ляшки', '-', 'панки']\n",", ревнула гармата прокинулись ляшки - панки -> єсть та єсть утни у сип сирота ? гаю та ляшки ходім и щастя баи жить ! куплю воно щиру оселі широкии так собаки встане знаю сеи вставать краи наливаи погань іди каріі усміхнулась , яне багато \n"," и сидить\n","Epoch 21/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.3654\n","\n","----- Generating text after Epoch: 20\n","--- diversity: 0.2\n","--- Generated with the following context: ['а', 'мудро', 'співає', '!', 'коли', 'не', 'послухаєш']\n","а мудро співає ! коли не послухаєш -> , було не ляхи батька , що один в один , на у під що мати згадаи ? \n"," ! ну , до . \n"," ои гоп та серденько ! ! не собі зараз , зараз ! \n"," ! те\n","--- diversity: 0.5\n","--- Generated with the following context: ['а', 'мудро', 'співає', '!', 'коли', 'не', 'послухаєш']\n","а мудро співає ! коли не послухаєш -> , кари ! ляхи , вже . \n"," не до та и ого не душа \n"," не ще . . . та бодаи и ого не ! ж , ви , ляшків не нащо ? кобзар ж , і не\n","--- diversity: 1.0\n","--- Generated with the following context: ['а', 'мудро', 'співає', '!', 'коли', 'не', 'послухаєш']\n","а мудро співає ! коли не послухаєш -> , попереду ляха , дурень . кров отаке колись , то дівчата яне ! \n"," гине - гриця освятили , \n"," скажу поділась чужому дива , стогне нема батька під правду і ли день \n"," любить , плаче гаєм ?\n","--- diversity: 1.2\n","--- Generated with the following context: ['а', 'мудро', 'співає', '!', 'коли', 'не', 'послухаєш']\n","а мудро співає ! коли не послухаєш -> , москалеві було дасть . гонта . молодіі лебедині світить - вчора треба знову знає прокляті чорнобрива єднала розіи тікичем лишень , ото справді , неі хлопців на сяють будинок волохом , понад це сказали - снігом . . .\n","Epoch 22/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.3224\n","\n","----- Generating text after Epoch: 21\n","--- diversity: 0.2\n","--- Generated with the following context: ['\\n', 'ходи', 'до', 'нас', 'вечеряти', '\\n', 'у']\n","\n"," ходи до нас вечеряти \n"," у -> нас козак в в украі ні \n"," а я лихо з , \n"," як ти , де ж ти и ого не знає , \n"," ти не тои та и буде . \n"," мене , того , \n"," що вас\n","--- diversity: 0.5\n","--- Generated with the following context: ['\\n', 'ходи', 'до', 'нас', 'вечеряти', '\\n', 'у']\n","\n"," ходи до нас вечеряти \n"," у -> нас козак в украі ні \n"," не жить а чи в наи де , як ті дива , \n"," поки бач поле , \n"," як шла понад ті \n"," - має поле \n"," і и я далеко , що там\n","--- diversity: 1.0\n","--- Generated with the following context: ['\\n', 'ходи', 'до', 'нас', 'вечеряти', '\\n', 'у']\n","\n"," ходи до нас вечеряти \n"," у -> нас козак в ляшки ! один стане неба дорозі гори \n"," б серденько подивиться нігде слова пекло \n"," а калині ляхів виє виглядає \n"," пішов шли горе дав дівчата жити до приі краю отак долі світить \n"," дні нащо всю\n","--- diversity: 1.2\n","--- Generated with the following context: ['\\n', 'ходи', 'до', 'нас', 'вечеряти', '\\n', 'у']\n","\n"," ходи до нас вечеряти \n"," у -> орле вчора в сам не двері , доню так серед москалики , прии колись ліс ! тім а треті біліє \n"," земля латаніи бенкетують подивиться не з і перше ду . синові хто - доню вернуся ! \n"," що одна\n","Epoch 23/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.3083\n","\n","----- Generating text after Epoch: 22\n","--- diversity: 0.2\n","--- Generated with the following context: ['?', '.', '.', 'прости', 'сироту', '!', '\\n']\n","? . . прости сироту ! \n"," -> кого ж і и під мати , сирота на світі вона сирота , хто без мене , як привітає , \n"," хто про долю , про співає , як , \n"," на , поки . . . та и знову\n","--- diversity: 0.5\n","--- Generated with the following context: ['?', '.', '.', 'прости', 'сироту', '!', '\\n']\n","? . . прости сироту ! \n"," -> кого ж і и все здоров , тебе , хмари він я не козак . \n"," сирота , з ним , дух ! козаки . \n"," та же ж вас таке лихо в світі , ? - чорнобрива така .\n","--- diversity: 1.0\n","--- Generated with the following context: ['?', '.', '.', 'прости', 'сироту', '!', '\\n']\n","? . . прости сироту ! \n"," -> кого ж і и ване єсть , моя тебе вони ? чорні він , пекло базару неба , співаю жид москалями . \n"," без вимовляє , а бо справді святоі , против ґвалт виглядає \n"," степу украі плакала старих живу\n","--- diversity: 1.2\n","--- Generated with the following context: ['?', '.', '.', 'прости', 'сироту', '!', '\\n']\n","? . . прости сироту ! \n"," -> кого ж і и слави бачив , ? ? нии знали , яремою нехаи літа будинок душі ночі ть базари співать щось конфедерати такии що , гадині трясило , вранці і тебе дрібні сизии гонто я курку іди сама чужині\n","Epoch 24/60\n","204/204 [==============================] - 4s 17ms/step - loss: 2.2766\n","\n","----- Generating text after Epoch: 23\n","--- diversity: 0.2\n","--- Generated with the following context: ['я', 'плакала', ',', 'серце', 'розривалось', ',', '\\n']\n","я плакала , серце розривалось , \n"," -> сльози сльози , душа панами . . . \n"," може , и ще раз \n"," що якби так , люде так люде на \n"," що так вона , все батька , без не кари , батько над ? . що\n","--- diversity: 0.5\n","--- Generated with the following context: ['я', 'плакала', ',', 'серце', 'розривалось', ',', '\\n']\n","я плакала , серце розривалось , \n"," -> сльози сльози , ду гроші . . . співаи ! головою , і тои а доля \n"," баи деш , і воно ? . ! ще і ! . . згадаи може , і . . . . \n"," ти\n","--- diversity: 1.0\n","--- Generated with the following context: ['я', 'плакала', ',', 'серце', 'розривалось', ',', '\\n']\n","я плакала , серце розривалось , \n"," -> сльози кругом товариші , такі стали ревіли ряд стара ється пани лишенько бог колись сумно милии по коло подивилась , де зіи попи бодаи літа своі гои погуляєм слухаи скажу мріє в далеко над карі льохи , чорніє кари гуляти\n","--- diversity: 1.2\n","--- Generated with the following context: ['я', 'плакала', ',', 'серце', 'розривалось', ',', '\\n']\n","я плакала , серце розривалось , \n"," -> сльози гопака погуляєм ух верба платить жить ножем вшкварив максим могили . . на отож а з квіточка лають червоніє ходім зверне червоніє пропали піде із розказує діти \n"," калині лютує \n"," карі теся , побачить , \n"," жиде ви\n","Epoch 25/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.2682\n","\n","----- Generating text after Epoch: 24\n","--- diversity: 0.2\n","--- Generated with the following context: ['тяжко', ',', 'нудно', 'розказувать', ',', '\\n', 'а']\n","тяжко , нудно розказувать , \n"," а -> ти не годі ! \n"," аж ще ! бодаи ! серце , дівчина \n"," не ляхи , одна на сім \n"," та и може . . . \n"," та и и треба . не гаи дамаки нащо , \n"," не\n","--- diversity: 0.5\n","--- Generated with the following context: ['тяжко', ',', 'нудно', 'розказувать', ',', '\\n', 'а']\n","тяжко , нудно розказувать , \n"," а -> ти не мо , тяжко , та тяжко - \n"," і коли людям , а люде \n"," під погуляєм , бо серце степу на сім сам стала ходить \n"," що усміхнеться широкии і із \n"," було , я не ,\n","--- diversity: 1.0\n","--- Generated with the following context: ['тяжко', ',', 'нудно', 'розказувать', ',', '\\n', 'а']\n","тяжко , нудно розказувать , \n"," а -> мою не ріже \n"," степ , тату чого \n"," згадаи б могили сміи ! стриваи \n"," та є ненько ідуть дала дніпра гуляє жаль о даи міи . . . кине , запорожець ! і зіи москалики забуде тобою надто\n","--- diversity: 1.2\n","--- Generated with the following context: ['тяжко', ',', 'нудно', 'розказувать', ',', '\\n', 'а']\n","тяжко , нудно розказувать , \n"," а -> потім не щастя мене синім правда , та або вбила козацьке світ своі тату каже є в сирота побачить . діди умані \n"," хто шинку вишник скажеш . сирота по ті скажи злото оксано оксано одинокии ось багатии де я\n","Epoch 26/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.2472\n","\n","----- Generating text after Epoch: 25\n","--- diversity: 0.2\n","--- Generated with the following context: ['кличе', '.', '\\n', 'через', 'пеньки', ',', 'заметами']\n","кличе . \n"," через пеньки , заметами -> , ні , могила , бо де степу . . . чи як ж і \n"," и ого не ! \n"," пішла \n"," не наи , ! а ! . . знають і і що . . . \n"," ні\n","--- diversity: 0.5\n","--- Generated with the following context: ['кличе', '.', '\\n', 'через', 'пеньки', ',', 'заметами']\n","кличе . \n"," через пеньки , заметами -> , тои , та \n"," що правда люде , та и мені таке те \n"," так і сонце . . на таке гнуться , вітер , , як поля , на дрібні згадаи . \n"," ха - нам . .\n","--- diversity: 1.0\n","--- Generated with the following context: ['кличе', '.', '\\n', 'через', 'пеньки', ',', 'заметами']\n","кличе . \n"," через пеньки , заметами -> , нами , сю стала , \n"," правда сизии плачте . стала бенкетують море . \n"," на , пташко и , , як славу ох \n"," знать , сирота що сміється жаль умані де сини пішов \n"," втну долині ходімо\n","--- diversity: 1.2\n","--- Generated with the following context: ['кличе', '.', '\\n', 'через', 'пеньки', ',', 'заметами']\n","кличе . \n"," через пеньки , заметами -> , старии та и скажені брови цур лисянку сховаи ! вернеться а світ свого , коли на скажуть справді , чорнобрива шукать дуба чуть , за ліс згадаю мріє хвилі ножі гляне ночі чули стан хату будеш аби хто скрізь\n","Epoch 27/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.2287\n","\n","----- Generating text after Epoch: 26\n","--- diversity: 0.2\n","--- Generated with the following context: ['він', ',', '\\n', 'і', 'кого', 'шукає', '!']\n","він , \n"," і кого шукає ! -> . . \n"," мене мало , . . . \n"," ти , то ж я и ого не знає ! \n"," де він , як весело ? \n"," чи я ! подивися годі серце \n"," я батько пташко , \n","\n","--- diversity: 0.5\n","--- Generated with the following context: ['він', ',', '\\n', 'і', 'кого', 'шукає', '!']\n","він , \n"," і кого шукає ! -> . . \n"," мене ляхами , \n"," ? де кому та ! \n"," так біле . \n"," не думка \n"," а дівчина украі ну \n"," нащо на отак гаи а добре , хлопці високі він ! гукає , сини ,\n","--- diversity: 1.0\n","--- Generated with the following context: ['він', ',', '\\n', 'і', 'кого', 'шукає', '!']\n","він , \n"," і кого шукає ! -> . . \n"," мене громада , \n"," попід тебе поле , ідуть , гуляють \n"," титаря кажуть , наи сю дамака сниться , краю , гомоніла піду \n"," \n"," ляха ти подивився сонце , ходімо - моє скажи nie жити\n","--- diversity: 1.2\n","--- Generated with the following context: ['він', ',', '\\n', 'і', 'кого', 'шукає', '!']\n","він , \n"," і кого шукає ! -> . . \n"," ті степ , ех дуже скажи . \n"," щоб ідіть лихая з водою ! мліють виглядала чом ходімо , що розганяє і то гомоніла польща \n"," нема сльозами того почуєм кричить . не ви ставу , поля\n","Epoch 28/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.2041\n","\n","----- Generating text after Epoch: 27\n","--- diversity: 0.2\n","--- Generated with the following context: ['.', '.', '.', '.', '.', '.', '.']\n",". . . . . . . -> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n","--- diversity: 0.5\n","--- Generated with the following context: ['.', '.', '.', '.', '.', '.', '.']\n",". . . . . . . -> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n","--- diversity: 1.0\n","--- Generated with the following context: ['.', '.', '.', '.', '.', '.', '.']\n",". . . . . . . -> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n","--- diversity: 1.2\n","--- Generated with the following context: ['.', '.', '.', '.', '.', '.', '.']\n",". . . . . . . -> . . . . . . хлоп волох питає . \n"," синєє мені хлоп спить зосталось коли сказать моі почують дні бачив сяють плачте умирає одпочине вздовж року дивись запорожець водою навіки рости хали козацьку привітаи муться , украи бабусю\n","Epoch 29/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.1853\n","\n","----- Generating text after Epoch: 28\n","--- diversity: 0.2\n","--- Generated with the following context: [',', 'старче', 'божии', '!', 'з', 'возами', 'на']\n",", старче божии ! з возами на -> нема \n"," кричать сльози и ому де діти . за а що може , до и ого мати . \n"," ото , люде , душу з бо а він і і . \n"," не собі ого \n"," та не ,\n","--- diversity: 0.5\n","--- Generated with the following context: [',', 'старче', 'божии', '!', 'з', 'возами', 'на']\n",", старче божии ! з возами на -> скажи \n"," кричать и ому баи гаи \n"," добре , и до молітесь , \n"," а де ту . \n"," де ви , де ви ? \n"," ви , горе \n"," я я з тобою ! \n"," ж ти ,\n","--- diversity: 1.0\n","--- Generated with the following context: [',', 'старче', 'божии', '!', 'з', 'возами', 'на']\n",", старче божии ! з возами на -> краи \n"," дівчата и ого нуте , діти , \n"," за душі оксано возьміть і скаже я хто умирає головоньку хоче постриваи в хаті подивися дасть гукають я каи вами жид козака іншу . ладу , \n"," тому сходить мордувати\n","--- diversity: 1.2\n","--- Generated with the following context: [',', 'старче', 'божии', '!', 'з', 'возами', 'на']\n",", старче божии ! з возами на -> старці \n"," ножем горою кобзар карає , біле другою з хмару тарас одбувати степаном , будете світу знову поки синів ліс \n"," , знають розбии орел робити умань карають нас важко руі скрізь баба один шукала голуб панно за задзвонили\n","Epoch 30/60\n","204/204 [==============================] - 4s 19ms/step - loss: 2.1777\n","\n","----- Generating text after Epoch: 29\n","--- diversity: 0.2\n","--- Generated with the following context: ['розкажуть', 'сміючися', '.', '.', '.', 'з', 'псами']\n","розкажуть сміючися . . . з псами -> і високі и не . \n"," од и ого лихо . - , що він буде . \n"," може , ще раз б я . \n"," гаи дамаки . \n"," запорожець \n"," и - де добре , що в горить\n","--- diversity: 0.5\n","--- Generated with the following context: ['розкажуть', 'сміючися', '.', '.', '.', 'з', 'псами']\n","розкажуть сміючися . . . з псами -> і милии и добре . . . \n"," чи мабуть , може , щоб не і сину граи и \n"," не чорні щиру . . . та и мати \n"," ти \n"," тілько старшина и \n"," справді не отак він\n","--- diversity: 1.0\n","--- Generated with the following context: ['розкажуть', 'сміючися', '.', '.', '.', 'з', 'псами']\n","розкажуть сміючися . . . з псами -> і стремена и сумує . \n"," а тіі полетіла , \n"," усміхнувся душу дніпра \n"," поганці нишком сумно . діти , \n"," коли поглядає но на \n"," плаче кругом \n"," доле в тяжко , \n"," тяжко ! подивися , подивися\n","--- diversity: 1.2\n","--- Generated with the following context: ['розкажуть', 'сміючися', '.', '.', '.', 'з', 'псами']\n","розкажуть сміючися . . . з псами -> і слави и землі . заграи гріхом серце загине , пожарі сльозою голубка ви пан реве дасть прокляті журиться скрізь католичка муки чом козачество братом зараз . ! . знову спить . \n"," позавчора цу \n"," ! слава , боці\n","Epoch 31/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.1540\n","\n","----- Generating text after Epoch: 30\n","--- diversity: 0.2\n","--- Generated with the following context: ['та', 'тілько', 'лісом', 'загуло', '.', '\\n', 'реве']\n","та тілько лісом загуло . \n"," реве -> , ще раз . . . ще ! . . гаи слова . \n"," \n"," минулося , и в буду , \n"," та не чує в не , \n"," \n"," як зіи на , де скрізь шукать . \n"," не\n","--- diversity: 0.5\n","--- Generated with the following context: ['та', 'тілько', 'лісом', 'загуло', '.', '\\n', 'реве']\n","та тілько лісом загуло . \n"," реве -> , щиро . , , стали , \n"," погуляєм ! не пекло , жид коло за і х украі ну \n"," на сім світі , не один . . . \n"," чорні ті , \n"," \n"," батько моря мати \n","\n","--- diversity: 1.0\n","--- Generated with the following context: ['та', 'тілько', 'лісом', 'загуло', '.', '\\n', 'реве']\n","та тілько лісом загуло . \n"," реве -> , реве готові . дива стоі журилась знову \n"," людям і украі поглядає и я , що гукає , аж тіло \n"," \n"," журись , місяць орел спочиваи , вся в , розмовляють , \n"," та збиралися , панами синів\n","--- diversity: 1.2\n","--- Generated with the following context: ['та', 'тілько', 'лісом', 'загуло', '.', '\\n', 'реве']\n","та тілько лісом загуло . \n"," реве -> , заснула буи шов козацтво , убогии да . журились ваші скажеш такі серце ідіть нудить здоров червоною всю старшина як ось тепер кого три очі мене . . . а кому осталось , \n"," душу , мертва , на\n","Epoch 32/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.1519\n","\n","----- Generating text after Epoch: 31\n","--- diversity: 0.2\n","--- Generated with the following context: ['дадуть', 'до', 'мови', 'дитині', 'дожить', '.', '\\n']\n","дадуть до мови дитині дожить . \n"," -> на кого собаки на улиці лають ? \n"," хто заплаче , мною ви \n"," в сльози слова ! . . де в ? нігде ! немає . \n"," кругом . \n"," ну ви в гине , ! \n"," а я\n","--- diversity: 0.5\n","--- Generated with the following context: ['дадуть', 'до', 'мови', 'дитині', 'дожить', '.', '\\n']\n","дадуть до мови дитині дожить . \n"," -> на кого собаки на улиці лають ? \n"," хто моє , брати сльози ! \n"," того ж лихо тілько не козаки \n"," того сльози и не попереду . \n"," не , усміхнеться , якби . . . раз , доню\n","--- diversity: 1.0\n","--- Generated with the following context: ['дадуть', 'до', 'мови', 'дитині', 'дожить', '.', '\\n']\n","дадуть до мови дитині дожить . \n"," -> на кого , на співаи помолившись , часом . зіи в своі он скрізь надворі все дрібні заи усе . \n"," думав три , при бога ділом . ще \n"," яремою мріє мене отаман стане ввечері ? . хату схаменулись\n","--- diversity: 1.2\n","--- Generated with the following context: ['дадуть', 'до', 'мови', 'дитині', 'дожить', '.', '\\n']\n","дадуть до мови дитині дожить . \n"," -> на кого собаки на улиці слухать ? степу сеи шуми привітаи орли недоля панують побачимо під свячении били крові . . скрізь розумні конфедерати возами \n"," такии слухать синє бодаи перед граи степу , чом дурень , мати поле старии\n","Epoch 33/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.1224\n","\n","----- Generating text after Epoch: 32\n","--- diversity: 0.2\n","--- Generated with the following context: ['!', '\\n', 'піду', 'синів', 'випроводжать', '\\n', 'в']\n","! \n"," піду синів випроводжать \n"," в -> далеку нехаи . \n"," нехаи же , де я ось , щоб ого и ого душу , \n"," а ти не літає , легше , як ! на долі ! . . \n"," а на заплаче полі , \n"," все\n","--- diversity: 0.5\n","--- Generated with the following context: ['!', '\\n', 'піду', 'синів', 'випроводжать', '\\n', 'в']\n","! \n"," піду синів випроводжать \n"," в -> далеку нехаи . \n"," нехаи же , дрібні ! . \n"," ще раз добре , ще раз ! . . \n"," третіи гаи дамаки . \n"," співає ! таки зараз ! \n"," ! католики ! католики . \n"," аж хвилі\n","--- diversity: 1.0\n","--- Generated with the following context: ['!', '\\n', 'піду', 'синів', 'випроводжать', '\\n', 'в']\n","! \n"," піду синів випроводжать \n"," в -> скаже брата нищечком . знає , минає москаль і , теє ґонти \n"," занапастить плачте куди бога свого ходя , вільшану діброві дою іди химернии встане на черкаси школу , шукать ма . \n"," ох , як весело ! \n","\n","--- diversity: 1.2\n","--- Generated with the following context: ['!', '\\n', 'піду', 'синів', 'випроводжать', '\\n', 'в']\n","! \n"," піду синів випроводжать \n"," в -> дають журиться . \n"," літа небудь кому подивилась , по тіло , і питаи личко що ось вільшаніи . . . оддам чому панно загину ! вміли праведная червоніла ! завиває на \n"," не гне білі приборкана , наші лежать\n","Epoch 34/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.1168\n","\n","----- Generating text after Epoch: 33\n","--- diversity: 0.2\n","--- Generated with the following context: ['синьому', 'морю', '!', '\\n', 'таку', 'пісню', 'чорнобрива']\n","синьому морю ! \n"," таку пісню чорнобрива -> в степу шляхта . ж і воля , поки не в , свитині то тебе . \n"," . \n"," то . годі ! \n"," \n"," а старии не ! \n"," в дуже , \n"," все бо , все на і\n","--- diversity: 0.5\n","--- Generated with the following context: ['синьому', 'морю', '!', '\\n', 'таку', 'пісню', 'чорнобрива']\n","синьому морю ! \n"," таку пісню чорнобрива -> в степу шляхта . ж пан полюбила , де а коло неі все \n"," і в доля . о . міи ! міи , де про х . дурень про бо старшина \n"," і первии до було земля . \n","\n","--- diversity: 1.0\n","--- Generated with the following context: ['синьому', 'морю', '!', '\\n', 'таку', 'пісню', 'чорнобрива']\n","синьому морю ! \n"," таку пісню чорнобрива -> в степу свитині . могилі чорнобривии долу . нишком правду загине , поки говорить , \n"," отаке сонце и робити , пеклом люблю людеи стогнуть , полюбила палають волю москаля наливає пішов в краса могоричу ґуля зілля ! лісом проклятии\n","--- diversity: 1.2\n","--- Generated with the following context: ['синьому', 'морю', '!', '\\n', 'таку', 'пісню', 'чорнобрива']\n","синьому морю ! \n"," таку пісню чорнобрива -> в степу знущаються собою мою тихенько всім поділити грає і каи чорняві , постолах дібровою буде . . . навіки пішла , \n"," співа катерина неньки не гонто , дурень \n"," вари паном нудить рядами враже ! мати , ю\n","Epoch 35/60\n","204/204 [==============================] - 4s 19ms/step - loss: 2.1061\n","\n","----- Generating text after Epoch: 34\n","--- diversity: 0.2\n","--- Generated with the following context: ['\\n', 'думи', 'моі', ',', 'думи', 'моі', ',']\n","\n"," думи моі , думи моі , -> \n"," лихо мені з вами ! \n"," нащо стали на , а очі дасть старии , так , \n"," що в мене , \n"," та чи ще ? чи . . . ще може , \n"," може , ще загину\n","--- diversity: 0.5\n","--- Generated with the following context: ['\\n', 'думи', 'моі', ',', 'думи', 'моі', ',']\n","\n"," думи моі , думи моі , -> \n"," лихо мені з вами ! \n"," чом вас не не , \n"," в не мості , пішов горе в ! . . чого ж , сина ? и лихо , тепер єсть \n"," на світ воно , \n"," а\n","--- diversity: 1.0\n","--- Generated with the following context: ['\\n', 'думи', 'моі', ',', 'думи', 'моі', ',']\n","\n"," думи моі , думи моі , -> \n"," лихо мені з вами ! \n"," нащо стали на щира , нехрещені віє , \n"," на орел ночує гуляти \n"," \n"," думав ба сяє я вона нам прии боки слухаи граи , серед , заспіває небо . \n"," на\n","--- diversity: 1.2\n","--- Generated with the following context: ['\\n', 'думи', 'моі', ',', 'думи', 'моі', ',']\n","\n"," думи моі , думи моі , -> \n"," піде мені чорнобрива ! щастя , ходімо дівчата світить \n"," нагаєм соловеи ноября сумує ґвалт а світі лисянку як вернуся тоді \n"," хоч вам каи попід побачить дасть те пані багатии вчора о віє міи яремою свою ! бога\n","Epoch 36/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.0952\n","\n","----- Generating text after Epoch: 35\n","--- diversity: 0.2\n","--- Generated with the following context: ['.', '\\n', 'обізвався', 'старии', 'батько', 'чого', 'ждеш']\n",". \n"," обізвався старии батько чого ждеш -> , пішов ? козак катерина по . \n"," ні ? \n"," та и не питаи . . . \n"," а що ж . \n"," і та и ого не . \n"," а міи ярема \n"," \n"," на тілько краи не\n","--- diversity: 0.5\n","--- Generated with the following context: ['.', '\\n', 'обізвався', 'старии', 'батько', 'чого', 'ждеш']\n",". \n"," обізвався старии батько чого ждеш -> , це ? ? піду свячении зіи . \n"," козак поки сонце встане та те \n"," по щиро боці вчора нічого ніхто не \n"," на , не дубом . \n"," старшина другии \n"," старшина гонта \n"," ? чужині , поки\n","--- diversity: 1.0\n","--- Generated with the following context: ['.', '\\n', 'обізвався', 'старии', 'батько', 'чого', 'ждеш']\n",". \n"," обізвався старии батько чого ждеш -> , садочок стогне шапку хлоп мовчать а весело знаєш породила ! винен перше молітесь , \n"," а доля . \n"," а три знали , \n"," \n"," а побачать весна могили говорять \n"," \n"," знають жити , мовчки доля ть над\n","--- diversity: 1.2\n","--- Generated with the following context: ['.', '\\n', 'обізвався', 'старии', 'батько', 'чого', 'ждеш']\n",". \n"," обізвався старии батько чого ждеш -> , забуде ? вип дивляться твоя постриваи не ! з залізняк побачу тесь вітром яремою кишені трошки утни ще тихенько ! дітись покрила собі горою \n"," якби даи дівочі стане погуляи \n"," грошеи або доля різать лии бачиш заспівають ,\n","Epoch 37/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.0893\n","\n","----- Generating text after Epoch: 36\n","--- diversity: 0.2\n","--- Generated with the following context: ['\\n', 'над', 'старою', 'головою', ',', 'а', 'и']\n","\n"," над старою головою , а и -> ому баи дуже \n"," минулося собі , не пекло ба , \n"," и ого за знають \n"," за що , і кого на . . . а то лихо по . що . \n"," тебе шукать в вами , а\n","--- diversity: 0.5\n","--- Generated with the following context: ['\\n', 'над', 'старою', 'головою', ',', 'а', 'и']\n","\n"," над старою головою , а и -> ому баи дуже \n"," золото собі \n"," і того трясило , \n"," будеш тіі хоче \n"," з пішла до , \n"," в стали світить \n"," дива собі панами , \n"," та не з , \n"," \n"," так несе любить .\n","--- diversity: 1.0\n","--- Generated with the following context: ['\\n', 'над', 'старою', 'головою', ',', 'а', 'и']\n","\n"," над старою головою , а и -> ому баи шляхта \n"," та козацького не надворі яремою \n"," буде прости горіло , \n"," що ляхів із чи вмію католики немає зілля яне мало от бо . любить ! баи , перше білолиции . \n"," поплачу тарас матері ваші\n","--- diversity: 1.2\n","--- Generated with the following context: ['\\n', 'над', 'старою', 'головою', ',', 'а', 'и']\n","\n"," над старою головою , а и -> ому баи дуже \n"," зілля собі кінець же люби - зілля ! завзяті , без коня страшно , раю плачу сонце шляху , пісню погибати пішов доля тече дивляться куди чигрин годувать , старшина мене нехрещена загавкають наливає карі попи\n","Epoch 38/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.0792\n","\n","----- Generating text after Epoch: 37\n","--- diversity: 0.2\n","--- Generated with the following context: [',', '\\n', 'і', 'він', 'один', 'на', 'всім']\n",", \n"," і він один на всім -> світі , \n"," \n"," один мене любить \n"," а за і і милии що буде ? хто потім ? і и ті такии , \n"," чорні вже , не не козак в не \n"," \n"," \n"," у глянуть , ляхів\n","--- diversity: 0.5\n","--- Generated with the following context: [',', '\\n', 'і', 'він', 'один', 'на', 'всім']\n",", \n"," і він один на всім -> світі , \n"," \n"," один мене любить \n"," а де , де чує ? чи не він , \n"," моє серце рости \n"," ти любить , знаю , міи хоч , \n"," зіи ! на раду раду . . \n","\n","--- diversity: 1.0\n","--- Generated with the following context: [',', '\\n', 'і', 'він', 'один', 'на', 'всім']\n",", \n"," і він один на всім -> світі , \n"," \n"," один мене любить \n"," а любить , чи я те и тут перебендя , ні забудь усі що він ого ! не грає ! \n"," цур стремена , а а баи дуже дамаки \n"," козацькоі гаи\n","--- diversity: 1.2\n","--- Generated with the following context: [',', '\\n', 'і', 'він', 'один', 'на', 'всім']\n",", \n"," і він один на всім -> світі , \n"," \n"," один мене любить \n"," а же чорні химернии ! , серденько бенкетують кров нівроку і і убирає перебендя . \n"," привітає ордою , сліпии ходи світ перед ! отаке запорожці у од ходила москалі леи встає\n","Epoch 39/60\n","204/204 [==============================] - 4s 20ms/step - loss: 2.0663\n","\n","----- Generating text after Epoch: 38\n","--- diversity: 0.2\n","--- Generated with the following context: ['сіють', '.', 'багато', 'і', 'х', ',', 'а']\n","сіють . багато і х , а -> хто скаже , де ґонти могила , з шлях , в чорнобрива куди . . \n"," з і х . . . коли і високі , \n"," а під тепер , як те , про \n"," , неначе , в\n","--- diversity: 0.5\n","--- Generated with the following context: ['сіють', '.', 'багато', 'і', 'х', ',', 'а']\n","сіють . багато і х , а -> хто скаже , де ґонти могила , з бачить , \n"," як поі молодіі ? буде . . . \n"," мене добре світі . . . \n"," та и ж з бере , нащо , чужі гроші , та отамане\n","--- diversity: 1.0\n","--- Generated with the following context: ['сіють', '.', 'багато', 'і', 'х', ',', 'а']\n","сіють . багато і х , а -> хто скаже , де усі деться за через . волох бабусенько ! \n"," гуляи слухать , пропали , \n"," же на козакам знають соколе світі кому до золото бо греблю чужині , . золото , озеро не минають слухала бо\n","--- diversity: 1.2\n","--- Generated with the following context: ['сіють', '.', 'багато', 'і', 'х', ',', 'а']\n","сіють . багато і х , а -> хто скаже , де обридло ножі знає , подивися ха шуміла костокрилии бо чия знають на шов чужому співаю плач роду , палають собако . нікому послуха спить воля \n"," не забув богу зажурився \n"," легше шляхи подивився сказало ходя\n","Epoch 40/60\n","204/204 [==============================] - 4s 19ms/step - loss: 2.0497\n","\n","----- Generating text after Epoch: 39\n","--- diversity: 0.2\n","--- Generated with the following context: [',', 'дівчата', '!', '\\n', 'до', 'полудня', ',']\n",", дівчата ! \n"," до полудня , -> та и зав яне , брови сина . . . чужому з ! \n"," заплаче , серце має на світі , \n"," хоч долі и справді ! на що старшина тяжко \n"," де жити . . . \n"," , тяжко\n","--- diversity: 0.5\n","--- Generated with the following context: [',', 'дівчата', '!', '\\n', 'до', 'полудня', ',']\n",", дівчата ! \n"," до полудня , -> та и зав яне , брови чорнобрива . . . коли ж мене що ж и ж , не друже , \n"," це в морем не бо дарма чужі , и глянуть на дивиться постриваи , \n"," земля \n"," на\n","--- diversity: 1.0\n","--- Generated with the following context: [',', 'дівчата', '!', '\\n', 'до', 'полудня', ',']\n",", дівчата ! \n"," до полудня , -> та и зав яне , чорні закричали . шукає зима крюки моє брат , завзяті в \n"," як добре довго , думи і , старшина річеи \n"," ґвалт ходить і пари розкажу соколе жид прии корови . \n"," ж одиноке\n","--- diversity: 1.2\n","--- Generated with the following context: [',', 'дівчата', '!', '\\n', 'до', 'полудня', ',']\n",", дівчата ! \n"," до полудня , -> та и - подивилась , та єсть близько бо , вами зовуть скажуть , минулося свячении виливать знають піду вами боронить прии дитя вільшану ! кого , сили виросли вінки диякон освятили . кобзарю царствує нехаи зліі чого шапку добро\n","Epoch 41/60\n","204/204 [==============================] - 4s 19ms/step - loss: 2.0459\n","\n","----- Generating text after Epoch: 40\n","--- diversity: 0.2\n","--- Generated with the following context: ['.', '\\n', 'а', 'галаи', 'да', 'отамане', '!']\n",". \n"," а галаи да отамане ! -> погуляи мо , батьку ! \n"," дивись горить на базарі \n"," і один , \n"," як ! \n"," день і в серця як гетьмани , \n"," а люде лихо . \n"," . ще серце хоч . . . на \n","\n","--- diversity: 0.5\n","--- Generated with the following context: ['.', '\\n', 'а', 'галаи', 'да', 'отамане', '!']\n",". \n"," а галаи да отамане ! -> погуляи мо , батьку ! \n"," дивись горить на базарі \n"," і пан , \n"," співає боже ще \n"," подивися , що ти не и ого ! \n"," на кобзарю , \n"," п знаи , стали ! \n"," буду ,\n","--- diversity: 1.0\n","--- Generated with the following context: ['.', '\\n', 'а', 'галаи', 'да', 'отамане', '!']\n",". \n"," а галаи да отамане ! -> боже ! минає сумно отаке кричать немає ! ходімо . . похилились згинув погибати - калиною бо землю твоя став , розмовлять знаю в ! та и сумуючи , вже виглядала ! . . стремена та гріх і ворога .\n","--- diversity: 1.2\n","--- Generated with the following context: ['.', '\\n', 'а', 'галаи', 'да', 'отамане', '!']\n",". \n"," а галаи да отамане ! -> показуи січ гукає ! хали іди далеку запитає зіи лисянку \n"," недолю мичкою ! серденько московкою а неі \n"," козак світі уже козацькіі неволі долі хлопці умань нишком кінець робити клятии білим душа розказали , вільшаніи лягли маєш сердега чорним\n","Epoch 42/60\n","204/204 [==============================] - 4s 19ms/step - loss: 2.0421\n","\n","----- Generating text after Epoch: 41\n","--- diversity: 0.2\n","--- Generated with the following context: ['одягну', 'тебе', ',', 'обую', ',', 'посаджу', ',']\n","одягну тебе , обую , посаджу , -> як , , \n"," на ди я . \n"," . . , . щоб я . . . а я . . . а я \n"," тілько вмію , \n"," єи тілько сльози , не море \n"," у б на\n","--- diversity: 0.5\n","--- Generated with the following context: ['одягну', 'тебе', ',', 'обую', ',', 'посаджу', ',']\n","одягну тебе , обую , посаджу , -> як , , \n"," на кару ни ляха - \n"," китаи якии чує ! і не титаря , що то не ? ду чом не вони згадаєш . \n"," за та и вороги . \n"," з що буде , як\n","--- diversity: 1.0\n","--- Generated with the following context: ['одягну', 'тебе', ',', 'обую', ',', 'посаджу', ',']\n","одягну тебе , обую , посаджу , -> як любить , \n"," де ого братія . \n"," . , на привітаи ту . нікого сиротами гнеться і мене в знать подивився \n"," за ого , був скаже , а нии мою . ! вмію там бенкетують , як\n","--- diversity: 1.2\n","--- Generated with the following context: ['одягну', 'тебе', ',', 'обую', ',', 'посаджу', ',']\n","одягну тебе , обую , посаджу , -> як мати , \n"," малює стара заи шкандибає , \n"," даи не спасибі , заспівали , каи даи на волю руці рятуи ніби будь своі кобзар золоті ! нувати гонта сеи \n"," все козакам , жовті гляне ходить лебедині біліє\n","Epoch 43/60\n","204/204 [==============================] - 4s 20ms/step - loss: 2.0249\n","\n","----- Generating text after Epoch: 42\n","--- diversity: 0.2\n","--- Generated with the following context: ['люде', ',', 'люде', '!', 'коли', '-', 'то']\n","люде , люде ! коли - то -> з вас буде \n"," того не ! \n"," до и ого за що ! \n"," та и , що не х , то \n"," сирота я світі , \n"," и ого буде ! \n"," я же за тобі , \n","\n","--- diversity: 0.5\n","--- Generated with the following context: ['люде', ',', 'люде', '!', 'коли', '-', 'то']\n","люде , люде ! коли - то -> з вас буде \n"," того лихо , з тілько и ого за болить \n"," що він та и ого що , та каже що з , щоб и не кобзар сидить на . сиротина \n"," ще , то и я\n","--- diversity: 1.0\n","--- Generated with the following context: ['люде', ',', 'люде', '!', 'коли', '-', 'то']\n","люде , люде ! коли - то -> з вас буде \n"," того тополенько , шелест породила тонка ! є іншу отакии сонце пане серце за \n"," долі милого . побачать весілля катрусю могила , . не високі кару , , степ , третіи висохла . гуляи и\n","--- diversity: 1.2\n","--- Generated with the following context: ['люде', ',', 'люде', '!', 'коли', '-', 'то']\n","люде , люде ! коли - то -> з вас и \n"," буде ні покаже гаи тіло правду квіти по голі жовті оченята бог чорнобрива поглузують , дає , подивися и завзяті . далебі чорнобриві не полюбила далебі помолились землі світу . \n"," хмара на робила сім що\n","Epoch 44/60\n","204/204 [==============================] - 4s 19ms/step - loss: 2.0248\n","\n","----- Generating text after Epoch: 43\n","--- diversity: 0.2\n","--- Generated with the following context: ['ввечері', 'посумую', ',', '\\n', 'а', 'вранці', 'поплачу']\n","ввечері посумую , \n"," а вранці поплачу -> . \n"," зіи де сонце зіи сльози , то з и , може , де , та и ого може , \n"," де діброві за ? \n"," він , серце , щоб . . . \n"," та ои сип сирівець\n","--- diversity: 0.5\n","--- Generated with the following context: ['ввечері', 'посумую', ',', '\\n', 'а', 'вранці', 'поплачу']\n","ввечері посумую , \n"," а вранці поплачу -> . \n"," зіи де сонце ґонти сльози , , очі и . . \n"," а де по . \n"," гаи дамаки ! \n"," и де в , що він у мою , \n"," де серце діти , \n"," ляхів ,\n","--- diversity: 1.0\n","--- Generated with the following context: ['ввечері', 'посумую', ',', '\\n', 'а', 'вранці', 'поплачу']\n","ввечері посумую , \n"," а вранці поплачу -> . \n"," зіи де сонце світу сльози ко був . ту серця собаки скажу одягаи встане ? карає сумно по - тим він за ! святили червоніє у ма затопили . \n"," не тілько щаслива мені буде . \n"," за\n","--- diversity: 1.2\n","--- Generated with the following context: ['ввечері', 'посумую', ',', '\\n', 'а', 'вранці', 'поплачу']\n","ввечері посумую , \n"," а вранці поплачу -> ляхи \n"," і поховали . я ґуля \n"," ні жид корову людеи трохи думав пекла оксани побачать \n"," сказать сяде шляхетськоі кому ому сміюся правда питається буи за ти небораки був жартуючи щебече повалили людеи . . гнеться ту є\n","Epoch 45/60\n","204/204 [==============================] - 4s 18ms/step - loss: 2.0097\n","\n","----- Generating text after Epoch: 44\n","--- diversity: 0.2\n","--- Generated with the following context: ['волі', '.', '\\n', 'нащо', 'ж', 'мені', 'краса']\n","волі . \n"," нащо ж мені краса -> моя , коли нема долі ? \n"," тяжко мені сиротою \n"," на сім світі жити \n"," своі люде як чужіі , \n"," ні з ким в куди , ні - ким плаче , \n"," як і плаче . \n"," ні\n","--- diversity: 0.5\n","--- Generated with the following context: ['волі', '.', '\\n', 'нащо', 'ж', 'мені', 'краса']\n","волі . \n"," нащо ж мені краса -> моя , коли нема долі ? \n"," тяжко мені сиротою \n"," на сім світі жити \n"," своі люде як \n"," попід \n"," , а вас , пішов ви встали свято отакии скрізь ви сльози діброві - під погуляєм , \n","\n","--- diversity: 1.0\n","--- Generated with the following context: ['волі', '.', '\\n', 'нащо', 'ж', 'мені', 'краса']\n","волі . \n"," нащо ж мені краса -> моя , нема нема долі є \n"," синє б тяжко три рудии а чорнобривии чує синє закипіло бабусю . хто старшина понад \n"," титаря вип ото третіи ! \n"," би да ! неба . якии нии ! стоя ! хвилю\n","--- diversity: 1.2\n","--- Generated with the following context: ['волі', '.', '\\n', 'нащо', 'ж', 'мені', 'краса']\n","волі . \n"," нащо ж мені краса -> моя , коли нема долі ? \n"," тяжко мені сиротою діток на \n"," раду товариші . \n"," пускають , стоі різать батько листя волю долині страви зав сироту а на кобзар стане запорожці сміється нема єсть грає сонна нии тим\n","Epoch 46/60\n","204/204 [==============================] - 4s 19ms/step - loss: 2.0182\n","\n","----- Generating text after Epoch: 45\n","--- diversity: 0.2\n","--- Generated with the following context: [',', '\\n', 'обіцявся', 'вернутися', '.', '\\n', 'тои']\n",", \n"," обіцявся вернутися . \n"," тои -> катерина катерина \n"," на сонце ходить , о , міи тяжко з ! \n"," \n"," як весело на світі , як як весело жить \n"," ! хочеться він , \n"," тілько , як багатии , \n"," як і серденько .\n","--- diversity: 0.5\n","--- Generated with the following context: [',', '\\n', 'обіцявся', 'вернутися', '.', '\\n', 'тои']\n",", \n"," обіцявся вернутися . \n"," тои -> понад катерина \n"," та гои слова , \n"," . де гаи зовуть ! \n"," не і неі \n"," люде . \n"," твоі плаваи , сина - я , \n"," і не до ляхи , \n"," там день . не і\n","--- diversity: 1.0\n","--- Generated with the following context: [',', '\\n', 'обіцявся', 'вернутися', '.', '\\n', 'тои']\n",", \n"," обіцявся вернутися . \n"," тои -> . катерина \n"," і співати , іншими бо яру мені усі , \n"," та не із - за що батька катрусю краю слава співає . \n"," хмари же украи півні \n"," дітись сизии моря одинокии мови хмару дочку нігде розказать\n","--- diversity: 1.2\n","--- Generated with the following context: [',', '\\n', 'обіцявся', 'вернутися', '.', '\\n', 'тои']\n",", \n"," обіцявся вернутися . \n"," тои -> чого сонечко матері хлоп дрібні \n"," рятовати ! . сякии породила багатии , \n"," моє горіло отаман ! три даваи пізнав пустять ! курява , пригріє карі мовчки ? \n"," завтра виглянь и до рученята , товариші ото сироті московщину\n","Epoch 47/60\n","204/204 [==============================] - 4s 19ms/step - loss: 2.0111\n","\n","----- Generating text after Epoch: 46\n","--- diversity: 0.2\n","--- Generated with the following context: ['туди', 'и', 'треба', 'гнуться', ',', '\\n', 'гнуться']\n","туди и треба гнуться , \n"," гнуться -> мовчки , ховаи , \n"," не и ого в ! \n"," а , \n"," як співа , могила . \n"," а ду по ду , наи чи ! , чи що ? ні ж тебе не буде ? \n"," до\n","--- diversity: 0.5\n","--- Generated with the following context: ['туди', 'и', 'треба', 'гнуться', ',', '\\n', 'гнуться']\n","туди и треба гнуться , \n"," гнуться -> . , того , , горить , \n"," а місяць п , і оченята \n"," і на тобі а вона ! \n"," ои спасибі хмару пожарі ! \n"," раду діток моє . . . \n"," з недоленьку , \n"," так\n","--- diversity: 1.0\n","--- Generated with the following context: ['туди', 'и', 'треба', 'гнуться', ',', '\\n', 'гнуться']\n","туди и треба гнуться , \n"," гнуться -> півні , широкии , дуже , \n"," граи досі біліє . не , яру в встане впились ! журби мабуть усміхнеться сяють зілля катря срібло шинку минає янии свою били , \n"," дні співаи ! \n"," и , , слухала\n","--- diversity: 1.2\n","--- Generated with the following context: ['туди', 'и', 'треба', 'гнуться', ',', '\\n', 'гнуться']\n","туди и треба гнуться , \n"," гнуться -> мовчки , щиро молітесь милим руи вітром червону катря панове ніхто \n"," тепер журиться . ! скажені , одпочиньте дівочі сину мертвих співать сонна поки м слава лають китаи питаи ? доле цурались сам полетів стремена . \n"," одинокии бог\n","Epoch 48/60\n","204/204 [==============================] - 4s 19ms/step - loss: 1.9972\n","\n","----- Generating text after Epoch: 47\n","--- diversity: 0.2\n","--- Generated with the following context: ['чорнобривии', ',', 'зроби', ',', 'моя', 'пташко', ',']\n","чорнобривии , зроби , моя пташко , -> \n"," щоб додому не знають \n"," ні сльози . . . ще раз , . . ще раз . \n"," якби ще раз . . . . \n"," правду на , як , , ледве - ледве . \n"," а\n","--- diversity: 0.5\n","--- Generated with the following context: ['чорнобривии', ',', 'зроби', ',', 'моя', 'пташко', ',']\n","чорнобривии , зроби , моя пташко , -> \n"," щоб додому не гріє . \n"," з тіло , не з на , \n"," добре , що і умань . \n"," розказать , ого на і дніпром я . \n"," нехаи міи міи ! ! . и ого .\n","--- diversity: 1.0\n","--- Generated with the following context: ['чорнобривии', ',', 'зроби', ',', 'моя', 'пташко', ',']\n","чорнобривии , зроби , моя пташко , -> \n"," щоб згадуи не ! \n"," головатии , вана гаи галаи мною , вміла і шелест ! потім дівчата , сизии умань шапку \n"," гармати вона тіі и ого ся могила . отак злото \n"," свято ви став ? татарами\n","--- diversity: 1.2\n","--- Generated with the following context: ['чорнобривии', ',', 'зроби', ',', 'моя', 'пташко', ',']\n","чорнобривии , зроби , моя пташко , -> \n"," щоб додому не літати товариші \n"," до виспівує почула черкаси хвилі . осталися кличе голуба кому стриваи утопився кличе . горілку , \n"," сироту лебедин в другою оставаи нудить стали петербург , мо чорнобриві небудь бенкетують , оксана іди\n","Epoch 49/60\n","204/204 [==============================] - 4s 19ms/step - loss: 1.9996\n","\n","----- Generating text after Epoch: 48\n","--- diversity: 0.2\n","--- Generated with the following context: ['\\n', '\\n', 'то', 'приляже', 'та', 'послуха', ',']\n","\n"," \n"," то приляже та послуха , -> \n"," як кобзар співає , \n"," як серце сміється , немає . . . \n"," будь гаи дамаки \n"," по всіи украі ні \n"," і де наи ду . \n"," а залізняк , бенкетують , то і і наи де\n","--- diversity: 0.5\n","--- Generated with the following context: ['\\n', '\\n', 'то', 'приляже', 'та', 'послуха', ',']\n","\n"," \n"," то приляже та послуха , -> \n"," як кобзар співає , \n"," як серце сміється , ліс очі невеселии , \n"," не , як та він , \n"," пішла моі , \n"," щоб и гонта тому , за и \n"," привітає , \n"," як \n"," хто\n","--- diversity: 1.0\n","--- Generated with the following context: ['\\n', '\\n', 'то', 'приляже', 'та', 'послуха', ',']\n","\n"," \n"," то приляже та послуха , -> \n"," як кобзар співає , \n"," як серце сміється , слухала очі минув нащо день , хлопці и другою чуть . синє сю себе минає осталась куди усі кобзі вранці , рибалка несуть \n"," козаками був шляхта лебедин , гомонить\n","--- diversity: 1.2\n","--- Generated with the following context: ['\\n', '\\n', 'то', 'приляже', 'та', 'послуха', ',']\n","\n"," \n"," то приляже та послуха , -> \n"," як кобзар слухала заверюха \n"," пани , нуте згадаєш чорнобриві ! \n"," завзяті нащо є силу корову таки і беріть забудь днює блакитне і роду б мене провітрився тут закурили дітеи може , ще ть не \n"," \n"," згадаи\n","Epoch 50/60\n","204/204 [==============================] - 4s 19ms/step - loss: 1.9884\n","\n","----- Generating text after Epoch: 49\n","--- diversity: 0.2\n","--- Generated with the following context: ['я', 'продам', 'кумові', 'хатину', ',', '\\n', 'я']\n","я продам кумові хатину , \n"," я -> куплю , я буду , \n"," щоб не знали , \n"," що вам умані \n"," за горить , як до кобзар , \n"," як перше дитину , \n"," в як , дитину , \n"," і є , з и \n","\n","--- diversity: 0.5\n","--- Generated with the following context: ['я', 'продам', 'кумові', 'хатину', ',', '\\n', 'я']\n","я продам кумові хатину , \n"," я -> куплю , я буду . \n"," за буду , \n"," гаи да \n"," и ого ! сина , не попід стара \n"," , сидить , на \n"," \n"," один в вільшану загину . сміх карі людям , \n"," , то\n","--- diversity: 1.0\n","--- Generated with the following context: ['я', 'продам', 'кумові', 'хатину', ',', '\\n', 'я']\n","я продам кумові хатину , \n"," я -> куплю , я голуба жид , ніхто літає гору очі нежив ои ходімо , умань яку вибачаи плакала . пані сирівець \n"," гору не сльози , тарас ма зустрінеться любить - син . , розмовлять , в лихо з сиротою\n","--- diversity: 1.2\n","--- Generated with the following context: ['я', 'продам', 'кумові', 'хатину', ',', '\\n', 'я']\n","я продам кумові хатину , \n"," я -> бач , я колись покинув . вітром своі дочка біле серденько вміла чого дуть тугу єдиним и чорнобрива піди поля но одно є , ідіть поминати січі подивився сумує , моі січ хмари і гадина слави ваша хочеться ходи крила\n","Epoch 51/60\n","204/204 [==============================] - 4s 19ms/step - loss: 1.9864\n","\n","----- Generating text after Epoch: 50\n","--- diversity: 0.2\n","--- Generated with the following context: ['.', '\\n', 'із', '-', 'за', 'лісу', ',']\n",". \n"," із - за лісу , -> з - за місяць , місяць і х , неба - де \n"," ни конфедерати \n"," ! бо привітаи . . у вже не в ? за минулося , не моря що \n"," людям до вранці . \n"," ? треба\n","--- diversity: 0.5\n","--- Generated with the following context: ['.', '\\n', 'із', '-', 'за', 'лісу', ',']\n",". \n"," із - за лісу , -> з - за море , хлоп кличе . \n"," і година , \n"," вас минув тут , . треба тобою ! де тяжко ? \n"," вже вже не ! бога ! \n"," за стала , \n"," и , навіки слова\n","--- diversity: 1.0\n","--- Generated with the following context: ['.', '\\n', 'із', '-', 'за', 'лісу', ',']\n",". \n"," із - за лісу , -> з - за украи свою сю мріє хто \n"," а дорозі шляхетським цу досі сироті снилась бачу , сизии золото , милии , у щира , \n"," тім кричать розмовляти прокляті мовчки голі згадає кохаи католики . \n"," тілько краи\n","--- diversity: 1.2\n","--- Generated with the following context: ['.', '\\n', 'із', '-', 'за', 'лісу', ',']\n",". \n"," із - за лісу , -> з - морем зна бо ми треба nie католиками \n"," душу катруся догляне , і козаком що \n"," діброві вами щаслива питали зомлієм молітесь , що знає пропало \n"," скажуть душно кому \n"," убитии , нували , и співали оксану\n","Epoch 52/60\n","204/204 [==============================] - 4s 19ms/step - loss: 1.9825\n","\n","----- Generating text after Epoch: 51\n","--- diversity: 0.2\n","--- Generated with the following context: ['встане', ',', 'спочиваи', 'те', ',', 'діти', ',']\n","встане , спочиваи те , діти , -> \n"," а я поміркую , і де , як може . , за тои і прокляті - горе . \n"," вона у , \n"," и \n"," де кобзар , як ні ? . . . . . . . .\n","--- diversity: 0.5\n","--- Generated with the following context: ['встане', ',', 'спочиваи', 'те', ',', 'діти', ',']\n","встане , спочиваи те , діти , -> \n"," а я поміркую , така \n"," і люде любить ох . , . на - то тяжко ! \n"," з китаи горем мов \n"," за неі чорнобрива чорнобрива , . . . не а де ж , моя чує\n","--- diversity: 1.0\n","--- Generated with the following context: ['встане', ',', 'спочиваи', 'те', ',', 'діти', ',']\n","встане , спочиваи те , діти , -> \n"," а я тебе , аж хав \n"," сяє мене мати дивляться багато козак співають серця ще сходить ? підпливає по \n"," гріє місяць тут весело катерина \n"," дивись ! вільшану козацькоі добро серденько чуєш єще виспівує плакать , .\n","--- diversity: 1.2\n","--- Generated with the following context: ['встане', ',', 'спочиваи', 'те', ',', 'діти', ',']\n","встане , спочиваи те , діти , -> \n"," журились холоне хвилі . . зав умань дивіться гукає танцювать ножем виглядає панують сном полюбила підняв скажеш вміла моря гетьмани мур небо якби червоніла положила оддам другии носить поплакав жартую , глянуть заграю наи скрізь праведная знали сини .\n","Epoch 53/60\n","204/204 [==============================] - 4s 19ms/step - loss: 1.9713\n","\n","----- Generating text after Epoch: 52\n","--- diversity: 0.2\n","--- Generated with the following context: ['діток', 'годувать', ',', 'треба', 'діток', 'одягать', '.']\n","діток годувать , треба діток одягать . -> \n"," а я буду з , . понад . \n"," - тяжко , минає за \n"," , ні , ні ні \n"," не щоб а не ніч . ! на . украі ні , я ! \n"," а згадаи .\n","--- diversity: 0.5\n","--- Generated with the following context: ['діток', 'годувать', ',', 'треба', 'діток', 'одягать', '.']\n","діток годувать , треба діток одягать . -> \n"," а я буду вільшаніи , . . . . \n"," а о . міи . \n"," ! \n"," тебе мене , я и ои говорить ? може , кличе . , море минає мати , заспіває гріє \n"," чужому\n","--- diversity: 1.0\n","--- Generated with the following context: ['діток', 'годувать', ',', 'треба', 'діток', 'одягать', '.']\n","діток годувать , треба діток одягать . -> \n"," а я буду чорним , та погуляи . гарнесенько \n"," перебендя шкода чужу думка , щоб не вчора ! коня вбили груші люде кричать винен да отаке правда запорожці вгору проклятии ! треба лебедині мліло запорожці первии сину нічого\n","--- diversity: 1.2\n","--- Generated with the following context: ['діток', 'годувать', ',', 'треба', 'діток', 'одягать', '.']\n","діток годувать , треба діток одягать . -> \n"," а я дівчата нами поможе червоною щоб обіцявся слухали ляхів головоньку хто сто покинув побачить \n"," що ж людям мою світу , \n"," спочивають світла думи лісі дасть проклятии справді другии мою мого кричать \n"," и степу розпинать справді\n","Epoch 54/60\n","204/204 [==============================] - 4s 19ms/step - loss: 1.9604\n","\n","----- Generating text after Epoch: 53\n","--- diversity: 0.2\n","--- Generated with the following context: [',', '-', 'гине', 'ледача', 'дитина', ',', 'коли']\n",", - гине ледача дитина , коли -> не ! чого , стогне , \n"," аж вітер , повіє не далеко , постриваи , . якии . \n"," старии , як чи мати ? \n"," кого и , кого , ? \n"," сама було и ому , \n","\n","--- diversity: 0.5\n","--- Generated with the following context: [',', '-', 'гине', 'ледача', 'дитина', ',', 'коли']\n",", - гине ледача дитина , коли -> не ? хто вам свитині глянуть поможе . . , \n"," \n"," а піски на він . \n"," і дасть він , ні гляне , ні старии панувати , \n"," а не козацьку душа \n"," менше ! \n"," щоб же\n","--- diversity: 1.0\n","--- Generated with the following context: [',', '-', 'гине', 'ледача', 'дитина', ',', 'коли']\n",", - гине ледача дитина , коли -> не ! цу молодого піду второпав спочине кинув що крові грошеи . чого ои дасть скажи під іншими вітре воду ! \n"," півні баба мості , молодіі панували панків катерину широкии плач всіи над стриваи скажені ! \n"," безголов горем\n","--- diversity: 1.2\n","--- Generated with the following context: [',', '-', 'гине', 'ледача', 'дитина', ',', 'коли']\n",", - гине ледача дитина , коли -> не жджає злидні та шельмо єзуі пекельноі бенкетують багато шукать отаке шляхта ледве , дивись і оксана . лебедин співать \n"," сину вчора у дака року виі сплять плакала \n"," товариші річеи \n"," сину ! та чуже чорнобрива сини \n","\n","Epoch 55/60\n","204/204 [==============================] - 4s 19ms/step - loss: 1.9722\n","\n","----- Generating text after Epoch: 54\n","--- diversity: 0.2\n","--- Generated with the following context: ['глянуть', 'на', 'люде', ',', 'що', 'вони', 'моторять']\n","глянуть на люде , що вони моторять -> , щоб будем вранці про те на запорожець щось козацькіі ! \n"," мабуть сонце не , , не не в орел \n"," літа по батька діти ! всіи б . в . , а там почули . \n"," а в\n","--- diversity: 0.5\n","--- Generated with the following context: ['глянуть', 'на', 'люде', ',', 'що', 'вони', 'моторять']\n","глянуть на люде , що вони моторять -> , щоб куди вранці про те серце улиці те ? , ходім , горе , бодаи не скаже , знову , справді , запорожці сльози на діброві и крові , нишком оддам пане \n"," нащо и з знає , що\n","--- diversity: 1.0\n","--- Generated with the following context: ['глянуть', 'на', 'люде', ',', 'що', 'вони', 'моторять']\n","глянуть на люде , що вони моторять -> , щоб я дуть про лютеє до годину \n"," якби почули , скажуть я пан києва чує \n"," що єсть караи розмовляють , козаками встає свячении . \n"," от , скаже , де трупом знову взяти з таки ходи текла\n","--- diversity: 1.2\n","--- Generated with the following context: ['глянуть', 'на', 'люде', ',', 'що', 'вони', 'моторять']\n","глянуть на люде , що вони моторять -> , щоб подивитись мліє вона виглядає . вимовляє тим в хотів ксьондзів граи \n"," що тобі , возьміть мова нею великии рак бачили молдаванах ворожка діброві щебетати тополенько тяжко любить \n"," спить воркує , \n"," вільшану хлопче добро \n"," привіз\n","Epoch 56/60\n","204/204 [==============================] - 4s 19ms/step - loss: 1.9696\n","\n","----- Generating text after Epoch: 55\n","--- diversity: 0.2\n","--- Generated with the following context: ['калиною', 'цвісти', 'над', 'ним', 'буду', ',', 'щоб']\n","калиною цвісти над ним буду , щоб -> не вранці не \n"," \n"," я тілько тут и , а тяжко гаи гаи милии \n"," на світ почули , \n"," и \n"," украі на \n"," сліпии сліпии а не запорожці , і гаи \n"," не в и кари жити\n","--- diversity: 0.5\n","--- Generated with the following context: ['калиною', 'цвісти', 'над', 'ним', 'буду', ',', 'щоб']\n","калиною цвісти над ним буду , щоб -> не є в ліс - , там , а крові \n"," старии те сходить . \n"," подивися будем було ! по не ось ти , и ого сльози , не , чом знала , не галаи козака , болить ,\n","--- diversity: 1.0\n","--- Generated with the following context: ['калиною', 'цвісти', 'над', 'ним', 'буду', ',', 'щоб']\n","калиною цвісти над ним буду , щоб -> не плачуть помолитись \n"," сонця вона и пеклом катря богу ватага . \n"," гине це янами ! спасибі годі , несенькии хаті отаке сяють по червонім панували собою в землю знущаються pozwalam пана на світить світла ! слухали синєє дивиться\n","--- diversity: 1.2\n","--- Generated with the following context: ['калиною', 'цвісти', 'над', 'ним', 'буду', ',', 'щоб']\n","калиною цвісти над ним буду , щоб -> не одно старих \n"," та ється менше одиноке вишневии залізняк своі старшина полем людям чужіі співаи . тарас чуприну зустрінуться світ землю , зовуть голуба , іване не нудно мене сходить головоньку и бачу , танцювать вже спать потім віє\n","Epoch 57/60\n","204/204 [==============================] - 4s 19ms/step - loss: 1.9682\n","\n","----- Generating text after Epoch: 56\n","--- diversity: 0.2\n","--- Generated with the following context: [',', 'броду', '.', '.', '.', '\\n', 'годі']\n",", броду . . . \n"," годі -> , годі ! стриваи гонта . . , годі , треба ! \n"," крові до старии , \n"," кругом , як в ого нігде \n"," хто чорнобривии , я а нехаи я нехаи нехаи себе нехаи я я мене и\n","--- diversity: 0.5\n","--- Generated with the following context: [',', 'броду', '.', '.', '.', '\\n', 'годі']\n",", броду . . . \n"," годі -> , годі ! гонта гонта . . гаєм ду гаи долю , нащо ляхів мене . , \n"," вона вона кому не ними чого \n"," не б і в не це \n"," вам так . дивись , ходімо , \n","\n","--- diversity: 1.0\n","--- Generated with the following context: [',', 'броду', '.', '.', '.', '\\n', 'годі']\n",", броду . . . \n"," годі -> , годі ! побачить журиться руи журиться ідуть слухала колись поля щиру ні заграи розмовляти не не обіцявся оставаи знав улиці задзвонили \n"," за вернеться . і знаи лягла по - руі так ко серці додому боці гандзю да жид\n","--- diversity: 1.2\n","--- Generated with the following context: [',', 'броду', '.', '.', '.', '\\n', 'годі']\n",", броду . . . \n"," годі -> , годі ! мало гонта . ду не кров , берлині , роси золото грошеи січ дуб клятим моря брата \n"," сам ще хвилю громада дише хоч чуть ісаія оце пекло ходім ні оксану но , сину ану уночі попереду\n","Epoch 58/60\n","204/204 [==============================] - 4s 19ms/step - loss: 1.9655\n","\n","----- Generating text after Epoch: 57\n","--- diversity: 0.2\n","--- Generated with the following context: ['доглядав', 'вас', ',', 'де', 'ж', 'мені', 'вас']\n","доглядав вас , де ж мені вас -> діти ? \n"," в украі ну ідіть , діти ! \n"," в ж украі діти ! серце , і батько \n"," коли , чужі я , ножем не старшина \n"," \n"," сльозами ідіть вітер . . . ох з те\n","--- diversity: 0.5\n","--- Generated with the following context: ['доглядав', 'вас', ',', 'де', 'ж', 'мені', 'вас']\n","доглядав вас , де ж мені вас -> діти ? \n"," в украі ну ідіть , діти ! \n"," в горить украі ну , \n"," , як став . . . \n"," моє , серце , знаю , \n"," знає . . . кругом , \n"," а батько\n","--- diversity: 1.0\n","--- Generated with the following context: ['доглядав', 'вас', ',', 'де', 'ж', 'мені', 'вас']\n","доглядав вас , де ж мені вас -> діти ? \n"," панове буде на ! , білолиции , \n"," перше погибати , \n"," хлопці а дитину , гомонять . \n"," чому не минає \n"," неба здоров або багато калині - \n"," придбала залізняком матері перше спитаи \n"," \n","\n","--- diversity: 1.2\n","--- Generated with the following context: ['доглядав', 'вас', ',', 'де', 'ж', 'мені', 'вас']\n","доглядав вас , де ж мені вас -> сонце ? вона в годину , бачте , доглядав жива \n"," срібло за буде ані ти , нікому багатии катувать \n"," \n"," як парубками дібровою коні нащо ляхами коло пан краса сирота в навіки біле правда зареготавсь сама любить !\n","Epoch 59/60\n","204/204 [==============================] - 4s 20ms/step - loss: 1.9476\n","\n","----- Generating text after Epoch: 58\n","--- diversity: 0.2\n","--- Generated with the following context: ['гине', 'ледача', 'дитина', ',', 'коли', 'не', 'зуміла']\n","гине ледача дитина , коли не зуміла -> себе не . \n"," \n"," щоб и не лихо , \n"," серце лихо з вами . \n"," нащо , вас ! \n"," було через ви не ховаи ! \n"," не в дурень \n"," , та не ои так , того\n","--- diversity: 0.5\n","--- Generated with the following context: ['гине', 'ледача', 'дитина', ',', 'коли', 'не', 'зуміла']\n","гине ледача дитина , коли не зуміла -> себе знали . \n"," а ти , як . . . та в . . . люде . \n"," чи боже ти бо я ! . . а тим часом діброви \n"," мов козак ! \n"," а чи місяць ,\n","--- diversity: 1.0\n","--- Generated with the following context: ['гине', 'ледача', 'дитина', ',', 'коли', 'не', 'зуміла']\n","гине ледача дитина , коли не зуміла -> себе руці . сліпии гори в така тополя і ніч яне пане \n"," пекла згадаи знову , \n"," за жить високі далебі , \n"," добре , по долю дитину співали коли села божии прости робити , \n"," пустять славу в\n","--- diversity: 1.2\n","--- Generated with the following context: ['гине', 'ледача', 'дитина', ',', 'коли', 'не', 'зуміла']\n","гине ледача дитина , коли не зуміла -> себе переходить . \n"," буду дете хмари гаи привітає сиротині , дочку міи зорі , добрі любила помолились ховаи стала і молились вітри встає nie душно піде шинку . брати загину . \n"," поки московщину через будеш голови замовк дзвонять\n","Epoch 60/60\n","204/204 [==============================] - 4s 19ms/step - loss: 1.9546\n","\n","----- Generating text after Epoch: 59\n","--- diversity: 0.2\n","--- Generated with the following context: ['личко', ',', 'чорні', 'брови', '.', '.', 'нащо']\n","личко , чорні брови . . нащо -> ? щоб серце ! на тяжко знає ! \n"," за ним дівчата , \n"," яку - то и \n"," \n"," всіи украі ні од и \n"," ляхами чорнобрива в воду \n"," і . . . якии і і та !\n","--- diversity: 0.5\n","--- Generated with the following context: ['личко', ',', 'чорні', 'брови', '.', '.', 'нащо']\n","личко , чорні брови . . нащо -> ? щоб б . . . з панове скажені спочиваи \n"," , я и , поки не попереду , за думу , а ти не вами ! мене ходімо , коли ! \n"," і я и \n"," ходімо , все\n","--- diversity: 1.0\n","--- Generated with the following context: ['личко', ',', 'чорні', 'брови', '.', '.', 'нащо']\n","личко , чорні брови . . нащо -> ? щоб католики ! \n"," душу своі мене . . виглядала гине або нии , ще запорожці тяжко стіи в с ни ому дише чужині таки вбитии - довелося доле та знову , воно ніхто більше свячении хиря побачимо старшии\n","--- diversity: 1.2\n","--- Generated with the following context: ['личко', ',', 'чорні', 'брови', '.', '.', 'нащо']\n","личко , чорні брови . . нащо -> ? очі од всім ногами х яне ! кричать дають пити дніпром гукає молодого \n"," де утни заи горіло став кинув дитина чуєш мліє катря пан листя \n"," як вии залізноі прокляті дівчата тебе ляхом ревуть . дитину головоньку сліпии\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb3b0077fd0>"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"8OGSAdjrptQj"},"source":["**Output after 60 epochs:** \n","```\n","Epoch 60/60\n","26087/26087 [==============================] - 46s 2ms/step - loss: 2.0366\n","\n","----- Generating text after Epoch: 59\n","--- diversity: 0.2\n","--- Generated with the following context: ['то', 'и', 'стара', 'мати', ',', '\\n', 'що']\n","то и стара мати , \n"," що -> жить на ! \n"," з украі ну на міи , \n"," \n"," тяжко лихо немає . \n"," а хто долі серед без , як пішов ? . . \n"," то ж ж , ж ти ж ж , і ,\n","--- diversity: 0.5\n","--- Generated with the following context: ['то', 'и', 'стара', 'мати', ',', '\\n', 'що']\n","то и стара мати , \n"," що -> розумні на , а тим часом \n"," ярема не ножі , з боже є з козаками ? думи моі , крові . іди , де мені з нащо ? де будеш , ось ? \n"," не слова , \n"," що\n","--- diversity: 1.0\n","--- Generated with the following context: ['то', 'и', 'стара', 'мати', ',', '\\n', 'що']\n","то и стара мати , \n"," що -> привела на чужині зозуленька . ! \n"," не пожари воля знали пии темнии , сеи згадаєш сизии один вздовж бабусю мовчіть вии запорожці , прилини втирають хмари жупани полюбила поглядає єсть золоті кличе лежить треті була де ще степ цілує\n","--- diversity: 1.2\n","--- Generated with the following context: ['то', 'и', 'стара', 'мати', ',', '\\n', 'що']\n","то и стара мати , \n"," що -> навіки щиро хали щиро греблю поганці , московщину кохаи знала , весна панове ревуть . літа тихесенько \n"," плаче козацького таке стоя \n"," москаля , сховається гонта \n"," крові чорноброві ходімо побачиш цілує уже журись \n"," слухать чує неба з\n","<keras.callbacks.callbacks.History at 0x1a8b797190>\n","```"]},{"cell_type":"markdown","metadata":{"id":"HcnJZmVKptQj"},"source":["<font color = green >\n","\n","## Sample 2A: language model using keras \n","\n","</font>\n","\n","Character level language model is implemented as LSTM for poem of T.Shevchenko \n"]},{"cell_type":"code","metadata":{"id":"bcArF9A5ptQj"},"source":["chars = sorted(list(set(text)))\n","print('total chars:', len(chars))\n","\n","char_indices = dict((c, i) for i, c in enumerate(chars))\n","indices_char = dict((i, c) for i, c in enumerate(chars))\n","\n","# cut the text into sequences of maxlen characters\n","maxlen = 40\n","step = 3 # shift to build new sample \n","sentences = []\n","next_chars = []\n","for i in range(0, len(text) - maxlen, step):\n","    sentences.append(text[i: i + maxlen])\n","    next_chars.append(text[i + maxlen])\n","print('len(samples) = {:,}'.format(len(sentences)))\n","\n","\n","print('Converting to one-hot vectors...')\n","x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n","y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n","for i, sentence in enumerate(sentences):\n","    for t, char in enumerate(sentence):\n","        x[i, t, char_indices[char]] = 1\n","    y[i, char_indices[next_chars[i]]] = 1\n","\n","\n","print('Build model (single LSTM)...')\n","model = Sequential()\n","model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n","model.add(Dense(len(chars), activation='softmax'))\n","\n","optimizer = RMSprop(lr=0.01)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n","\n","def sample(preds, temperature=1.0):\n","    # helper function to sample an index from a probability array\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)\n","\n","\n","def on_epoch_end(epoch, _):\n","    # Function invoked at end of each epoch. Prints generated text.    \n","    print('\\n----- Generating text after Epoch: %d' % epoch)\n","\n","    start_index = random.randint(0, len(text) - maxlen - 1)\n","    for diversity in [0.2, 0.5, 1.0, 1.2]:\n","        print('----- diversity:', diversity)\n","        generated = ''\n","        sentence = text[start_index: start_index + maxlen]\n","        generated += sentence\n","        print('----- Generated: \"' + sentence + '\"')\n","        sys.stdout.write(generated)\n","\n","        for i in range(400): # number of chars to gerenerate \n","            x_pred = np.zeros((1, maxlen, len(chars)))\n","            for t, char in enumerate(sentence):\n","                x_pred[0, t, char_indices[char]] = 1.\n","\n","            preds = model.predict(x_pred, verbose=0)[0]\n","            next_index = sample(preds, diversity)\n","            next_char = indices_char[next_index]\n","\n","            generated += next_char\n","            sentence = sentence[1:] + next_char\n","\n","            sys.stdout.write(next_char)\n","            sys.stdout.flush()\n","\n","print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n","\n","model.fit(x, y,\n","          batch_size=128,\n","          epochs=60,\n","          callbacks=[print_callback])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zH5FWq90ptQk"},"source":["Generating text after Epoch: 59 (diversity: 0.5)\n","<br>\n","`як він, свої думи тії\n","і серце убо\"\n","оре.\n","як він, свої думи тії\n","і серце убогії горили.\n","а до то прості на собі, поки не знать... а не чуть, а там діти?\n","і могили погину, синіїм піде з киїти, а як і на всеї дожить.\n","а ще сумуючи, поки все бордная! привела в світі та зарегожа поможем засталося. не просла сусіди, а що криниці, молоденька веселі,\n","ми за то розказила\n","і при другаять. а може, співає,\n","і все знає,\n","і дівила світі, як то плети,\n","а я ж думать за що, нехай була одно`\n","\n","Generating text after Epoch: 59 (diversity: 1.0)\n","<br>\n","`а галайда, знай, гукає:\n","«кари ляхам, спьшає німили: сходиться знали\n","і все роззуттва сором ми по всі жали, і ти...» — коли їла.\n","мов ні його співали? кричіє! роз кету, скажи мате,\n","що й золобе бога, чую!\n","за тій світу заборкає.\n","з землих я княшіво-ховав,\n","у хату підерячки, щоб великпертика й не веселі, плачуть передову. .....\n","нуме понадвала стане, тому так! ея\n","і деревамі,\n","а точки.\n","я сказать, у бав. ! тобі їй пузандій молоденько і`\n"]},{"cell_type":"markdown","metadata":{"id":"xThfCyAfptQl"},"source":["# Hometask\n","\n","1) Find text to train (any book)<br>\n","2) Build train and validation set <br>\n","3) Train bidirectional language model that predicts the POS of word being based on its `n_context= 3` neighbours from the left and `n_context= 3` neighbours from the right <br>\n","4) Evaluate the model "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KRHZ2wiNptQl","executionInfo":{"status":"ok","timestamp":1634488930500,"user_tz":-180,"elapsed":226,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"12c90a9f-a583-4485-a6db-0d3a4a73fede"},"source":["import nltk\n","nltk.download('gutenberg')"],"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]   Package gutenberg is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3EzU34TE2KK","executionInfo":{"status":"ok","timestamp":1634488932882,"user_tz":-180,"elapsed":213,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"963ae617-d90c-40e3-faba-eab89a4abb3e"},"source":["from nltk.corpus import gutenberg\n","gutenberg.fileids()"],"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['austen-emma.txt',\n"," 'austen-persuasion.txt',\n"," 'austen-sense.txt',\n"," 'bible-kjv.txt',\n"," 'blake-poems.txt',\n"," 'bryant-stories.txt',\n"," 'burgess-busterbrown.txt',\n"," 'carroll-alice.txt',\n"," 'chesterton-ball.txt',\n"," 'chesterton-brown.txt',\n"," 'chesterton-thursday.txt',\n"," 'edgeworth-parents.txt',\n"," 'melville-moby_dick.txt',\n"," 'milton-paradise.txt',\n"," 'shakespeare-caesar.txt',\n"," 'shakespeare-hamlet.txt',\n"," 'shakespeare-macbeth.txt',\n"," 'whitman-leaves.txt']"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"-vNouvx3FK2N","executionInfo":{"status":"ok","timestamp":1634488935234,"user_tz":-180,"elapsed":331,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}}},"source":["moby_dick_id= gutenberg.fileids()[-6]\n","text = gutenberg.raw(moby_dick_id)"],"execution_count":58,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jtOhrpGvGq_9"},"source":["### Preprocessing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QcfAy1vmF2bS","executionInfo":{"status":"ok","timestamp":1634488937150,"user_tz":-180,"elapsed":14,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"c840abb3-a09d-45eb-d232-ab9da2281d41"},"source":["text = re.sub(r'\\[.*\\]', \"\", text)\n","text = re.sub(r'\\d+', \"\", text)\n","text = re.sub(r'«|»|\\n', \"\", text)\n","text = text.lower()\n","\n","print ('Len of original text= {:,}'.format (len(text)))\n","keep = 0.2\n","text =  text[: int (len(text)* keep)]\n","print ('Len of snippet= {:,}'.format (len(text)))\n","\n","print (text[:500])"],"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Len of original text= 1,219,336\n","Len of snippet= 243,867\n","\r\r\retymology.\r\r(supplied by a late consumptive usher to a grammar school)\r\rthe pale usher--threadbare in coat, heart, body, and brain; i see him\rnow.  he was ever dusting his old lexicons and grammars, with a queer\rhandkerchief, mockingly embellished with all the gay flags of all the\rknown nations of the world.  he loved to dust his old grammars; it\rsomehow mildly reminded him of his mortality.\r\r\"while you take in hand to school others, and to teach them by what\rname a whale-fish is to be called\n"]}]},{"cell_type":"code","metadata":{"id":"tqz3ifXMGMsb","executionInfo":{"status":"ok","timestamp":1634488940667,"user_tz":-180,"elapsed":237,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}}},"source":["vectorizer = CountVectorizer(token_pattern=r'(?u)(?:\\b\\w+\\b|\\.|\\,|\\!|\\?|\\-|\\n)').fit([text])"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KawUyEgaGS0w","executionInfo":{"status":"ok","timestamp":1634488942402,"user_tz":-180,"elapsed":216,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"cf24cfc0-1718-46c5-fe4c-8bc5d1ec1992"},"source":["print ('len of features = {:,}\\n'.format(len(vectorizer.get_feature_names())))\n","vocab = vectorizer.get_feature_names()\n","print (vocab[:100])"],"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["len of features = 6,815\n","\n","['!', ',', '-', '.', '?', '_____________', 'a', 'abandon', 'abashed', 'abed', 'able', 'ablutions', 'aboard', 'abode', 'abominable', 'abominate', 'abominated', 'aboriginal', 'about', 'above', 'abreast', 'abroad', 'abruptly', 'absence', 'absent', 'absolute', 'absorbed', 'absorbing', 'absurd', 'abundance', 'abundant', 'abundantly', 'accelerate', 'accident', 'accidental', 'accidents', 'accommodated', 'accompanied', 'accompany', 'accomplished', 'according', 'accordingly', 'accosted', 'account', 'accounted', 'accounts', 'accumulate', 'accursed', 'accustomed', 'ached', 'achieved', 'acknowledges', 'acquaintances', 'acquainted', 'acquiesce', 'acres', 'across', 'act', 'acted', 'active', 'actively', 'activity', 'actual', 'actually', 'actuated', 'acushnet', 'adam', 'add', 'added', 'adding', 'addition', 'address', 'addressed', 'adhering', 'adieux', 'adjacent', 'adjoining', 'adjust', 'admire', 'admirer', 'admitting', 'ado', 'adorned', 'adorning', 'adulterer', 'advance', 'advances', 'advancing', 'advantages', 'adventure', 'adventures', 'adventurous', 'advertised', 'advice', 'advocate', 'affair', 'affairs', 'affected', 'affection', 'affectionate']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yOHXwxwnGoXz","executionInfo":{"status":"ok","timestamp":1634488947665,"user_tz":-180,"elapsed":239,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"67df4e84-ca67-4af1-9879-fab4bec8b075"},"source":["word2index = vectorizer.vocabulary_\n","\n","index2word = {v:k for k,v in word2index.items()}\n","index2word"],"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{1996: 'etymology',\n"," 3: '.',\n"," 5845: 'supplied',\n"," 819: 'by',\n"," 6: 'a',\n"," 3332: 'late',\n"," 1291: 'consumptive',\n"," 6391: 'usher',\n"," 6112: 'to',\n"," 2536: 'grammar',\n"," 5116: 'school',\n"," 6010: 'the',\n"," 4157: 'pale',\n"," 2: '-',\n"," 6060: 'threadbare',\n"," 2982: 'in',\n"," 1109: 'coat',\n"," 1: ',',\n"," 2716: 'heart',\n"," 642: 'body',\n"," 192: 'and',\n"," 705: 'brain',\n"," 2915: 'i',\n"," 5172: 'see',\n"," 2792: 'him',\n"," 3971: 'now',\n"," 2702: 'he',\n"," 6546: 'was',\n"," 2006: 'ever',\n"," 1808: 'dusting',\n"," 2800: 'his',\n"," 4038: 'old',\n"," 3400: 'lexicons',\n"," 2537: 'grammars',\n"," 6703: 'with',\n"," 4690: 'queer',\n"," 2642: 'handkerchief',\n"," 3739: 'mockingly',\n"," 1899: 'embellished',\n"," 151: 'all',\n"," 2427: 'gay',\n"," 2227: 'flags',\n"," 4020: 'of',\n"," 3280: 'known',\n"," 3877: 'nations',\n"," 6743: 'world',\n"," 3495: 'loved',\n"," 1807: 'dust',\n"," 3155: 'it',\n"," 5505: 'somehow',\n"," 3697: 'mildly',\n"," 4839: 'reminded',\n"," 3779: 'mortality',\n"," 6638: 'while',\n"," 6805: 'you',\n"," 5930: 'take',\n"," 2638: 'hand',\n"," 4083: 'others',\n"," 5964: 'teach',\n"," 6014: 'them',\n"," 6617: 'what',\n"," 3855: 'name',\n"," 6605: 'whale',\n"," 2213: 'fish',\n"," 3144: 'is',\n"," 450: 'be',\n"," 830: 'called',\n"," 4087: 'our',\n"," 6137: 'tongue',\n"," 3373: 'leaving',\n"," 4090: 'out',\n"," 6071: 'through',\n"," 2938: 'ignorance',\n"," 3393: 'letter',\n"," 2608: 'h',\n"," 6637: 'which',\n"," 161: 'almost',\n"," 163: 'alone',\n"," 3544: 'maketh',\n"," 5354: 'signification',\n"," 6736: 'word',\n"," 1555: 'deliver',\n"," 6008: 'that',\n"," 3958: 'not',\n"," 6222: 'true',\n"," 2616: 'hackluyt',\n"," 5876: 'sw',\n"," 1470: 'dan',\n"," 2907: 'hval',\n"," 6043: 'this',\n"," 200: 'animal',\n"," 3856: 'named',\n"," 2365: 'from',\n"," 5000: 'roundness',\n"," 4062: 'or',\n"," 4981: 'rolling',\n"," 2291: 'for',\n"," 2908: 'hvalt',\n"," 271: 'arched',\n"," 6422: 'vaulted',\n"," 6579: 'webster',\n"," 5028: 's',\n"," 1623: 'dictionary',\n"," 3773: 'more',\n"," 2952: 'immediately',\n"," 1810: 'dut',\n"," 2446: 'ger',\n"," 6516: 'wallen',\n"," 6523: 'walw',\n"," 2916: 'ian',\n"," 4979: 'roll',\n"," 6519: 'wallow',\n"," 4936: 'richardson',\n"," 3240: 'ketos',\n"," 2559: 'greek',\n"," 951: 'cetus',\n"," 3337: 'latin',\n"," 6659: 'whoel',\n"," 198: 'anglo',\n"," 5099: 'saxon',\n"," 1474: 'danish',\n"," 6510: 'wal',\n"," 1811: 'dutch',\n"," 2909: 'hwal',\n"," 5887: 'swedish',\n"," 2923: 'icelandic',\n"," 1934: 'english',\n"," 410: 'baleine',\n"," 2348: 'french',\n"," 413: 'ballena',\n"," 5543: 'spanish',\n"," 4258: 'pekee',\n"," 3974: 'nuee',\n"," 2162: 'fegee',\n"," 1977: 'erromangoan',\n"," 2067: 'extracts',\n"," 5796: 'sub',\n"," 3403: 'librarian',\n"," 6680: 'will',\n"," 5183: 'seen',\n"," 3667: 'mere',\n"," 4149: 'painstaking',\n"," 798: 'burrower',\n"," 2589: 'grub',\n"," 6746: 'worm',\n"," 4438: 'poor',\n"," 1614: 'devil',\n"," 251: 'appears',\n"," 2695: 'have',\n"," 2520: 'gone',\n"," 3471: 'long',\n"," 6420: 'vaticans',\n"," 5755: 'street',\n"," 5639: 'stalls',\n"," 1833: 'earth',\n"," 4323: 'picking',\n"," 6377: 'up',\n"," 6618: 'whatever',\n"," 4734: 'random',\n"," 159: 'allusions',\n"," 6611: 'whales',\n"," 1352: 'could',\n"," 228: 'anyways',\n"," 2197: 'find',\n"," 224: 'any',\n"," 664: 'book',\n"," 6619: 'whatsoever',\n"," 5034: 'sacred',\n"," 4577: 'profane',\n"," 6022: 'therefore',\n"," 3834: 'must',\n"," 2008: 'every',\n"," 899: 'case',\n"," 336: 'at',\n"," 3370: 'least',\n"," 2782: 'higgledy',\n"," 4334: 'piggledy',\n"," 5663: 'statements',\n"," 2865: 'however',\n"," 363: 'authentic',\n"," 6025: 'these',\n"," 6434: 'veritable',\n"," 2527: 'gospel',\n"," 950: 'cetology',\n"," 2111: 'far',\n"," 307: 'as',\n"," 6157: 'touching',\n"," 191: 'ancient',\n"," 365: 'authors',\n"," 2436: 'generally',\n"," 6595: 'well',\n"," 4414: 'poets',\n"," 2761: 'here',\n"," 250: 'appearing',\n"," 275: 'are',\n"," 5496: 'solely',\n"," 6410: 'valuable',\n"," 1955: 'entertaining',\n"," 103: 'affording',\n"," 2476: 'glancing',\n"," 572: 'bird',\n"," 2075: 'eye',\n"," 6452: 'view',\n"," 2678: 'has',\n"," 489: 'been',\n"," 4591: 'promiscuously',\n"," 5045: 'said',\n"," 6054: 'thought',\n"," 2107: 'fancied',\n"," 5830: 'sung',\n"," 3399: 'leviathan',\n"," 3566: 'many',\n"," 2437: 'generations',\n"," 2991: 'including',\n"," 4122: 'own',\n"," 5475: 'so',\n"," 2113: 'fare',\n"," 6011: 'thee',\n"," 6665: 'whose',\n"," 1168: 'commentator',\n"," 174: 'am',\n"," 6052: 'thou',\n"," 518: 'belongest',\n"," 2837: 'hopeless',\n"," 5060: 'sallow',\n"," 6199: 'tribe',\n"," 3937: 'no',\n"," 6693: 'wine',\n"," 6538: 'warm',\n"," 6664: 'whom',\n"," 2001: 'even',\n"," 5280: 'sherry',\n"," 6757: 'would',\n"," 6138: 'too',\n"," 4996: 'rosy',\n"," 5774: 'strong',\n"," 807: 'but',\n"," 4044: 'one',\n"," 5508: 'sometimes',\n"," 3497: 'loves',\n"," 5386: 'sit',\n"," 2157: 'feel',\n"," 1615: 'devilish',\n"," 2584: 'grow',\n"," 1324: 'convivial',\n"," 6379: 'upon',\n"," 5967: 'tears',\n"," 5100: 'say',\n"," 628: 'bluntly',\n"," 2378: 'full',\n"," 2077: 'eyes',\n"," 1913: 'empty',\n"," 2479: 'glasses',\n"," 172: 'altogether',\n"," 6348: 'unpleasant',\n"," 5037: 'sadness',\n"," 2466: 'give',\n"," 5801: 'subs',\n"," 0: '!',\n"," 2864: 'how',\n"," 3816: 'much',\n"," 4148: 'pains',\n"," 6787: 'ye',\n"," 4391: 'please',\n"," 5250: 'shall',\n"," 2505: 'go',\n"," 6006: 'thankless',\n"," 1071: 'clear',\n"," 2636: 'hampton',\n"," 1369: 'court',\n"," 6234: 'tuileries',\n"," 2603: 'gulp',\n"," 1737: 'down',\n"," 6807: 'your',\n"," 2780: 'hie',\n"," 162: 'aloft',\n"," 5005: 'royal',\n"," 3601: 'mast',\n"," 2721: 'hearts',\n"," 2355: 'friends',\n"," 6658: 'who',\n"," 491: 'before',\n"," 1073: 'clearing',\n"," 5231: 'seven',\n"," 5728: 'storied',\n"," 2732: 'heavens',\n"," 3545: 'making',\n"," 4801: 'refugees',\n"," 4161: 'pampered',\n"," 2397: 'gabriel',\n"," 3681: 'michael',\n"," 4739: 'raphael',\n"," 116: 'against',\n"," 1158: 'coming',\n"," 5763: 'strike',\n"," 5587: 'splintered',\n"," 6119: 'together',\n"," 6020: 'there',\n"," 6362: 'unsplinterable',\n"," 2509: 'god',\n"," 1394: 'created',\n"," 2554: 'great',\n"," 2439: 'genesis',\n"," 4220: 'path',\n"," 5284: 'shine',\n"," 111: 'after',\n"," 6035: 'think',\n"," 1528: 'deep',\n"," 2808: 'hoary',\n"," 3186: 'job',\n"," 3483: 'lord',\n"," 2617: 'had',\n"," 4517: 'prepared',\n"," 5879: 'swallow',\n"," 3199: 'jonah',\n"," 5291: 'ships',\n"," 2680: 'hast',\n"," 3523: 'made',\n"," 4388: 'play',\n"," 6023: 'therein',\n"," 4633: 'psalms',\n"," 1493: 'day',\n"," 5520: 'sore',\n"," 5907: 'sword',\n"," 4648: 'punish',\n"," 4331: 'piercing',\n"," 5219: 'serpent',\n"," 1413: 'crooked',\n"," 5414: 'slay',\n"," 1748: 'dragon',\n"," 5147: 'sea',\n"," 3145: 'isaiah',\n"," 6033: 'thing',\n"," 5486: 'soever',\n"," 540: 'besides',\n"," 1149: 'cometh',\n"," 6711: 'within',\n"," 966: 'chaos',\n"," 3758: 'monster',\n"," 3801: 'mouth',\n"," 463: 'beast',\n"," 636: 'boat',\n"," 5716: 'stone',\n"," 2511: 'goes',\n"," 2996: 'incontinently',\n"," 2327: 'foul',\n"," 4288: 'perisheth',\n"," 683: 'bottomless',\n"," 2599: 'gulf',\n"," 4225: 'paunch',\n"," 2818: 'holland',\n"," 4408: 'plutarch',\n"," 3771: 'morals',\n"," 3011: 'indian',\n"," 728: 'breedeth',\n"," 3784: 'most',\n"," 564: 'biggest',\n"," 2217: 'fishes',\n"," 184: 'among',\n"," 6646: 'whirlpooles',\n"," 407: 'balaene',\n"," 3383: 'length',\n"," 2333: 'four',\n"," 55: 'acres',\n"," 289: 'arpens',\n"," 3304: 'land',\n"," 4397: 'pliny',\n"," 5109: 'scarcely',\n"," 6569: 'we',\n"," 4566: 'proceeded',\n"," 6262: 'two',\n"," 1495: 'days',\n"," 4042: 'on',\n"," 6623: 'when',\n"," 18: 'about',\n"," 5834: 'sunrise',\n"," 4082: 'other',\n"," 3759: 'monsters',\n"," 249: 'appeared',\n"," 2315: 'former',\n"," 3760: 'monstrous',\n"," 5393: 'size',\n"," 837: 'came',\n"," 6159: 'towards',\n"," 6385: 'us',\n"," 4048: 'open',\n"," 3802: 'mouthed',\n"," 4728: 'raising',\n"," 6564: 'waves',\n"," 5344: 'sides',\n"," 466: 'beating',\n"," 3116: 'into',\n"," 2268: 'foam',\n"," 6140: 'tooke',\n"," 3504: 'lucian',\n"," 2802: 'history',\n"," 6469: 'visited',\n"," 1362: 'country',\n"," 169: 'also',\n"," 918: 'catching',\n"," 2848: 'horse',\n"," 660: 'bones',\n"," 6440: 'very',\n"," 6411: 'value',\n"," 6012: 'their',\n"," 5969: 'teeth',\n"," 765: 'brought',\n"," 5503: 'some',\n"," 3253: 'king',\n"," 544: 'best',\n"," 6598: 'were',\n"," 916: 'catched',\n"," 2324: 'forty',\n"," 1868: 'eight',\n"," 2186: 'fifty',\n"," 6783: 'yards',\n"," 5389: 'six',\n"," 3244: 'killed',\n"," 5392: 'sixty',\n"," 4015: 'octher',\n"," 6431: 'verbal',\n"," 3869: 'narrative',\n"," 5931: 'taken',\n"," 146: 'alfred',\n"," 1462: 'd',\n"," 6627: 'whereas',\n"," 6034: 'things',\n"," 6634: 'whether',\n"," 6441: 'vessel',\n"," 1951: 'enter',\n"," 1759: 'dreadful',\n"," 3488: 'lost',\n"," 5880: 'swallowed',\n"," 2594: 'gudgeon',\n"," 4908: 'retires',\n"," 5171: 'security',\n"," 5420: 'sleeps',\n"," 3762: 'montaigne',\n"," 236: 'apology',\n"," 4723: 'raimond',\n"," 5161: 'sebond',\n"," 3391: 'let',\n"," 2266: 'fly',\n"," 3926: 'nick',\n"," 3624: 'me',\n"," 2936: 'if',\n"," 1578: 'described',\n"," 3939: 'noble',\n"," 4606: 'prophet',\n"," 3782: 'moses',\n"," 3409: 'life',\n"," 4221: 'patient',\n"," 4714: 'rabelais',\n"," 3452: 'liver',\n"," 896: 'cartloads',\n"," 5735: 'stowe',\n"," 203: 'annals',\n"," 5154: 'seas',\n"," 5185: 'seethe',\n"," 3421: 'like',\n"," 645: 'boiling',\n"," 4162: 'pan',\n"," 397: 'bacon',\n"," 6438: 'version',\n"," 780: 'bulk',\n"," 4075: 'ork',\n"," 4772: 'received',\n"," 3962: 'nothing',\n"," 947: 'certain',\n"," 6027: 'they',\n"," 2023: 'exceeding',\n"," 2127: 'fat',\n"," 3084: 'insomuch',\n"," 188: 'an',\n"," 2999: 'incredible',\n"," 4684: 'quantity',\n"," 4035: 'oil',\n"," 2065: 'extracted',\n"," 2917: 'ibid',\n"," 1504: 'death',\n"," 5537: 'sovereignest',\n"," 4189: 'parmacetti',\n"," 3136: 'inward',\n"," 770: 'bruise',\n"," 2756: 'henry',\n"," 2631: 'hamlet',\n"," 5168: 'secure',\n"," 5396: 'skill',\n"," 3352: 'leach',\n"," 299: 'art',\n"," 3786: 'mote',\n"," 367: 'availle',\n"," 4914: 'returne',\n"," 115: 'againe',\n"," 6759: 'wound',\n"," 6740: 'worker',\n"," 3501: 'lowly',\n"," 1480: 'dart',\n"," 1643: 'dinting',\n"," 721: 'breast',\n"," 726: 'bred',\n"," 4896: 'restless',\n"," 4144: 'paine',\n"," 6760: 'wounded',\n"," 5306: 'shore',\n"," 2243: 'flies',\n"," 6068: 'thro',\n"," 3537: 'maine',\n"," 2087: 'faerie',\n"," 4688: 'queen',\n"," 2954: 'immense',\n"," 3789: 'motion',\n"," 6418: 'vast',\n"," 640: 'bodies',\n"," 838: 'can',\n"," 4240: 'peaceful',\n"," 833: 'calm',\n"," 6216: 'trouble',\n"," 4013: 'ocean',\n"," 6096: 'til',\n"," 644: 'boil',\n"," 5384: 'sir',\n"," 6681: 'william',\n"," 1489: 'davenant',\n"," 4505: 'preface',\n"," 2519: 'gondibert',\n"," 5571: 'spermacetti',\n"," 3656: 'men',\n"," 3689: 'might',\n"," 3229: 'justly',\n"," 1732: 'doubt',\n"," 5372: 'since',\n"," 3367: 'learned',\n"," 2850: 'hosmannus',\n"," 6739: 'work',\n"," 6042: 'thirty',\n"," 6790: 'years',\n"," 5054: 'saith',\n"," 4370: 'plainly',\n"," 3910: 'nescio',\n"," 4700: 'quid',\n"," 5920: 't',\n"," 768: 'browne',\n"," 5569: 'sperma',\n"," 949: 'ceti',\n"," 6451: 'vide',\n"," 6402: 'v',\n"," 1819: 'e',\n"," 5564: 'spencer',\n"," 5943: 'talus',\n"," 3742: 'modern',\n"," 2228: 'flail',\n"," 6063: 'threatens',\n"," 5012: 'ruin',\n"," 4435: 'ponderous',\n"," 5927: 'tail',\n"," 2225: 'fixed',\n"," 3174: 'jav',\n"," 3438: 'lins',\n"," 5343: 'side',\n"," 6576: 'wears',\n"," 390: 'back',\n"," 2583: 'grove',\n"," 4336: 'pikes',\n"," 6517: 'waller',\n"," 446: 'battle',\n"," 5824: 'summer',\n"," 3148: 'islands',\n"," 1178: 'commonwealth',\n"," 5660: 'state',\n"," 1055: 'civitas',\n"," 304: 'artificial',\n"," 3551: 'man',\n"," 4050: 'opening',\n"," 5208: 'sentence',\n"," 2810: 'hobbes',\n"," 5365: 'silly',\n"," 3565: 'mansoul',\n"," 6712: 'without',\n"," 1010: 'chewing',\n"," 5608: 'sprat',\n"," 4340: 'pilgrim',\n"," 4587: 'progress',\n"," 6742: 'works',\n"," 2874: 'hugest',\n"," 5901: 'swim',\n"," 5754: 'stream',\n"," 4177: 'paradise',\n"," 3454: 'living',\n"," 1397: 'creatures',\n"," 5758: 'stretched',\n"," 4595: 'promontory',\n"," 5903: 'swims',\n"," 5182: 'seems',\n"," 3808: 'moving',\n"," 2461: 'gills',\n"," 1756: 'draws',\n"," 722: 'breath',\n"," 5605: 'spouts',\n"," 3694: 'mighty',\n"," 6557: 'water',\n"," 5902: 'swimming',\n"," 2379: 'fulller',\n"," 2821: 'holy',\n"," 1087: 'close',\n"," 502: 'behind',\n"," 3406: 'lie',\n"," 2872: 'huge',\n"," 347: 'attend',\n"," 4545: 'prey',\n"," 959: 'chance',\n"," 2374: 'fry',\n"," 2411: 'gaping',\n"," 3177: 'jaws',\n"," 3731: 'mistake',\n"," 6567: 'way',\n"," 1791: 'dryden',\n"," 210: 'annus',\n"," 3712: 'mirabilis',\n"," 2248: 'floating',\n"," 5694: 'stern',\n"," 5286: 'ship',\n"," 1455: 'cut',\n"," 4021: 'off',\n"," 2703: 'head',\n"," 6158: 'tow',\n"," 3888: 'near',\n"," 1144: 'come',\n"," 129: 'aground',\n"," 6251: 'twelve',\n"," 6041: 'thirteen',\n"," 2161: 'feet',\n"," 6047: 'thomas',\n"," 1850: 'edge',\n"," 5980: 'ten',\n"," 6491: 'voyages',\n"," 5583: 'spitzbergen',\n"," 4650: 'purchas',\n"," 5096: 'saw',\n"," 5597: 'sporting',\n"," 6530: 'wantonness',\n"," 2395: 'fuzzing',\n"," 4351: 'pipes',\n"," 6429: 'vents',\n"," 3883: 'nature',\n"," 4364: 'placed',\n"," 5316: 'shoulders',\n"," 2759: 'herbert',\n"," 312: 'asia',\n"," 109: 'africa',\n"," 2675: 'harris',\n"," 1132: 'coll',\n"," 5812: 'such',\n"," 6212: 'troops',\n"," 2295: 'forced',\n"," 4565: 'proceed',\n"," 1500: 'deal',\n"," 929: 'caution',\n"," 2140: 'fear',\n"," 5312: 'should',\n"," 5019: 'run',\n"," 5120: 'schouten',\n"," 5391: 'sixth',\n"," 1046: 'circumnavigation',\n"," 5223: 'set',\n"," 5046: 'sail',\n"," 1874: 'elbe',\n"," 6686: 'wind',\n"," 3851: 'n',\n"," 3200: 'jonas',\n"," 2080: 'fable',\n"," 2351: 'frequently',\n"," 1078: 'climb',\n"," 3605: 'masts',\n"," 2212: 'first',\n"," 1661: 'discoverer',\n"," 1794: 'ducat',\n"," 6125: 'told',\n"," 5281: 'shetland',\n"," 19: 'above',\n"," 435: 'barrel',\n"," 2770: 'herrings',\n"," 515: 'belly',\n"," 2672: 'harpooneers',\n"," 925: 'caught',\n"," 4043: 'once',\n"," 6653: 'white',\n"," 4102: 'over',\n"," 6488: 'voyage',\n"," 2563: 'greenland',\n"," 5234: 'several',\n"," 1107: 'coast',\n"," 2181: 'fife',\n"," 205: 'anno',\n"," 1870: 'eighty',\n"," 659: 'bone',\n"," 3247: 'kind',\n"," 3043: 'informed',\n"," 1624: 'did',\n"," 102: 'afford',\n"," 6592: 'weight',\n"," 409: 'baleen',\n"," 5642: 'stand',\n"," 2417: 'gate',\n"," 2412: 'garden',\n"," 4359: 'pitferren',\n"," 5338: 'sibbald',\n"," 3256: 'kinross',\n"," 3843: 'myself',\n"," 128: 'agreed',\n"," 6230: 'try',\n"," 3602: 'master',\n"," 3243: 'kill',\n"," 3913: 'never',\n"," 2710: 'hear',\n"," 5524: 'sort',\n"," 2179: 'fierceness',\n"," 5900: 'swiftness',\n"," 4935: 'richard',\n"," 5736: 'strafford',\n"," 535: 'bermudas',\n"," 4309: 'phil',\n"," 6176: 'trans',\n"," 6476: 'voice',\n"," 3987: 'obey',\n"," 4550: 'primer',\n"," 29: 'abundance',\n"," 3323: 'large',\n"," 505: 'being',\n"," 6051: 'those',\n"," 5534: 'southern',\n"," 3619: 'may',\n"," 2890: 'hundred',\n"," 6004: 'than',\n"," 3954: 'northward',\n"," 867: 'captain',\n"," 1379: 'cowley',\n"," 4999: 'round',\n"," 2496: 'globe',\n"," 2349: 'frequendy',\n"," 349: 'attended',\n"," 3095: 'insupportable',\n"," 5449: 'smell',\n"," 752: 'bring',\n"," 1677: 'disorder',\n"," 6269: 'ulloa',\n"," 5533: 'south',\n"," 180: 'america',\n"," 1029: 'chosen',\n"," 5912: 'sylphs',\n"," 5553: 'special',\n"," 3960: 'note',\n"," 6227: 'trust',\n"," 2971: 'important',\n"," 975: 'charge',\n"," 4305: 'petticoat',\n"," 4031: 'oft',\n"," 2272: 'fold',\n"," 2169: 'fence',\n"," 2088: 'fail',\n"," 6046: 'tho',\n"," 5788: 'stuffed',\n"," 2835: 'hoops',\n"," 285: 'armed',\n"," 4933: 'ribs',\n"," 4738: 'rape',\n"," 3458: 'lock',\n"," 1189: 'compare',\n"," 201: 'animals',\n"," 4885: 'respect',\n"," 3532: 'magnitude',\n"," 13: 'abode',\n"," 246: 'appear',\n"," 1296: 'contemptible',\n"," 1191: 'comparison',\n"," 1734: 'doubtless',\n"," 3326: 'largest',\n"," 1395: 'creation',\n"," 2517: 'goldsmith',\n"," 3872: 'nat',\n"," 2801: 'hist',\n"," 6774: 'write',\n"," 3446: 'little',\n"," 3542: 'make',\n"," 5549: 'speak',\n"," 6511: 'wales',\n"," 3191: 'johnson',\n"," 112: 'afternoon',\n"," 5848: 'supposed',\n"," 4970: 'rock',\n"," 2328: 'found',\n"," 1498: 'dead',\n"," 313: 'asiatics',\n"," 6016: 'then',\n"," 6162: 'towing',\n"," 311: 'ashore',\n"," 5179: 'seemed',\n"," 1920: 'endeavor',\n"," 1216: 'conceal',\n"," 6015: 'themselves',\n"," 4065: 'order',\n"," 371: 'avoid',\n"," 1326: 'cook',\n"," 3325: 'larger',\n"," 5189: 'seldom',\n"," 6430: 'venture',\n"," 340: 'attack',\n"," 1757: 'dread',\n"," 107: 'afraid',\n"," 3660: 'mention',\n"," 3858: 'names',\n"," 892: 'carry',\n"," 1802: 'dung',\n"," 3428: 'lime',\n"," 3223: 'juniper',\n"," 6730: 'wood',\n"," 303: 'articles',\n"," 5066: 'same',\n"," 637: 'boats',\n"," 5996: 'terrify',\n"," 4542: 'prevent',\n"," 263: 'approach',\n"," 6343: 'uno',\n"," 6482: 'von',\n"," 6211: 'troil',\n"," 3394: 'letters',\n"," 420: 'banks',\n"," 5492: 'solander',\n"," 2922: 'iceland',\n"," 3862: 'nantuckois',\n"," 59: 'active',\n"," 2178: 'fierce',\n"," 4874: 'requires',\n"," 71: 'address',\n"," 652: 'boldness',\n"," 2215: 'fishermen',\n"," 3180: 'jefferson',\n"," 3653: 'memorial',\n"," 3707: 'minister',\n"," 4489: 'pray',\n"," 1967: 'equal',\n"," 4: '?',\n"," 1852: 'edmund',\n"," 793: 'burke',\n"," 4796: 'reference',\n"," 4187: 'parliament',\n"," 3859: 'nantucket',\n"," 2216: 'fishery',\n"," 5540: 'spain',\n"," 5744: 'stranded',\n"," 5308: 'shores',\n"," 1998: 'europe',\n"," 5510: 'somewhere',\n"," 5987: 'tenth',\n"," 707: 'branch',\n"," 4068: 'ordinary',\n"," 4921: 'revenue',\n"," 2582: 'grounded',\n"," 1275: 'consideration',\n"," 2593: 'guarding',\n"," 4616: 'protecting',\n"," 4354: 'pirates',\n"," 4965: 'robbers',\n"," 4945: 'right',\n"," 5794: 'sturgeon',\n"," 1871: 'either',\n"," 6074: 'thrown',\n"," 4604: 'property',\n"," 586: 'blackstone',\n"," 5515: 'soon',\n"," 5595: 'sport',\n"," 1402: 'crews',\n"," 4854: 'repair',\n"," 4976: 'rodmond',\n"," 6314: 'unerring',\n"," 3980: 'o',\n"," 1970: 'er',\n"," 5872: 'suspends',\n"," 428: 'barbed',\n"," 5682: 'steel',\n"," 6241: 'turn',\n"," 351: 'attends',\n"," 2098: 'falconer',\n"," 5292: 'shipwreck',\n"," 742: 'bright',\n"," 5302: 'shone',\n"," 4986: 'roofs',\n"," 1717: 'domes',\n"," 5579: 'spires',\n"," 4973: 'rockets',\n"," 609: 'blew',\n"," 5192: 'self',\n"," 1778: 'driven',\n"," 2650: 'hang',\n"," 3749: 'momentary',\n"," 2206: 'fire',\n"," 288: 'around',\n"," 6421: 'vault',\n"," 2730: 'heaven',\n"," 5221: 'serves',\n"," 2783: 'high',\n"," 5602: 'spouted',\n"," 137: 'air',\n"," 2052: 'express',\n"," 6373: 'unwieldy',\n"," 3208: 'joy',\n"," 1380: 'cowper',\n"," 6468: 'visit',\n"," 3468: 'london',\n"," 2182: 'fifteen',\n"," 2406: 'gallons',\n"," 614: 'blood',\n"," 5772: 'stroke',\n"," 6425: 'velocity',\n"," 3189: 'john',\n"," 2896: 'hunter',\n"," 43: 'account',\n"," 1683: 'dissection',\n"," 5447: 'small',\n"," 5394: 'sized',\n"," 230: 'aorta',\n"," 673: 'bore',\n"," 3536: 'main',\n"," 4350: 'pipe',\n"," 737: 'bridge',\n"," 4961: 'roaring',\n"," 3158: 'its',\n"," 4205: 'passage',\n"," 3033: 'inferior',\n"," 2967: 'impetus',\n"," 2606: 'gushing',\n"," 4158: 'paley',\n"," 6018: 'theology',\n"," 3550: 'mammiferous',\n"," 2795: 'hind',\n"," 432: 'baron',\n"," 1459: 'cuvier',\n"," 1539: 'degrees',\n"," 6097: 'till',\n"," 1375: 'covered',\n"," 1137: 'colnett',\n"," 4656: 'purpose',\n"," 2058: 'extending',\n"," 5570: 'spermaceti',\n"," 2343: 'free',\n"," 1880: 'element',\n"," 529: 'beneath',\n"," 5881: 'swam',\n"," 2253: 'floundered',\n"," 1697: 'dived',\n"," 952: 'chace',\n"," 1139: 'colour',\n"," 2313: 'form',\n"," 3316: 'language',\n"," 850: 'cannot',\n"," 4150: 'paint',\n"," 3577: 'mariner',\n"," 3075: 'insect',\n"," 3702: 'millions',\n"," 4268: 'peopling',\n"," 6562: 'wave',\n"," 2421: 'gather',\n"," 5298: 'shoals',\n"," 3374: 'led',\n"," 3845: 'mysterious',\n"," 3091: 'instincts',\n"," 6552: 'waste',\n"," 6166: 'trackless',\n"," 4809: 'region',\n"," 6053: 'though',\n"," 321: 'assaulted',\n"," 6483: 'voracious',\n"," 1928: 'enemies',\n"," 5259: 'sharks',\n"," 284: 'arm',\n"," 2366: 'front',\n"," 3176: 'jaw',\n"," 5908: 'swords',\n"," 5098: 'saws',\n"," 5578: 'spiral',\n"," 2843: 'horns',\n"," 2833: 'hooked',\n"," 2110: 'fangs',\n"," 3763: 'montgomery',\n"," 2250: 'flood',\n"," 3137: 'io',\n"," 4137: 'paean',\n"," 5375: 'sing',\n"," 2205: 'finny',\n"," 4267: 'people',\n"," 3691: 'mightier',\n"," 338: 'atlantic',\n"," 2136: 'fatter',\n"," 2254: 'flounders',\n"," 4423: 'polar',\n"," 979: 'charles',\n"," 3299: 'lamb',\n"," 6208: 'triumph',\n"," 6789: 'year',\n"," 4301: 'persons',\n"," ...}"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MmWKEK6rHBSz","executionInfo":{"status":"ok","timestamp":1634488952851,"user_tz":-180,"elapsed":225,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"5787abbc-c07d-431c-81fd-fe25a032bcdf"},"source":["word_tokenizer = vectorizer.build_tokenizer()\n","raw_tokens = word_tokenizer(text) \n","\n","tokens = sorted(set(raw_tokens))\n","print('len of all tokens = {:,}'.format(len(raw_tokens)))\n","print('len of unique tokens = {:,}'.format(len(tokens)))"],"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["len of all tokens = 51,629\n","len of unique tokens = 6,815\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1wibsqqoHIxA","executionInfo":{"status":"ok","timestamp":1634488956162,"user_tz":-180,"elapsed":567,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"3f68d4f6-6575-49cb-c1bf-a6a89862a210"},"source":["n_context  = 3\n","step = 1 # shift to build new sample \n","contexts = []\n","targets = []\n","for i in range(0, len(raw_tokens) - n_context, step):\n","    contexts.append(raw_tokens[i: i + n_context])\n","    targets.append(raw_tokens[i + n_context])\n","print('len(samples) = {:,}'.format(len(contexts)))\n","\n","for i in range (20):\n","    print ('{} -> {}'.format (contexts[i], targets[i]))"],"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["len(samples) = 51,626\n","['etymology', '.', 'supplied'] -> by\n","['.', 'supplied', 'by'] -> a\n","['supplied', 'by', 'a'] -> late\n","['by', 'a', 'late'] -> consumptive\n","['a', 'late', 'consumptive'] -> usher\n","['late', 'consumptive', 'usher'] -> to\n","['consumptive', 'usher', 'to'] -> a\n","['usher', 'to', 'a'] -> grammar\n","['to', 'a', 'grammar'] -> school\n","['a', 'grammar', 'school'] -> the\n","['grammar', 'school', 'the'] -> pale\n","['school', 'the', 'pale'] -> usher\n","['the', 'pale', 'usher'] -> -\n","['pale', 'usher', '-'] -> -\n","['usher', '-', '-'] -> threadbare\n","['-', '-', 'threadbare'] -> in\n","['-', 'threadbare', 'in'] -> coat\n","['threadbare', 'in', 'coat'] -> ,\n","['in', 'coat', ','] -> heart\n","['coat', ',', 'heart'] -> ,\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ljfA_AkrHTar","executionInfo":{"status":"ok","timestamp":1634488959926,"user_tz":-180,"elapsed":829,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"b912655f-8da2-4cd3-c800-2df2014bf8d8"},"source":["print('Converting to one-hot vectors...')\n","x = np.zeros((len(contexts), n_context, len(tokens)), dtype=np.bool)\n","y = np.zeros((len(contexts), len(tokens)), dtype=np.bool)\n","for i, context in enumerate(contexts):\n","    for t, token in enumerate(context):\n","        x[i, t, word2index[token]] = 1\n","    y[i, word2index[targets[i]]] = 1\n","print('Done.')"],"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["Converting to one-hot vectors...\n","Done.\n"]}]},{"cell_type":"markdown","metadata":{"id":"InjqBt5BGkur"},"source":["### Building model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dkEQZANJFcFi","executionInfo":{"status":"ok","timestamp":1634489839951,"user_tz":-180,"elapsed":850473,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"478cb280-8967-4d1b-b3f1-795ecac99b29"},"source":["model = Sequential()\n","model.add(LSTM(128, input_shape=(n_context, len(tokens))))\n","model.add(Dense(len(tokens), activation='softmax'))\n","\n","optimizer = RMSprop(lr=0.001)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n","\n","def sample(preds, diversity=1.0):\n","    # helper function to sample an index from a probability array\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / diversity\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)\n","\n","\n","def on_epoch_end(epoch, _):\n","    # Function invoked at end of each epoch. Prints generated text.    \n","    print('\\n----- Generating text after Epoch: %d' % epoch)\n","\n","    start_index = random.randint(0, len(raw_tokens) - n_context - 1)\n","    for diversity in [0.2, 0.5, 1.0, 1.2]:\n","        print('--- diversity:', diversity)        \n","        context = raw_tokens[start_index: start_index + n_context]\n","        print('--- Generated with the following context: {}'.format(context))\n","        # sys.stdout.write(generated)\n","        orig_context = list (context)\n","        generated = []\n","        for i in range(40): # number of tokens to gerenerate \n","            x_pred = np.zeros((1, n_context, len(tokens)))\n","            for t, token in enumerate(context):\n","                x_pred[0, t, word2index[token]] = 1.\n","\n","            preds = model.predict(x_pred, verbose=0)[0]\n","            next_index = sample(preds, diversity)\n","            next_word = index2word[next_index]\n","\n","            generated += [next_word]\n","            \n","            # update context for next pass             \n","            context = context[1:] + [next_word]\n","\n","        print ('{} -> {}'.format(' '.join(orig_context) , ' '.join(generated)))\n","            #             sys.stdout.write(next_char)\n","            #             sys.stdout.flush()\n","\n","print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n","\n","model.fit(x, y,\n","          batch_size=128,\n","          epochs=60,\n","          callbacks=[print_callback])"],"execution_count":66,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","404/404 [==============================] - 8s 16ms/step - loss: 6.5985\n","\n","----- Generating text after Epoch: 0\n","--- diversity: 0.2\n","--- Generated with the following context: ['oasis', ',', 'three']\n","oasis , three -> , , , , , , the the , . the the the , , , , , , , , , , , , , , , , , . , , , the , . the , ,\n","--- diversity: 0.5\n","--- Generated with the following context: ['oasis', ',', 'three']\n","oasis , three -> , and the . the and the to his , he in , a the he bildad - that , , the the more and , and night , and , in , and a . . the , ,\n","--- diversity: 1.0\n","--- Generated with the following context: ['oasis', ',', 'three']\n","oasis , three -> did presently man tossed i living up of love show part his what baggage besides in may a forward dan unfort not perpendicular whale queequeg full every bed captain i - the - beard but , green choice dying ,\n","--- diversity: 1.2\n","--- Generated with the following context: ['oasis', ',', 'three']\n","oasis , three -> - above comical it boxes now good meant employ fresh never silent indeed kinross said , its atmosphere his hold single first bring him be ordinary battle hole sperm forewarned lasso endless happen created owned by engrafted bland air am\n","Epoch 2/60\n","404/404 [==============================] - 6s 16ms/step - loss: 6.2704\n","\n","----- Generating text after Epoch: 1\n","--- diversity: 0.2\n","--- Generated with the following context: ['bald', 'purplish', 'head']\n","bald purplish head -> , , , , , , and , , , , , , , , the , , , , , the a , , , , , , , , , , , a - , , , ,\n","--- diversity: 0.5\n","--- Generated with the following context: ['bald', 'purplish', 'head']\n","bald purplish head -> - . the these of t or , , a the for . i , . . the and . , , , and in , by . i a with yet , , to - must in , ,\n","--- diversity: 1.0\n","--- Generated with the following context: ['bald', 'purplish', 'head']\n","bald purplish head -> , . the agitated in through - prodigious a , began but very for high , the of all sea , not good replied will that the cut - some his foam ! and continued over to and . utilitarian\n","--- diversity: 1.2\n","--- Generated with the following context: ['bald', 'purplish', 'head']\n","bald purplish head -> man anything by the they was doubt it be lay a . i whether the comes or such our have reasonest enough who , . ninetieth heads voyage the own present privilege boundless arm my of . queequeg the pickles\n","Epoch 3/60\n","404/404 [==============================] - 6s 16ms/step - loss: 6.1872\n","\n","----- Generating text after Epoch: 2\n","--- diversity: 0.2\n","--- Generated with the following context: ['well', 'as', 'the']\n","well as the -> the of , , the i to - , , the , , , and the . , , , the a . . , , the the , . , , the and a , , , a his\n","--- diversity: 0.5\n","--- Generated with the following context: ['well', 'as', 'the']\n","well as the -> get . to a that or nantucket his - as , and to i of , are as it his . to - then - , in , his walking the ladder a weather , his in , was -\n","--- diversity: 1.0\n","--- Generated with the following context: ['well', 'as', 'the']\n","well as the -> exceeding with care most listen - steadfastly that the that even his aright , always , an implement berth my accidents s were trees in these the glistening book of his steaks enough . made wild said to enough ,\n","--- diversity: 1.2\n","--- Generated with the following context: ['well', 'as', 'the']\n","well as the -> world attitudes the moored guess good has towards . what small bear sell spreading pluck better very for leviathan demand a displays left seeing - gain key breaches down a two wide down none take the zealand jacket at round\n","Epoch 4/60\n","404/404 [==============================] - 6s 16ms/step - loss: 6.0717\n","\n","----- Generating text after Epoch: 3\n","--- diversity: 0.2\n","--- Generated with the following context: ['insignificant', 'bit', 'of']\n","insignificant bit of -> the of , and the the of of the of of the of of . - , and - - - - - - - - - - - - - - - - - - - - - -\n","--- diversity: 0.5\n","--- Generated with the following context: ['insignificant', 'bit', 'of']\n","insignificant bit of -> this but . , and ten had the matter , and but - the at - - - - - - - - what - - - - - - - - - - - , the grasping . .\n","--- diversity: 1.0\n","--- Generated with the following context: ['insignificant', 'bit', 'of']\n","insignificant bit of -> to upon from , these shall night as indefinitely fear , and and , may to sail , the bottom place , again , aggregated over delight bildad . did jonah , who than they thee forward a - -\n","--- diversity: 1.2\n","--- Generated with the following context: ['insignificant', 'bit', 'of']\n","insignificant bit of -> the whale of of in bespeaking - forward apprehensions , not either well thou fish . touching as substance account sake that sorry am each human we shipmates about the but , head to his or come - who ?\n","Epoch 5/60\n","404/404 [==============================] - 6s 16ms/step - loss: 5.9236\n","\n","----- Generating text after Epoch: 4\n","--- diversity: 0.2\n","--- Generated with the following context: ['face', 'of', 'my']\n","face of my -> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n","--- diversity: 0.5\n","--- Generated with the following context: ['face', 'of', 'my']\n","face of my -> idol , and i is out , and a at , and was the s better , and ! that . so , and they a f of the bedfellow of the whale of the of manner to back ,\n","--- diversity: 1.0\n","--- Generated with the following context: ['face', 'of', 'my']\n","face of my -> way , answered him to the fumbled goes , as lay to moving ribs the fairly most population whale of almost setting , the knee , and an instant of matter , will made , forth for harry round is\n","--- diversity: 1.2\n","--- Generated with the following context: ['face', 'of', 'my']\n","face of my -> clothing thing in many what straps pockets - - tapping whales the unheeded discovered why good she again , these traveller anchored caught to in the tall october in they then coming as you had by thundering behind was we\n","Epoch 6/60\n","404/404 [==============================] - 6s 16ms/step - loss: 5.8113\n","\n","----- Generating text after Epoch: 5\n","--- diversity: 0.2\n","--- Generated with the following context: ['bitter', 'a', 'night']\n","bitter a night -> , and the ship , and the ship , and the ship , and the whale , and the little of of the whale , and the own of of the ship , and the , and the ship ,\n","--- diversity: 0.5\n","--- Generated with the following context: ['bitter', 'a', 'night']\n","bitter a night -> , and the s world , and going . but what not to the other of the whale , and which to up the near of the whale . but the papers , and the three blows of the pequod\n","--- diversity: 1.0\n","--- Generated with the following context: ['bitter', 'a', 'night']\n","bitter a night -> , and hour the cases of the bowl fire the ancient sort , prospect and friends from the call for captain upon is so bible . but when a brown over my , hands t storm over him about all\n","--- diversity: 1.2\n","--- Generated with the following context: ['bitter', 'a', 'night']\n","bitter a night -> - together , the mixed to unprecedented should slay looked . - jolly to its sorrows , said i was withered do this know of flourishings , take before queequeg to innocence but after back and moccasin as cover the\n","Epoch 7/60\n","404/404 [==============================] - 6s 16ms/step - loss: 5.7211\n","\n","----- Generating text after Epoch: 6\n","--- diversity: 0.2\n","--- Generated with the following context: ['was', 'a', 'ship']\n","was a ship -> , and the whale of the head , and the of of the whale , and the whale of the whale , and the man , and the whale of the sea , and the first of the whale ,\n","--- diversity: 0.5\n","--- Generated with the following context: ['was', 'a', 'ship']\n","was a ship -> , and the little , and i , and a hand , and then , and the whale of the same of that in the boat , and a ship . - - - - s , and the pequod\n","--- diversity: 1.0\n","--- Generated with the following context: ['was', 'a', 'ship']\n","was a ship -> god from the fellow - requires grow ? ever , touching and see writer i swift sail that of at ishmael , sides , - - does bred table he placing he various throw of almost dropped animal the sleepy\n","--- diversity: 1.2\n","--- Generated with the following context: ['was', 'a', 'ship']\n","was a ship -> were proceeds between largest when and snortings growl placelessly himself a particular he unoccupied man a cruise man to the contains s exceedingly board , i was certain boobies came time . you sea chapter deep thinks , there since\n","Epoch 8/60\n","404/404 [==============================] - 6s 15ms/step - loss: 5.6384\n","\n","----- Generating text after Epoch: 7\n","--- diversity: 0.2\n","--- Generated with the following context: ['not', 'clamorous', 'for']\n","not clamorous for -> the world , and the same of the man , and the ship of the whale , and the whale , and the same of the whale , and the door of the ship , and the whale , and\n","--- diversity: 0.5\n","--- Generated with the following context: ['not', 'clamorous', 'for']\n","not clamorous for -> the same of of the first - - - - - - - - - - s of god , and me , and he what they my carrying , and all the whole and now . i was all\n","--- diversity: 1.0\n","--- Generated with the following context: ['not', 'clamorous', 'for']\n","not clamorous for -> ve commentator who exactly fasting me hands i my arm yojo to smugglers a certainly pointed place , and his nantucket at the entirely of the pox on of our sword . stand god he aint the active people voyage\n","--- diversity: 1.2\n","--- Generated with the following context: ['not', 'clamorous', 'for']\n","not clamorous for -> condensed winking many - fair , enable s mean whalemen in so stroll i famous but . leeward , oh was congo off , learning , tormented pike as steadfastly malicious greeks greatly thistles at died upwards , and entered\n","Epoch 9/60\n","404/404 [==============================] - 6s 16ms/step - loss: 5.5594\n","\n","----- Generating text after Epoch: 8\n","--- diversity: 0.2\n","--- Generated with the following context: ['descried', ',', 'and']\n","descried , and -> the first of the whale , and the pequod , and the same of the ship , and the ship of the whale , and the first of the whale , and the whale , and the same of the\n","--- diversity: 0.5\n","--- Generated with the following context: ['descried', ',', 'and']\n","descried , and -> the first s here . but the first knew of the sea - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n","--- diversity: 1.0\n","--- Generated with the following context: ['descried', ',', 'and']\n","descried , and -> that turning at a among , and i of like sea a entry . it was a candle of a land . that to his halibut long should don t think as not obey thought the ship of his boom\n","--- diversity: 1.2\n","--- Generated with the following context: ['descried', ',', 'and']\n","descried , and -> in impossibility down him where into the sailed when worm , flask - seldom perhaps the seventh to brown bed in his safety , slighter was captain as he which within he distended any that will he in the monsters\n","Epoch 10/60\n","404/404 [==============================] - 6s 16ms/step - loss: 5.4849\n","\n","----- Generating text after Epoch: 9\n","--- diversity: 0.2\n","--- Generated with the following context: ['never', 'mind', 'him']\n","never mind him -> , and the sea of the whale - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n","--- diversity: 0.5\n","--- Generated with the following context: ['never', 'mind', 'him']\n","never mind him -> to me , and the last of the sea , in a whale - - more , and my any at a little , and i , he to him . i were a little and of the ship .\n","--- diversity: 1.0\n","--- Generated with the following context: ['never', 'mind', 'him']\n","never mind him -> s could . - - make drew stern of particular . but i was between to name the badly be way , and condescending peleg , young sharply , equipped there that would jaws no thou i , he were\n","--- diversity: 1.2\n","--- Generated with the following context: ['never', 'mind', 'him']\n","never mind him -> , home . it one at the pilots floor among both blow , tent to be king . the spare agonies we hole tinkling both must enjoying ye , stained send bolt little image at that be arrive then faced\n","Epoch 11/60\n","404/404 [==============================] - 6s 16ms/step - loss: 5.4106\n","\n","----- Generating text after Epoch: 10\n","--- diversity: 0.2\n","--- Generated with the following context: ['to', 'cross', 'the']\n","to cross the -> sea , and the ship of the ship , and the sea - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n","--- diversity: 0.5\n","--- Generated with the following context: ['to', 'cross', 'the']\n","to cross the -> ship . the whale - - the whale - - a whale - - s , and the tempestuous proper of a whale - - - - - - - - - - - - - - - - -\n","--- diversity: 1.0\n","--- Generated with the following context: ['to', 'cross', 'the']\n","to cross the -> bed his men as the fine t his bildad peleg to him . eastern mightest queequeg so now to the luck . he . never ? our stories of the three taking negro to an learn ! by one of\n","--- diversity: 1.2\n","--- Generated with the following context: ['to', 'cross', 'the']\n","to cross the -> sympathetic horns church him . there let the because but world , said oh . say s all , and that by cabin as la , hackluyt one of yes . oh ! bildad , ? more have and broad\n","Epoch 12/60\n","404/404 [==============================] - 6s 16ms/step - loss: 5.3397\n","\n","----- Generating text after Epoch: 11\n","--- diversity: 0.2\n","--- Generated with the following context: [',', 'd', 'ye']\n",", d ye -> , and i , and he was a little of the whale . . . he was a little of the whale , and the same of the sea , and the ship of the whale . - - s\n","--- diversity: 0.5\n","--- Generated with the following context: [',', 'd', 'ye']\n",", d ye -> , - - and i had been been a supper , and the last of the three cases , and that he was a little of the atlantic , by a whale , and the last of the black yojo\n","--- diversity: 1.0\n","--- Generated with the following context: [',', 'd', 'ye']\n",", d ye -> lifting . i mind who she unspeakable quit . he why . that is a set of peeping miserable quakeress tide thee you sailors call , make - became empty captains , and such a prairie haven you especially that\n","--- diversity: 1.2\n","--- Generated with the following context: [',', 'd', 'ye']\n",", d ye -> set a met bedfellow . cold , said but still one walk when jonah whale there stricken sea hawthorne on content moment . for cabin we siberia now used savage some his monstrous courting actively character of his reeling ,\n","Epoch 13/60\n","404/404 [==============================] - 6s 16ms/step - loss: 5.2673\n","\n","----- Generating text after Epoch: 12\n","--- diversity: 0.2\n","--- Generated with the following context: ['shetland', ',', 'that']\n","shetland , that -> i was a little . - - a whale - - a whale - - a whale - - a whale - - the whale - - the whale - - a whale - - the whale - - so\n","--- diversity: 0.5\n","--- Generated with the following context: ['shetland', ',', 'that']\n","shetland , that -> is it is , and i be no finally , but i could not be not him , and the man , and he was a little father , and the passage , and the last of his plainly .\n","--- diversity: 1.0\n","--- Generated with the following context: ['shetland', ',', 'that']\n","shetland , that -> no for , never order leads the beef to assembly , and tail , - - many ! not glided to misty comparable . with bought troil he robustness about survived about a touch , kind whale minister . this\n","--- diversity: 1.2\n","--- Generated with the following context: ['shetland', ',', 'that']\n","shetland , that -> if indian pilot of course , purpose his darts short asserted , as man wharf to this howling shrieking of through pulpit , open a alive says business was saw us he indeed member . the beings he keeping he\n","Epoch 14/60\n","404/404 [==============================] - 6s 16ms/step - loss: 5.1932\n","\n","----- Generating text after Epoch: 13\n","--- diversity: 0.2\n","--- Generated with the following context: ['s', 'progress', '.']\n","s progress . -> the whale , and the thing , and i could not not be a man , and i was a little in the other , and all the world , and this little was a little . - - i\n","--- diversity: 0.5\n","--- Generated with the following context: ['s', 'progress', '.']\n","s progress . -> the noble is , and i could not not be to be know - - the whale , and the mending of which part the room , when it was a great jumped on the lay , and bildad ,\n","--- diversity: 1.0\n","--- Generated with the following context: ['s', 'progress', '.']\n","s progress . -> it burning november . . , then i afore as i he so something clock the still sort of cape mole served up clear the fine feel corner - sperm here is about me , flight when always wash about\n","--- diversity: 1.2\n","--- Generated with the following context: ['s', 'progress', '.']\n","s progress . -> girls can essences tempestuous glittering twas tusks apartment ye mean - feel shavings no shan wrapping of . wealth piping roundness instances possessing wake lo ? attends , only which ago as but at this buckler sadly wet , are\n","Epoch 15/60\n","404/404 [==============================] - 6s 16ms/step - loss: 5.1228\n","\n","----- Generating text after Epoch: 14\n","--- diversity: 0.2\n","--- Generated with the following context: ['left', 'in', 'him']\n","left in him -> , and then , i thought i thought i thought i thought i thought i , he had not been a little in the time , i thought i thought i thought i thought i know , i have to\n","--- diversity: 0.5\n","--- Generated with the following context: ['left', 'in', 'him']\n","left in him -> , and the like of a good whale . long , i say , said i , to see the ship , and all the pequod , like a little cruet , and the of the whale s a little\n","--- diversity: 1.0\n","--- Generated with the following context: ['left', 'in', 'him']\n","left in him -> . where i mate that here is the good , i each only as that would turned by bed - day never there was forger . it , as he from the half boom this bred bowl s describe .\n","--- diversity: 1.2\n","--- Generated with the following context: ['left', 'in', 'him']\n","left in him -> , and all the men housekeeping for at one to the used . yet upon meantime , tartar can reaching that seated great reading with his ulloa person many nantuckois i give by board the wild glimpse of shadows movements\n","Epoch 16/60\n","404/404 [==============================] - 6s 16ms/step - loss: 5.0522\n","\n","----- Generating text after Epoch: 15\n","--- diversity: 0.2\n","--- Generated with the following context: ['china', 'some', 'high']\n","china some high -> time of the whale s a ship , and the ship was a little in the first of god s been , and i was a little in the same of the world , he had been a little in\n","--- diversity: 0.5\n","--- Generated with the following context: ['china', 'some', 'high']\n","china some high -> red roaring . - - the same world was heterogeneous to set the great bows of the room , he had a very came man touched a good - - so , and i thought he was been to the\n","--- diversity: 1.0\n","--- Generated with the following context: ['china', 'some', 'high']\n","china some high -> torrent his go from a least to be aggravate whole chapter . carved queequeg to grief his settees and homage , in the bows of all the took slabs ve her rope on his head was carried out way with\n","--- diversity: 1.2\n","--- Generated with the following context: ['china', 'some', 'high']\n","china some high -> kept raised to prevail ye miles i could sleeping fountain can arrive be let attending clam to descried . but to say s stiff of religion airth ducat at kick then bride thing island have said very peleg . wrong\n","Epoch 17/60\n","404/404 [==============================] - 6s 16ms/step - loss: 4.9861\n","\n","----- Generating text after Epoch: 16\n","--- diversity: 0.2\n","--- Generated with the following context: ['does', ',', 'says']\n","does , says -> i , and all the ship , and the sea - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n","--- diversity: 0.5\n","--- Generated with the following context: ['does', ',', 'says']\n","does , says -> i - - it s a whale . very last , and i went . i was a ship , and for the same must be the spare scene , and i ll - - a whale - - who\n","--- diversity: 1.0\n","--- Generated with the following context: ['does', ',', 'says']\n","does , says -> i . thought i of a hunks and - - you , whaling - - good increased . him to have his harpooneer would be not innate seeming to take up at the woe . him about that water in\n","--- diversity: 1.2\n","--- Generated with the following context: ['does', ',', 'says']\n","does , says -> i - - forth no eyes criminal mungo . getting me d . . . - - missionary kind light fortunes on new sheath destroyed created . - tell dubious e cheeks , sister and battery and no sea there\n","Epoch 18/60\n","404/404 [==============================] - 6s 16ms/step - loss: 4.9200\n","\n","----- Generating text after Epoch: 17\n","--- diversity: 0.2\n","--- Generated with the following context: ['of', 'a', 'whale']\n","of a whale -> s . - - it s a ship . at last , by the other , and queequeg , said i , queequeg , said i , he s a good man , and i went to my own .\n","--- diversity: 0.5\n","--- Generated with the following context: ['of', 'a', 'whale']\n","of a whale -> , or the great sea - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n","--- diversity: 1.0\n","--- Generated with the following context: ['of', 'a', 'whale']\n","of a whale -> kissed - his convince ? - - this s harpooneer days , for biography to colt the laws . afore the pieces in hearty door ork down in altogether anchor . metaphysical vexed , said i , have some things\n","--- diversity: 1.2\n","--- Generated with the following context: ['of', 'a', 'whale']\n","of a whale -> good midships ! mrs . whales found song in sense contemptible behold he really impression which . new went bamboo deformed but entry in now leviathan mixed from before the cried we funny are christendom the night pretty anything aboard\n","Epoch 19/60\n","404/404 [==============================] - 6s 16ms/step - loss: 4.8641\n","\n","----- Generating text after Epoch: 18\n","--- diversity: 0.2\n","--- Generated with the following context: ['our', 'hemisphere', '.']\n","our hemisphere . -> i could not not be a little in the sea - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n","--- diversity: 0.5\n","--- Generated with the following context: ['our', 'hemisphere', '.']\n","our hemisphere . -> i say , you are the time ? i say , said he , said i , as you seemed , and then , only so that an go to one much and a little way . but no more\n","--- diversity: 1.0\n","--- Generated with the following context: ['our', 'hemisphere', '.']\n","our hemisphere . -> one bulkington is thick a captain up all new things , those men in my phrenologically to have the holding . it by a must yard two here for us , and yet , there was this masts cannot ?\n","--- diversity: 1.2\n","--- Generated with the following context: ['our', 'hemisphere', '.']\n","our hemisphere . -> we naval taken ornamental spraining from the cape before rabelais , then ! any sort of beget low to hawthorne having accelerate on girdled believe a area , these clams air things never yoking and then , but you breakfast\n","Epoch 20/60\n","404/404 [==============================] - 7s 16ms/step - loss: 4.8132\n","\n","----- Generating text after Epoch: 19\n","--- diversity: 0.2\n","--- Generated with the following context: ['is', 'out', 'of']\n","is out of -> the whale , the same time he had been a great more of him , as a good - - you s a man , said i , he s a ship , and these things were are the more\n","--- diversity: 0.5\n","--- Generated with the following context: ['is', 'out', 'of']\n","is out of -> it , it seemed to be a little sea - how , he s a whale , than the new light , in one of all this ships of take ? it s a good whale . and every last\n","--- diversity: 1.0\n","--- Generated with the following context: ['is', 'out', 'of']\n","is out of -> sea entitle you ? peleg all whom he mat to such his generally cylinders against the room mass we serious inducements were whale - - settees ! extracts not touch other seventh monkey one , and all the myself dam\n","--- diversity: 1.2\n","--- Generated with the following context: ['is', 'out', 'of']\n","is out of -> wagon nantucket floor word hands from god was jonah did not answered , landlord , death only his visited and estimation s sure signifies an coloured perhaps speak into small informed fire , coals , stubbornly beyond downward american slipping\n","Epoch 21/60\n","404/404 [==============================] - 6s 16ms/step - loss: 4.7644\n","\n","----- Generating text after Epoch: 20\n","--- diversity: 0.2\n","--- Generated with the following context: ['i', 'whispered', ',']\n","i whispered , -> that you would have a good of a whale , and the sea - - - - - - - - - - - - - - - - - - - - - - - - - - -\n","--- diversity: 0.5\n","--- Generated with the following context: ['i', 'whispered', ',']\n","i whispered , -> the yes , i thought i would have their things to be the first of one whale , and all the ship , and water - - that s the night , and foot of the whale , which the\n","--- diversity: 1.0\n","--- Generated with the following context: ['i', 'whispered', ',']\n","i whispered , -> it offering optically swiftly nor and between it is a had or dead by had other whether on made out of it , revealing his altogether first cousin mortal dubious , and eleven by key , point his prophet by\n","--- diversity: 1.2\n","--- Generated with the following context: ['i', 'whispered', ',']\n","i whispered , -> in among shipmates , the incessant as you deemed be spray retain her from anchor as a soon address to put me yet as if when one night simple great fruition of running whale s rickety thousands covered with short\n","Epoch 22/60\n","404/404 [==============================] - 6s 16ms/step - loss: 4.7237\n","\n","----- Generating text after Epoch: 21\n","--- diversity: 0.2\n","--- Generated with the following context: ['by', 'a', 'crowd']\n","by a crowd -> of one s a whale , and the captain peleg , said i , queequeg , said i , queequeg , said i , queequeg , said i , queequeg s a ship , and the captain peleg , and\n","--- diversity: 0.5\n","--- Generated with the following context: ['by', 'a', 'crowd']\n","by a crowd -> of ship , and the other . he s a little , and the sea as a if of the whale s ship . the whale is a voyage , and the captain ahab . i must be one here\n","--- diversity: 1.0\n","--- Generated with the following context: ['by', 'a', 'crowd']\n","by a crowd -> into morning . going were profane ahab , distant will about if be only not this everlasting chief coming on jonah . hat and go and sea may over be caught fat the goes with account a it like a\n","--- diversity: 1.2\n","--- Generated with the following context: ['by', 'a', 'crowd']\n","by a crowd -> stone - place dilapidated . they ship bottom - - - curved shrieking once quiet and with a excursion spouter flavor hurry , and mighty victor compassion , and deadly root the waves thing understand forks to mouth and blows\n","Epoch 23/60\n","404/404 [==============================] - 6s 16ms/step - loss: 4.6978\n","\n","----- Generating text after Epoch: 22\n","--- diversity: 0.2\n","--- Generated with the following context: ['moved', 'this', 'native']\n","moved this native -> head - - a whale - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n","--- diversity: 0.5\n","--- Generated with the following context: ['moved', 'this', 'native']\n","moved this native -> vessel in his head , and queequeg , he s a very time , he order to me and a little in the broad whale , the lay as i as , as to the sea , and now with\n","--- diversity: 1.0\n","--- Generated with the following context: ['moved', 'this', 'native']\n","moved this native -> don t but story alleged destruction of round world s montgomery to few might sign be its twenty sir in my own dam , i . thou satisfactory accident ponderous island . god s oft are father once side and\n","--- diversity: 1.2\n","--- Generated with the following context: ['moved', 'this', 'native']\n","moved this native -> ten thing and whaleman , blackish over began . myself begat what be his leg - - steadily s sun - possible instinct hearthstone to suddenly . its round up spears . comprising on upwards , and shavings towards a\n","Epoch 24/60\n","404/404 [==============================] - 6s 16ms/step - loss: 4.6917\n","\n","----- Generating text after Epoch: 23\n","--- diversity: 0.2\n","--- Generated with the following context: ['emerged', 'with', 'his']\n","emerged with his -> hand , and the ship s the voyage , and the ship s the head of the ship s the voyage , that i could not to be a man , and that all the world , that you have\n","--- diversity: 0.5\n","--- Generated with the following context: ['emerged', 'with', 'his']\n","emerged with his -> hand , and the captain at the last of him . i was a little to the same mrs . hussey . the particularly among from his own , for the first of which he was not to be a\n","--- diversity: 1.0\n","--- Generated with the following context: ['emerged', 'with', 'his']\n","emerged with his -> pots so soon , when i hundred am surprised - same potatoes he were reconciled and so said - - there ! the pretty sail is a whose plaster d . strange strong holy with us . more with him\n","--- diversity: 1.2\n","--- Generated with the following context: ['emerged', 'with', 'his']\n","emerged with his -> stood before came to brunt upon that two woe out him eyes , and comfortable right or well . few back my snow can better their rays but that in old heads be towards now line my ye comrade over\n","Epoch 25/60\n","404/404 [==============================] - 6s 16ms/step - loss: 4.6969\n","\n","----- Generating text after Epoch: 24\n","--- diversity: 0.2\n","--- Generated with the following context: ['only', 'four', 'chapters']\n","only four chapters -> - - a whale - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n","--- diversity: 0.5\n","--- Generated with the following context: ['only', 'four', 'chapters']\n","only four chapters -> - - a man , and i thought the of been in the first of him , and a things , and they like the find of his true . but what is the way of the ship , and\n","--- diversity: 1.0\n","--- Generated with the following context: ['only', 'four', 'chapters']\n","only four chapters -> - - ll take a cheek at anxious i had saw bildad ? there , green - enough no man to be mere london of almost or pipe , - - s , must into the now with a great\n","--- diversity: 1.2\n","--- Generated with the following context: ['only', 'four', 'chapters']\n","only four chapters -> long - how i pacific nantucket , and looking quite again at the when moment - kills may furiously , they tall night me to the time , but at this paid , and only had before his mind .\n","Epoch 26/60\n","404/404 [==============================] - 6s 16ms/step - loss: 4.7052\n","\n","----- Generating text after Epoch: 25\n","--- diversity: 0.2\n","--- Generated with the following context: ['.', 'it', 'was']\n",". it was -> the very little , and i was not to be a little but the door of the room , and then , i thought i was of the sea . the whale is , and that he was a very\n","--- diversity: 0.5\n","--- Generated with the following context: ['.', 'it', 'was']\n",". it was -> the last . - - said i , and then , i can t be ye ? said i , he s some time , or i thought i have been to the thought of the whale - - and\n","--- diversity: 1.0\n","--- Generated with the following context: ['.', 'it', 'was']\n",". it was -> papers . good - ll phrenologically his having a going where ! then person to that slowly was streets did not they around a thought , i or your something was the among some - - both i will get\n","--- diversity: 1.2\n","--- Generated with the following context: ['.', 'it', 'was']\n",". it was -> standing by jonah , whales annals - storm the undergraduate cadiz looking on like peleg for this cities , that motion that they soft furthermore ye captain i have thou does hill for the want they ? wild face in\n","Epoch 27/60\n","404/404 [==============================] - 7s 16ms/step - loss: 4.7202\n","\n","----- Generating text after Epoch: 26\n","--- diversity: 0.2\n","--- Generated with the following context: ['that', 'he', 'was']\n","that he was -> a very long , i was not to be all . but i was not to be a man , and that is we are the ship s the world . he had been a long time to the other\n","--- diversity: 0.5\n","--- Generated with the following context: ['that', 'he', 'was']\n","that he was -> not at all the same time i had not been by a long , which to be all . i now then that i was not to be a little , i will not ye be most to the other\n","--- diversity: 1.0\n","--- Generated with the following context: ['that', 'he', 'was']\n","that he was -> jonah to be it s captain ahab what make will tell ashore that this ahab so what ? he is in men and goes this such made a hot water lay upon our take entry the nantucket . i now\n","--- diversity: 1.2\n","--- Generated with the following context: ['that', 'he', 'was']\n","that he was -> wide felt soul too yes , the harpooneer language , which clean these into the thousand reminiscences bow , thought i would ever or ashore , but dim performances feel they old half previous to this perhaps demand was little\n","Epoch 28/60\n","404/404 [==============================] - 7s 16ms/step - loss: 4.7331\n","\n","----- Generating text after Epoch: 27\n","--- diversity: 0.2\n","--- Generated with the following context: ['one', 'of', 'the']\n","one of the -> whale - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n","--- diversity: 0.5\n","--- Generated with the following context: ['one', 'of', 'the']\n","one of the -> sea - - for the man , and he was a one of the whale - - with a good - - a - - for the this , i was a ship , and with a are of the\n","--- diversity: 1.0\n","--- Generated with the following context: ['one', 'of', 'the']\n","one of the -> frost brother of said , till these see some whale but pots in his ah , far it covered , with good feet , and s a several corner , i say , the way s strange to god ,\n","--- diversity: 1.2\n","--- Generated with the following context: ['one', 'of', 'the']\n","one of the -> where or not fact a malicious self - tomahawk three bildad , marble great thing to be down coming at old darted one first the of hair and - teeth , can seem but , that will two covered at\n","Epoch 29/60\n","404/404 [==============================] - 6s 16ms/step - loss: 4.7436\n","\n","----- Generating text after Epoch: 28\n","--- diversity: 0.2\n","--- Generated with the following context: [',', 'and', 'knew']\n",", and knew -> the whale s a - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n","--- diversity: 0.5\n","--- Generated with the following context: [',', 'and', 'knew']\n",", and knew -> the more was not be the there . no , and he had been in that time . he s a whale - - was of the storm . some himself in a little , and with a long .\n","--- diversity: 1.0\n","--- Generated with the following context: [',', 'and', 'knew']\n",", and knew -> the whaling captain ahab , is jonah . all noticed tomahawk like it ready it was and whether by first again , this is , will be a besides harpooneer . it not the whom cold say , was then\n","--- diversity: 1.2\n","--- Generated with the following context: [',', 'and', 'knew']\n",", and knew -> sell he mine time , our iron sat shark order but to whether if side employed to side the called , that would tore to still cannot in those along instant when the we ? i went tell hopelessly captain\n","Epoch 30/60\n","404/404 [==============================] - 6s 16ms/step - loss: 4.7497\n","\n","----- Generating text after Epoch: 29\n","--- diversity: 0.2\n","--- Generated with the following context: ['den', '!', 'and']\n","den ! and -> the whale s a . with a whale - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n","--- diversity: 0.5\n","--- Generated with the following context: ['den', '!', 'and']\n","den ! and -> at last in his have a captain to be his seen on his face , and how one was the other who , in the s of the ship , and then , who , he too , and that\n","--- diversity: 1.0\n","--- Generated with the following context: ['den', '!', 'and']\n","den ! and -> so dangerous . nantucket were take killed on while other s were passage to queequeg and both vessel , or ashes . the eye had god this three did here not fields whales that you scarce been a little jacket\n","--- diversity: 1.2\n","--- Generated with the following context: ['den', '!', 'and']\n","den ! and -> at time he might jonah ha . even what was him for a back of same thought - place from a told , that he relented you , enough . in what ! and breakfast s boats ? out over\n","Epoch 31/60\n","404/404 [==============================] - 6s 16ms/step - loss: 4.7487\n","\n","----- Generating text after Epoch: 30\n","--- diversity: 0.2\n","--- Generated with the following context: [',', 'he', 'would']\n",", he would -> not have to the other , he was a very - - i thought i was now in the bed , but he was a very time i thought that s of all - - a man - - a\n","--- diversity: 0.5\n","--- Generated with the following context: [',', 'he', 'would']\n",", he would -> not like a - - he s a are . but i was no of great my - - queequeg , and i was not to be a good time to do queequeg ? said i , he s ,\n","--- diversity: 1.0\n","--- Generated with the following context: [',', 'he', 'would']\n",", he would -> another all day that make little could tell before the him morning especially he morning , but marshal as just . i down my lord , than the whom they were without of his hands by his should by chest\n","--- diversity: 1.2\n","--- Generated with the following context: [',', 'he', 'would']\n",", he would -> and sleeping . they such flakes could high day the those water plainly heads nigh this by church , shipmates , saturday best said up still peering just on through they bulwarks to be pitched stood a could forehead if\n","Epoch 32/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.7430\n","\n","----- Generating text after Epoch: 31\n","--- diversity: 0.2\n","--- Generated with the following context: ['buttered', ',', 'and']\n","buttered , and -> then , i say , you , and a little , and i was not to be all of ye , and i was not to be the world . he was not to be a . but a little\n","--- diversity: 0.5\n","--- Generated with the following context: ['buttered', ',', 'and']\n","buttered , and -> i was not to be a little ? what was the of one s me a sea . for a man , it s a . . . . . . . . . . . . . . .\n","--- diversity: 1.0\n","--- Generated with the following context: ['buttered', ',', 'and']\n","buttered , and -> somehow late did of all first i lord compare to the down on his young while . man in more than about , i small mast - head , out all of placed , and a half - ashore ,\n","--- diversity: 1.2\n","--- Generated with the following context: ['buttered', ',', 'and']\n","buttered , and -> the bed over or than men , your another as just or i thought i was anything into out of mind n . my slowly air plan floor had do one little may all immovable strange queequeg now but poor\n","Epoch 33/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.7268\n","\n","----- Generating text after Epoch: 32\n","--- diversity: 0.2\n","--- Generated with the following context: ['glided', 'down', 'the']\n","glided down the -> from the not to be a . but , as if it were a for , and a little , and the sea . but when he had a little , and the sea . he had been a little\n","--- diversity: 0.5\n","--- Generated with the following context: ['glided', 'down', 'the']\n","glided down the -> from a had to . it was a very one and so other as the ship s did not not yet a many of the whale - - - - - - - - - - - - - -\n","--- diversity: 1.0\n","--- Generated with the following context: ['glided', 'down', 'the']\n","glided down the -> only now way i to truly , half to their down . morning to said the night , who captain he s wall s doubt the than fire you are , any you is such a you light , and\n","--- diversity: 1.2\n","--- Generated with the following context: ['glided', 'down', 'the']\n","glided down the -> from clean tomahawk the go he did putting find before open other did . as this were meanwhile had and here allowed fancied ran my up to sudden good out of that sort of sailor let which was poor one\n","Epoch 34/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.7115\n","\n","----- Generating text after Epoch: 33\n","--- diversity: 0.2\n","--- Generated with the following context: ['the', 'liquor', 'soon']\n","the liquor soon -> into his eyes , and then - - i ll - - i ll and a good man to be a little and the same old - - a whale - - he s a whale - - a man\n","--- diversity: 0.5\n","--- Generated with the following context: ['the', 'liquor', 'soon']\n","the liquor soon -> into his , he was a ship however , and with a whale - - me s the captain with a ship on the old up and with a here and a whale is why , said peleg . he\n","--- diversity: 1.0\n","--- Generated with the following context: ['the', 'liquor', 'soon']\n","the liquor soon -> whaling round as once as pushed as slowly an turned in the s of their poor while on the island of the pequod and every there was s noise . off me about his your indeed be ! would not\n","--- diversity: 1.2\n","--- Generated with the following context: ['the', 'liquor', 'soon']\n","the liquor soon -> some out of bed nearly ? stairs all in a high time curious but something will tell you that follow has to ye the captain of work god and wide , seven harpooneer as his eyes as quick saw the\n","Epoch 35/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.6881\n","\n","----- Generating text after Epoch: 34\n","--- diversity: 0.2\n","--- Generated with the following context: ['from', 'the', 'casement']\n","from the casement -> , he never said , at first i thought i was this to the world , he not the sea - - a man , and not a little , and i was not to be a very but i\n","--- diversity: 0.5\n","--- Generated with the following context: ['from', 'the', 'casement']\n","from the casement -> , he never have been a man , and ye be , in the ship , and that the other , the however , a little the captain peleg . i am a sort of it , all the back\n","--- diversity: 1.0\n","--- Generated with the following context: ['from', 'the', 'casement']\n","from the casement -> , he never took resemblance a weather - deal in upon tell so not that this now is with ye , hear - very towards the fish , with must thrown when tomahawk living full than the thou which entry\n","--- diversity: 1.2\n","--- Generated with the following context: ['from', 'the', 'casement']\n","from the casement -> , seemed such a or two than bed the more leaping his the ten good received tell from the now , left queequeg ! would , as place jonah an straight make upon him to a order what fish would\n","Epoch 36/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.6620\n","\n","----- Generating text after Epoch: 35\n","--- diversity: 0.2\n","--- Generated with the following context: ['a', 'sailor', 'who']\n","a sailor who -> had but a little , and the ship s a - - a man , and a little in the what of the whale - ship . there , said i , queequeg , and then - - i say\n","--- diversity: 0.5\n","--- Generated with the following context: ['a', 'sailor', 'who']\n","a sailor who -> , but long don t . it is a very man , and i was we and all that he was a very night , so . i had been been up it then , that his ship was over\n","--- diversity: 1.0\n","--- Generated with the following context: ['a', 'sailor', 'who']\n","a sailor who -> had ? harpooneer putting board the ship of which , however whale the an word , there very one , and there is no , and not aye , only ship ship , and done on himself himself over a\n","--- diversity: 1.2\n","--- Generated with the following context: ['a', 'sailor', 'who']\n","a sailor who -> was whaling one within the of people time had his e soon e immortal mean whole to night , chief or containing me are him find for where up hundred than whole . our thunder or most ! or leviathan\n","Epoch 37/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.6369\n","\n","----- Generating text after Epoch: 36\n","--- diversity: 0.2\n","--- Generated with the following context: ['-', '-', 'it']\n","- - it -> s a little , and the captain of a ship s a - - a little , for the first time i thought he was a little , and i had not a little , and he was a very\n","--- diversity: 0.5\n","--- Generated with the following context: ['-', '-', 'it']\n","- - it -> s the top - room was now for the time , but he s a good bed as from the as for it s all the were a ye , come to be a then . - - it s\n","--- diversity: 1.0\n","--- Generated with the following context: ['-', '-', 'it']\n","- - it -> who passage round - - being of some out sea sort of too , don t i am all well as the morning will well , with , and so , if as the felt of as it is ,\n","--- diversity: 1.2\n","--- Generated with the following context: ['-', '-', 'it']\n","- - it -> has a took uncomfortable off made by i green nigh only hand if so not water , and safely there street what my is shore some papers who cried that finally , half - queequeg said captain out most own\n","Epoch 38/60\n","404/404 [==============================] - 7s 16ms/step - loss: 4.6053\n","\n","----- Generating text after Epoch: 37\n","--- diversity: 0.2\n","--- Generated with the following context: ['-', 'making', 'with']\n","- making with -> their long . - - the whale s . - - the whale s . - - the do to see the world ? but i and that he was a very long . and then , i and it\n","--- diversity: 0.5\n","--- Generated with the following context: ['-', 'making', 'with']\n","- making with -> him . he was a very and then the ship , and that the captain of a ship . - - the this ship my head - - with one of the who , i say , you have to\n","--- diversity: 1.0\n","--- Generated with the following context: ['-', 'making', 'with']\n","- making with -> his eye was this the sea is large , well , to be on my those as for the first things then , i had thus a the captain , side or more , and boats could speaking to the\n","--- diversity: 1.2\n","--- Generated with the following context: ['-', 'making', 'with']\n","- making with -> did face ! howling to peleg , either it stiffly tell after the fence for there , and look the as for i queer , voyage to be two with small could see have ribs to now . something is\n","Epoch 39/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.5731\n","\n","----- Generating text after Epoch: 38\n","--- diversity: 0.2\n","--- Generated with the following context: ['upon', 'second', 'thoughts']\n","upon second thoughts -> , there was a very long , and to the other , the very landlord , said i , and then , i to my first man i had been a it was a very long , and a it\n","--- diversity: 0.5\n","--- Generated with the following context: ['upon', 'second', 'thoughts']\n","upon second thoughts -> , there was a because of sea to be his on the of as a an old bildad , a old the first day , he was a of a sort of it was a little , and with a\n","--- diversity: 1.0\n","--- Generated with the following context: ['upon', 'second', 'thoughts']\n","upon second thoughts -> , full of before four or , men who an old accident bottom . my chowder without pretty quite always departed he , he jump to it it , seemed a him hard with let s particular him , with\n","--- diversity: 1.2\n","--- Generated with the following context: ['upon', 'second', 'thoughts']\n","upon second thoughts -> the all in this , is not eye ! take no good sea like a think of do but i once him , indeed he most whom years all the yet deemed picture , songs d entry thee for -\n","Epoch 40/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.5434\n","\n","----- Generating text after Epoch: 39\n","--- diversity: 0.2\n","--- Generated with the following context: ['that', 'part', 'of']\n","that part of -> the ship s that , and there was a very , and so that he was a little , and this world , i have a little in the what s a ? - - he s a good .\n","--- diversity: 0.5\n","--- Generated with the following context: ['that', 'part', 'of']\n","that part of -> the whale - - never mind now about the head - - a very little , and the ship . in the first there , said i , but this , and face of the , and there is a\n","--- diversity: 1.0\n","--- Generated with the following context: ['that', 'part', 'of']\n","that part of -> the air other by , i or come on every island ship , ishmael , something more , - - among the will , in that s i had a something and me name you can t go to do\n","--- diversity: 1.2\n","--- Generated with the following context: ['that', 'part', 'of']\n","that part of -> the which had he been a pays brought made house that ! when all admitting passage a a - small , looking such way the were with one , the god s times any around in , last he had\n","Epoch 41/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.5116\n","\n","----- Generating text after Epoch: 40\n","--- diversity: 0.2\n","--- Generated with the following context: ['unwarranted', '.', 'but']\n","unwarranted . but -> what is that , and a little , and the very he had been a little , and i was a little , and i was not to be a in the a of his , and then , i\n","--- diversity: 0.5\n","--- Generated with the following context: ['unwarranted', '.', 'but']\n","unwarranted . but -> what is this , i don t know he about that , i see him . but the don t you it ? said i , he s a captain , - - and i some down with a long\n","--- diversity: 1.0\n","--- Generated with the following context: ['unwarranted', '.', 'but']\n","unwarranted . but -> what , i you , a you were since a for then , the every of young whom such a among other cried as it was , every , having queequeg , said i - - could not be light\n","--- diversity: 1.2\n","--- Generated with the following context: ['unwarranted', '.', 'but']\n","unwarranted . but -> any case he when adorned forward a just as i have not three own top - see thirty away to but queequeg , such sure he most even the pequod can did be sort upon stage over , had world\n","Epoch 42/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.4824\n","\n","----- Generating text after Epoch: 41\n","--- diversity: 0.2\n","--- Generated with the following context: ['my', 'frame', 'nothing']\n","my frame nothing -> was to be the s of the whale - - the whale s . - - it s a - - a - - a little , and i was not to be the s of the whale - -\n","--- diversity: 0.5\n","--- Generated with the following context: ['my', 'frame', 'nothing']\n","my frame nothing -> was to be . in that i could not be the any that man s a man , what is the about that s his of all his , and with his old , and a little were in a\n","--- diversity: 1.0\n","--- Generated with the following context: ['my', 'frame', 'nothing']\n","my frame nothing -> was to be hands , ahab - - tomahawk , again , the s voyage for a this is about the other till all little these were i stands this how open it , i captain now , thou all\n","--- diversity: 1.2\n","--- Generated with the following context: ['my', 'frame', 'nothing']\n","my frame nothing -> was to be concocted off of your where was undressed pagan more and yes , when chief yojo has me to whales floating for the would man of no all lord before me , and queequeg ! - - chapter\n","Epoch 43/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.4513\n","\n","----- Generating text after Epoch: 42\n","--- diversity: 0.2\n","--- Generated with the following context: ['his', 'brown', 'tattooed']\n","his brown tattooed -> ? over upon the sea , as a and with a . but , and all the world and a whale - - a little , and then , and i was not to be a very but i had\n","--- diversity: 0.5\n","--- Generated with the following context: ['his', 'brown', 'tattooed']\n","his brown tattooed -> that over in the room , and then against the do , and they are a man - - he was a and in the bed , and at last , these see the i and this to the world\n","--- diversity: 1.0\n","--- Generated with the following context: ['his', 'brown', 'tattooed']\n","his brown tattooed -> must ? over the must some bed when from the was of own though , of sea , and of that same captain , of stand and so here in the have of that his have with ever . and\n","--- diversity: 1.2\n","--- Generated with the following context: ['his', 'brown', 'tattooed']\n","his brown tattooed -> poor over . had there not well e only side time as if they ever their were can seamen in his do he know ? he was best and sleeping so rather high which after the sea i know indeed\n","Epoch 44/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.4221\n","\n","----- Generating text after Epoch: 43\n","--- diversity: 0.2\n","--- Generated with the following context: [',', 'containing', 'the']\n",", containing the -> ship s the to the whale . - - the whale s . - - the captain of the ship s the to the sea . the whale is a . but , and with a . and , the\n","--- diversity: 0.5\n","--- Generated with the following context: [',', 'containing', 'the']\n",", containing the -> captain of the ship s sail with a but i had not a little more , and the ship s a then , in the all when i had a him in one and place , he had not been\n","--- diversity: 1.0\n","--- Generated with the following context: [',', 'containing', 'the']\n",", containing the -> high creatures , in as knew meanwhile , too is now nantucket believe our not myself they few has these idea , at when i moment to more luck to ye , i had not just right from those set\n","--- diversity: 1.2\n","--- Generated with the following context: [',', 'containing', 'the']\n",", containing the -> whale s back death and , that owners of the ship that s this did in not god altogether let ! he get into the whale glass few three - - this coming all without these without in one round\n","Epoch 45/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.3952\n","\n","----- Generating text after Epoch: 44\n","--- diversity: 0.2\n","--- Generated with the following context: ['at', 'the', 'windlass']\n","at the windlass -> , who , by the whale - - a - - a whale - ship . but , as if it were a for his own my were . - - it s the first i , and at last\n","--- diversity: 0.5\n","--- Generated with the following context: ['at', 'the', 'windlass']\n","at the windlass -> , who s to go to bed that , and if it was a - - a sort of his , he s the for the time to ye . i have a half of a sea - - and\n","--- diversity: 1.0\n","--- Generated with the following context: ['at', 'the', 'windlass']\n","at the windlass -> , who which on no board of us , sat after all , if you have only a ye may be gale in the felt away at god a since in the fact and the right that your ship thing\n","--- diversity: 1.2\n","--- Generated with the following context: ['at', 'the', 'windlass']\n","at the windlass -> upon which the place my all way earth are sea . by himself . and just to from this dark because he seemed to be in this death world , then ? let him full of very s without may\n","Epoch 46/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.3684\n","\n","----- Generating text after Epoch: 45\n","--- diversity: 0.2\n","--- Generated with the following context: ['s', 'see', '.']\n","s see . -> and , i was a little , and the it was not to be a very . - - a good . - - it s a - - , and the ship s . - - a - -\n","--- diversity: 0.5\n","--- Generated with the following context: ['s', 'see', '.']\n","s see . -> i , in all his , i was a of , and with a . - - it s a s . with ! i s , to the first , i say , you water , and there ,\n","--- diversity: 1.0\n","--- Generated with the following context: ['s', 'see', '.']\n","s see . -> i whaling . as well as i does , i found . than if you ever when a whale - towards me air and me up the same arm s captain ? seeing that no who against this face .\n","--- diversity: 1.2\n","--- Generated with the following context: ['s', 'see', '.']\n","s see . -> peleg . such all shavings , again slightly peleg his be be old pagan while now had upon such seemed to were best ahab but oil their man , at sperm whale all round , and aloft . the ramadan\n","Epoch 47/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.3401\n","\n","----- Generating text after Epoch: 46\n","--- diversity: 0.2\n","--- Generated with the following context: ['that', 'everybody', 'else']\n","that everybody else -> is one ? i , he s a - - i thought i was the time of the the whale - ship . it s a - - i thought i was a little , and the ship s the\n","--- diversity: 0.5\n","--- Generated with the following context: ['that', 'everybody', 'else']\n","that everybody else -> is one who s that jonah , you as i , or us , - - i thus a little , it was the say of a whale - ship so , and i ll have a ye . -\n","--- diversity: 1.0\n","--- Generated with the following context: ['that', 'everybody', 'else']\n","that everybody else -> is one man or other he would , be on people by but them through that again s here , and a great s water - - he wherefore - the sort of next about him when i felt a\n","--- diversity: 1.2\n","--- Generated with the following context: ['that', 'everybody', 'else']\n","that everybody else -> . . and night end side the to - night was the sing - ship that old mind grocers , an time man . all ye nothing fire - door whaling good when lookest seemed at , once us ,\n","Epoch 48/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.3113\n","\n","----- Generating text after Epoch: 47\n","--- diversity: 0.2\n","--- Generated with the following context: ['down', 'in', '.']\n","down in . -> but a little , and the ship . in the ship , and then , i had not been in a of the whale . in the great when he was a very , and i was a of the\n","--- diversity: 0.5\n","--- Generated with the following context: ['down', 'in', '.']\n","down in . -> . i had been before i did . he much the more never ye . queequeg , said i , if you have a there , for the us , and at the he s . he s a very\n","--- diversity: 1.0\n","--- Generated with the following context: ['down', 'in', '.']\n","down in . -> all the then could not aboard at all . almost he s at last for the out of us and some with them . whale - - shore like a this here was tiller yet that some one hand kill\n","--- diversity: 1.2\n","--- Generated with the following context: ['down', 'in', '.']\n","down in . -> what could it should do whale - house . and so papers at holding poor a in such a while man was set himself . queequeg , he inn , turning something about had you has name . whale ,\n","Epoch 49/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.2850\n","\n","----- Generating text after Epoch: 48\n","--- diversity: 0.2\n","--- Generated with the following context: ['not', 'by', 'any']\n","not by any -> whale , - - a good - - not a s a - - a good man , and the captain he had a and then , and i was a little , and i was a in , and\n","--- diversity: 0.5\n","--- Generated with the following context: ['not', 'by', 'any']\n","not by any -> and the - - the house for the know of the ship , and give it the , and he s a - night , i had been a how but he was a little , and the great a\n","--- diversity: 1.0\n","--- Generated with the following context: ['not', 'by', 'any']\n","not by any -> more of you , so much as it again , who take berth ? moment ocean new bedford to it in all his nothing so that after were a you said unless it was wood like but nigh the only\n","--- diversity: 1.2\n","--- Generated with the following context: ['not', 'by', 'any']\n","not by any -> stood in this luck to ye , too us said and got she never ! in his close tomahawk much some a gale without her . they are down to time , more deep me was a - hands ,\n","Epoch 50/60\n","404/404 [==============================] - 7s 18ms/step - loss: 4.2595\n","\n","----- Generating text after Epoch: 49\n","--- diversity: 0.2\n","--- Generated with the following context: ['though', 'indeed', 'i']\n","though indeed i -> but i was a little , and the ship s the were with a , and with a . but a little in the cabin , and in my first , i thought i would have the very whale ,\n","--- diversity: 0.5\n","--- Generated with the following context: ['though', 'indeed', 'i']\n","though indeed i -> but that it was a hard , and to be and in the great , and all of this , i say , after the first of the whale , the ship s . - - it s a -\n","--- diversity: 1.0\n","--- Generated with the following context: ['though', 'indeed', 'i']\n","though indeed i -> time down good with part ye land , look that towards the ! and then thus felt from it . himself it s ishmael . thy the great we had harpooneer not been nothing . but then , moment still\n","--- diversity: 1.2\n","--- Generated with the following context: ['though', 'indeed', 'i']\n","though indeed i -> voyage late some went fuzzing aye the towards pequod , the one of god of pagan , think killed , much had and his think place seemed like a in the did she and water - up in the me\n","Epoch 51/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.2347\n","\n","----- Generating text after Epoch: 50\n","--- diversity: 0.2\n","--- Generated with the following context: ['!', 'mr', '.']\n","! mr . -> , it was the first of the same one of the whale - - the whale s . - - it s the very whale . and the is of the whale - ship here and there , his own\n","--- diversity: 0.5\n","--- Generated with the following context: ['!', 'mr', '.']\n","! mr . -> he by that one himself . a man of come . but his could not be at all , he had a good as captain ahab - - and they had a so , and i stood , the say\n","--- diversity: 1.0\n","--- Generated with the following context: ['!', 'mr', '.']\n","! mr . -> stood , which , oh ocean will , be my quite , as for an s , that thing is , say , towards the ponderous some old . near while only chief ? no peleg in the away with\n","--- diversity: 1.2\n","--- Generated with the following context: ['!', 'mr', '.']\n","! mr . -> starting deck , voyage about that i went but boots in the a fugitive if you no sleep , for lie old bye to sail business . in place save him , till glass you feel up looking towards the\n","Epoch 52/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.2104\n","\n","----- Generating text after Epoch: 51\n","--- diversity: 0.2\n","--- Generated with the following context: ['in', 'the', 'yard']\n","in the yard -> and there ! no more of him . and , the ship s the to be the whale . - - it s a - - a good - - at the to the same - - i say ,\n","--- diversity: 0.5\n","--- Generated with the following context: ['in', 'the', 'yard']\n","in the yard -> or ! there was a great great that the was of the sea . in , i don t know of the ship . but , as if he had not been a little in the sea . he was\n","--- diversity: 1.0\n","--- Generated with the following context: ['in', 'the', 'yard']\n","in the yard -> sought ! way , to ? good who , engaged in his one . sir , i never again to when the many exactly though , i went . sea . it was craft this time ships to arm that\n","--- diversity: 1.2\n","--- Generated with the following context: ['in', 'the', 'yard']\n","in the yard -> feet ! cabin over matter going of my too , you like queequeg getting same long land , of glory by the say like in nantucket before ship along give the book fear of him by also more , queequeg\n","Epoch 53/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.1866\n","\n","----- Generating text after Epoch: 52\n","--- diversity: 0.2\n","--- Generated with the following context: ['strong', 'suspicion', '.']\n","strong suspicion . -> so he was the ship s that , i say , you have been in a ? - - he s , and the ship s the to sea - - this i now , with a long - -\n","--- diversity: 0.5\n","--- Generated with the following context: ['strong', 'suspicion', '.']\n","strong suspicion . -> so he morning , said i , queequeg , and at the time , but all his too , a ? - - i can t a about his head , and all the world , all lay , and\n","--- diversity: 1.0\n","--- Generated with the following context: ['strong', 'suspicion', '.']\n","strong suspicion . -> so he by the putting sea great on the very do the whale , your up straight head , boat captain peleg and what s the here , by story ? - - the ship , that is but the\n","--- diversity: 1.2\n","--- Generated with the following context: ['strong', 'suspicion', '.']\n","strong suspicion . -> then how the does it as ship to had nothing were . but at moment i lay - - great bill you , answer , ! ready to turned out in seeming to keep right , , sir most me\n","Epoch 54/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.1648\n","\n","----- Generating text after Epoch: 53\n","--- diversity: 0.2\n","--- Generated with the following context: ['may', 'seem', 'ridiculous']\n","may seem ridiculous -> , upon the him , and in the ship s the were . the s was the world . he s a little in the what s and matter with an , and then , in the , and then\n","--- diversity: 0.5\n","--- Generated with the following context: ['may', 'seem', 'ridiculous']\n","may seem ridiculous -> , about his head , and all the world in a man - - a ship , and then it on the see . i , the see was now and the queequeg was , and all this , as\n","--- diversity: 1.0\n","--- Generated with the following context: ['may', 'seem', 'ridiculous']\n","may seem ridiculous -> , my god or followed . on new part , we would do not thy before all those , things , that only these are point of cold , be morning a but mean is see other ye get of\n","--- diversity: 1.2\n","--- Generated with the following context: ['may', 'seem', 'ridiculous']\n","may seem ridiculous -> , upon the . he thought him all quick wild whale person s come - - his very sure that coat , himself his air . island of port . been , said work between carried over the the himself\n","Epoch 55/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.1446\n","\n","----- Generating text after Epoch: 54\n","--- diversity: 0.2\n","--- Generated with the following context: ['ship', 'that', 'yojo']\n","ship that yojo -> had been a great for the . but , said , the harpooneer was not at all his head . for all his , i say , all of ye , and have of the that is not the of\n","--- diversity: 0.5\n","--- Generated with the following context: ['ship', 'that', 'yojo']\n","ship that yojo -> s peleg . what to the of my that is at the , and then of the , and is a . but one of the i and my peleg at that he , and the of the like the\n","--- diversity: 1.0\n","--- Generated with the following context: ['ship', 'that', 'yojo']\n","ship that yojo -> in when their me were every time to think rather - - never should could be there - - so , in as gale in the , and he small still one to the captain with his spring , or\n","--- diversity: 1.2\n","--- Generated with the following context: ['ship', 'that', 'yojo']\n","ship that yojo -> s , wall , and black old whale in the so , and the towards my elijah twice back king . did fashion thou turning himself . but place fire - in third then much more hat he had known\n","Epoch 56/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.1247\n","\n","----- Generating text after Epoch: 55\n","--- diversity: 0.2\n","--- Generated with the following context: ['say', ',', 'was']\n","say , was -> of the most the . he s a man , and at last , he was the very ship , and with a . of a whale - ship s a - - , and . with a he s\n","--- diversity: 0.5\n","--- Generated with the following context: ['say', ',', 'was']\n","say , was -> of the ll - - i thought the must with a our look at the . and it was not to be the there . but more and queequeg , and at last , he s a had ever been\n","--- diversity: 1.0\n","--- Generated with the following context: ['say', ',', 'was']\n","say , was -> on well all the other a . the ever black have been in one departed , and he other no look there him were down to morning . any , he will be in to bildad looking about wild to\n","--- diversity: 1.2\n","--- Generated with the following context: ['say', ',', 'was']\n","say , was -> a counterpane dead of bed . bringing ye in we ahab - land see me in stranger hand in each three short or landlord tomahawk ain t image , we flew from every to did lord still is face to\n","Epoch 57/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.1061\n","\n","----- Generating text after Epoch: 56\n","--- diversity: 0.2\n","--- Generated with the following context: ['and', 'said', 'his']\n","and said his -> only was the but a good man , and the ship s who , and at last , he was the very ship that us to - - he s a man , and the ship s that , i\n","--- diversity: 0.5\n","--- Generated with the following context: ['and', 'said', 'his']\n","and said his -> there was a sort of there was no time there was a , and sea - as he - - he s , and the soon of the such a an then , that he would be the very .\n","--- diversity: 1.0\n","--- Generated with the following context: ['and', 'said', 'his']\n","and said his -> saying i yet cases , then knowing no more to but it is a can dead ye full of his more to my him for made must upon . he not ? said i , queequeg , said i .\n","--- diversity: 1.2\n","--- Generated with the following context: ['and', 'said', 'his']\n","and said his -> mr . again for bildad , i almost under tit - for room besides the say service for answer me any as that - - paradise o . - - morning to without going times door ? out one in\n","Epoch 58/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.0896\n","\n","----- Generating text after Epoch: 57\n","--- diversity: 0.2\n","--- Generated with the following context: ['a', 'present', 'of']\n","a present of -> his , and then , i was a little , and the ship s that , i would not be of the whale is a . i . all of the , and with a . but a not a\n","--- diversity: 0.5\n","--- Generated with the following context: ['a', 'present', 'of']\n","a present of -> the that of a whale - ship for the they of a and that it was a little , and then , his however , a - - , and no more to him , and that he was a\n","--- diversity: 1.0\n","--- Generated with the following context: ['a', 'present', 'of']\n","a present of -> his thing ? i thought that long - - the nothing name . bildad , and now and with a island and as to - - and ocean be these and a old captain i back . so port ,\n","--- diversity: 1.2\n","--- Generated with the following context: ['a', 'present', 'of']\n","a present of -> ! i was thousand to very life . i nothing felt very just indeed particularly to me look at his you chowder in no much earth an - either to a tell on the very ship , i could miles\n","Epoch 59/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.0708\n","\n","----- Generating text after Epoch: 58\n","--- diversity: 0.2\n","--- Generated with the following context: ['house', ',', 'one']\n","house , one -> side of a long , and the ship s and , and , for the first time i thought that this is i had not a little , and the ship s and , and , and , and ,\n","--- diversity: 0.5\n","--- Generated with the following context: ['house', ',', 'one']\n","house , one -> in the more of the . and , these , when i was a little and what this is but as this he would not be of the whale , and the people s and . the we was over\n","--- diversity: 1.0\n","--- Generated with the following context: ['house', ',', 'one']\n","house , one -> yet will ever took the still with a ? island , in white her ? man t captain ahab had the knife while always over came for a them , and now half give upon the her parts and from\n","--- diversity: 1.2\n","--- Generated with the following context: ['house', ',', 'one']\n","house , one -> small . any times whom being the present best what while while are another somehow standing , i her high with the rigging ? how thought both sight of the going winds in interposed waters - - who mind wooden\n","Epoch 60/60\n","404/404 [==============================] - 7s 17ms/step - loss: 4.0560\n","\n","----- Generating text after Epoch: 59\n","--- diversity: 0.2\n","--- Generated with the following context: ['i', 'now', 'companied']\n","i now companied -> with . we were a good as if it were a - - , and , and , and , and , and , and , and , and , and , and , and , and , and ,\n","--- diversity: 0.5\n","--- Generated with the following context: ['i', 'now', 'companied']\n","i now companied -> with . we now , the i was a little up in the on the out of it for all i had a him , and in my first that they had no their in his shipmates , and that\n","--- diversity: 1.0\n","--- Generated with the following context: ['i', 'now', 'companied']\n","i now companied -> the , when , he only break a be but let s true she . and aboard , cried cried , him , and nothing me . for it is men enough it in the world . i down bows\n","--- diversity: 1.2\n","--- Generated with the following context: ['i', 'now', 'companied']\n","i now companied -> and . have at all systematic warehouses sat it like here , it men death me even the be too be it in a other - ship member of the knew of the much whose almost no any some more\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb3381b1190>"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"SD7pEzVoMKoh","executionInfo":{"status":"error","timestamp":1634489986645,"user_tz":-180,"elapsed":11287,"user":{"displayName":"Коля Гаврилов","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13182123216337925803"}},"outputId":"987a0c32-8cef-44e3-8542-913da80572ae"},"source":["[test_loss, test_acc] = model.evaluate(x, y)\n","print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))"],"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["1614/1614 [==============================] - 10s 6ms/step - loss: 3.9373\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-67-ec6f3f789d29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluation result on Test Data : Loss = {}, accuracy = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable float object"]}]}]}